<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="sec-useful-descriptive-statistics-tools" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Useful Tools for Descriptive Statistics and Exploratory Data Analysis</title>
  <introduction>
    <p>
      Exploratory Data Analysis (EDA) is a critical step in understanding your data before applying advanced techniques like machine learning. It involves summarizing the main characteristics of a dataset, often using visual methods, to uncover patterns, spot anomalies, test hypotheses, and check assumptions. In this section, we focus on Python-based tools that enable efficient and effective data analysis, tailored for machine learning workflows. While languages like R are powerful for statistics, we emphasize Python due to its widespread use in data science and machine learning communities. Key tools include NumPy for numerical computations, Pandas for data manipulation, and Matplotlib/Seaborn for visualization. These libraries integrate seamlessly, allowing you to load, clean, analyze, and visualize data in a streamlined manner.
    </p>
    <p>
      A typical EDA workflow includes: loading data, inspecting its structure, handling missing values, computing summary statistics, exploring distributions, and visualizing relationships. Using Jupyter notebooks ensures reproducibility and documentation of your analysis.
    </p>
  </introduction>
  <subsection xml:id="subsec-NumPy">
    <title>NumPy: Foundation for Numerical Operations</title>
    <p>
      NumPy (Numerical Python) is the backbone of scientific computing in Python, providing support for large, multi-dimensional arrays and matrices, along with mathematical functions for efficient operations. It’s foundational for Pandas and essential for computing descriptive statistics.
    </p>
    <p>
      <alert>Key Features:</alert>
      <ul>
        <li>Efficient array creation and manipulation (e.g., reshaping, slicing).</li>
        <li>Statistical functions: mean, median, standard deviation, variance, percentiles.</li>
        <li>Integration with Pandas DataFrames and visualization libraries.</li>
      </ul>
    </p>
    <p>
      <alert>Example:</alert> Compute descriptive statistics for exam scores.
    </p>
    <program language="python" line-numbers="yes">
      <title>Computing statistics with NumPy</title>
      <code>
import numpy as np

# Sample data: exam scores
scores = np.array([85, 92, 78, 95, 88, 76, 90, 82])

# Basic statistics
mean = np.mean(scores)
median = np.median(scores)
std_dev = np.std(scores, ddof=1)  # Sample std dev
variance = np.var(scores, ddof=1)  # Sample variance
percentiles = np.percentile(scores, [25, 50, 75])

print(f"Mean: {mean:.2f}")
print(f"Median: {median:.2f}")
print(f"Sample Standard Deviation: {std_dev:.2f}")
print(f"Sample Variance: {variance:.2f}")
print(f"25th, 50th, 75th Percentiles: {percentiles}")

      </code>
    </program>
    <p>
      Output:
      <pre>
Mean: 85.75
Median: 86.50
Sample Standard Deviation: 6.82
Sample Variance: 46.50
25th, 50th, 75th Percentiles: [80.5  86.5  91.25]
      </pre>
    </p>
    <p>
      <alert>NumPy is fast for numerical operations but lacks labeled data handling, which is where Pandas excels.</alert>
    </p>
  </subsection>
  <subsection xml:id="subsec-Pandas">
    <title>Pandas: Data Manipulation and Analysis</title>
    <introduction>
      <p>
        Pandas is a powerful, flexible library for data manipulation and analysis, built on NumPy. Its core data structures are:
        <ol>
          <li><alert>Series</alert>: A one-dimensional labeled array for sequences of data.</li>
          <li><alert>DataFrame</alert>: A two-dimensional labeled table, similar to a spreadsheet or SQL table, ideal for tabular data.</li>
        </ol>
      </p>
      <p>
        Pandas is designed for cleaning, transforming, analyzing, and visualizing data. It supports multiple file formats (CSV, Excel, JSON, SQL) and integrates with NumPy, Matplotlib, Seaborn, and Scikit-learn, making it a cornerstone for EDA in machine learning.
      </p>
    </introduction>
    <p>
      <alert>Why Use Pandas?</alert>
      <ul>
        <li>Handles structured data efficiently (e.g., tabular data).</li>
        <li>Supports data cleaning (missing values, duplicates, outliers).</li>
        <li>Enables grouping, aggregation, and statistical summaries.</li>
        <li>Scales to large datasets with optimized performance.</li>
      </ul>
    </p>
    <p>
      <alert>EDA Workflow with Pandas:</alert>
      <ol>
        <li>Load data (<c>pd.read_csv()</c>, <c>pd.read_excel()</c>).</li>
        <li>Inspect structure (<c>head()</c>, <c>info()</c>, <c>describe()</c>).</li>
        <li>Clean data (handle missing values, remove duplicates).</li>
        <li>Compute statistics and explore distributions.</li>
        <li>Visualize (integrate with Matplotlib/Seaborn).</li>
      </ol>
    </p>
    <p>
      <alert>Example: Analyzing Student Data</alert> Let’s use a realistic dataset of student scores, including a missing value, loaded from a CSV file.
    </p>
    <program language="python" line-numbers="yes">
      <title>Creating and loading sample student data</title>
      <code>
import pandas as pd

# Create sample CSV data (in practice, load from disk)
data = """Name,Age,Score,Passed
Alice,25,85.5,True
Bob,30,90.0,True
Carol,27,88.0,True
Dave,22,76.5,False
Eve,28,,True"""

with open('students.csv', 'w') as f:
    f.write(data)

# Load data
df = pd.read_csv('students.csv')
print(df)
      </code>
    </program>
    <p>
      Output as a table:
    </p>
    <table xml:id="tab-students-dataframe">
      <title>Student DataFrame</title>
      <tabular>
        <row header="yes">
          <cell>Name</cell> <cell>Age</cell> <cell>Score</cell> <cell>Passed</cell>
        </row>
        <row>
          <cell>Alice</cell> <cell>25</cell> <cell>85.5</cell> <cell>True</cell>
        </row>
        <row>
          <cell>Bob</cell> <cell>30</cell> <cell>90.0</cell> <cell>True</cell>
        </row>
        <row>
          <cell>Carol</cell> <cell>27</cell> <cell>88.0</cell> <cell>True</cell>
        </row>
        <row>
          <cell>Dave</cell> <cell>22</cell> <cell>76.5</cell> <cell>False</cell>
        </row>
        <row>
          <cell>Eve</cell> <cell>28</cell> <cell>NaN</cell> <cell>True</cell>
        </row>
      </tabular>
    </table>
    <p>
      Inspect the data using common Pandas methods:
    </p>
    <program language="python" line-numbers="yes">
      <title>Inspecting DataFrame</title>
      <code>
# Inspect data
print("First 3 rows:")
print(df.head(3))
print("\nLast 2 rows:")
print(df.tail(2))
print("\nShape:", df.shape)  # (5, 4)
print("\nColumns:", df.columns.tolist())
print("\nInfo:")
print(df.info())
print("\nDescriptive Statistics:")
print(df.describe())
      </code>
    </program>
    <p>
      Output of <c>df.describe()</c>:
    </p>
    <table xml:id="tab-students-describe">
      <title>Descriptive Statistics from df.describe()</title>
      <tabular>
        <row header="yes">
          <cell></cell> <cell>Age</cell> <cell>Score</cell>
        </row>
        <row>
          <cell>count</cell> <cell>5.000000</cell> <cell>4.000000</cell>
        </row>
        <row>
          <cell>mean</cell> <cell>26.400000</cell> <cell>85.000000</cell>
        </row>
        <row>
          <cell>std</cell> <cell>3.209361</cell> <cell>5.958188</cell>
        </row>
        <row>
          <cell>min</cell> <cell>22.000000</cell> <cell>76.500000</cell>
        </row>
        <row>
          <cell>25%</cell> <cell>24.250000</cell> <cell>83.250000</cell>
        </row>
        <row>
          <cell>50%</cell> <cell>26.000000</cell> <cell>86.750000</cell>
        </row>
        <row>
          <cell>75%</cell> <cell>27.750000</cell> <cell>88.500000</cell>
        </row>
        <row>
          <cell>max</cell> <cell>30.000000</cell> <cell>90.000000</cell>
        </row>
      </tabular>
    </table>
    <p>
      Clean and transform the data (e.g., handle missing values, filter, add columns, group, sort):
    </p>
    <program language="python" line-numbers="yes">
      <title>Data cleaning and transformation</title>
      <code>
# Handle missing values
print("Missing values:\n", df.isnull())
df['Score'] = df['Score'].fillna(df['Score'].mean())  # Fill NaN with mean

# Filter rows
high_scorers = df[df['Score'] > 85]
print("\nHigh scorers:\n", high_scorers)

# Add new column
df['Grade'] = df['Score'].apply(lambda x: 'A' if x >= 90 else 'B' if x >= 80 else 'C')
print("\nDataFrame with Grade:\n", df)

# Group and aggregate
grouped = df.groupby('Passed')['Score'].agg(['mean', 'count'])
print("\nGrouped by Passed:\n", grouped)

# Sort by Score
df_sorted = df.sort_values(by='Score', ascending=False)
print("\nSorted by Score:\n", df_sorted)

# Chain operations
result = df[df['Age'] > 25][['Name', 'Score']].sort_values(by='Score')
print("\nChained operations (Age > 25, select columns, sort):\n", result)
      </code>
    </program>
    <p>
      Visualize the score distribution:
    </p>
    <figure xml:id="fig-pandas-histogram">
      <caption>Histogram of student scores using Pandas and Matplotlib.</caption>
      <image source="./images/essential-probability-and-statistics/pandas-histogram.png">
        <shortdescription>Histogram from Pandas DataFrame.</shortdescription>
      </image>
    </figure>
    <program language="python" line-numbers="yes">
      <title>Generating histogram from Pandas</title>
      <code>
import matplotlib.pyplot as plt
import pandas as pd

# Assuming df from previous code
df['Score'].hist(bins=5, edgecolor='black', alpha=0.7)
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.title('Distribution of Student Scores')
plt.grid(True, alpha=0.3)
plt.savefig('pandas-histogram.png', dpi=300)
plt.show()
      </code>
    </program>
    <p>
      For further learning, explore <url href="https://wesmckinney.com/book/" visual="wesmckinney.com">Python for Data Analysis</url> by Wes McKinney (free online) and <url href="https://www.kaggle.com/learn/pandas" visual="kaggle.com">Kaggle’s Pandas course</url>.
    </p>
  </subsection>
  <subsection xml:id="subsec-Visualization">
    <title>Visualization with Matplotlib and Seaborn</title>
    <p>
      Visualization is a cornerstone of EDA, making patterns and relationships in data intuitive. Matplotlib provides customizable, low-level plotting, while Seaborn, built on Matplotlib, offers high-level statistical visualizations with attractive defaults.
    </p>
    <p>
      <alert>Matplotlib Key Features:</alert>
      <ul>
        <li>Flexible plots: histograms, boxplots, scatter plots, line plots.</li>
        <li>Customizable axes, labels, and styles.</li>
        <li>Integration with Pandas for direct plotting.</li>
      </ul>
    </p>
    <p>
      <alert>Seaborn Advantages:</alert>
      <ul>
        <li>Statistical plots: histplot with KDE, boxplot, pairplot for correlations.</li>
        <li>Attractive themes and color palettes.</li>
        <li>Simplified syntax for complex visualizations.</li>
      </ul>
    </p>
    <p>
      <alert>Example: Visualizing Student Data</alert> Using the student DataFrame, create a histogram and boxplot with Matplotlib, and a histplot with KDE and pairplot with Seaborn.
    </p>
    <figure xml:id="fig-matplotlib-plots">
      <caption>Matplotlib histogram and boxplot of student scores.</caption>
      <image source="./images/essential-probability-and-statistics/matplotlib-plots.png">
        <shortdescription>Matplotlib plots from Pandas.</shortdescription>
      </image>
    </figure>
    <program language="python" line-numbers="yes">
      <title>Matplotlib histogram and boxplot</title>
      <code>

import matplotlib.pyplot as plt
import pandas as pd

# Assuming df from previous code
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))
df['Score'].hist(bins=5, ax=ax1, edgecolor='black', alpha=0.7)
ax1.set_title('Histogram of Scores')
ax1.set_xlabel('Score')
ax1.set_ylabel('Frequency')
ax1.grid(True, alpha=0.3)

df.boxplot(column='Score', ax=ax2)
ax2.set_title('Boxplot of Scores')
ax2.set_ylabel('Score')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('matplotlib-plots.png', dpi=300)
plt.show()

      </code>
    </program>
    <figure xml:id="fig-seaborn-plots">
      <caption>Seaborn histplot with KDE and pairplot of student data.</caption>
      <image source="./images/essential-probability-and-statistics/seaborn-plots.png">
        <shortdescription>Seaborn plots from Pandas.</shortdescription>
      </image>
    </figure>
    <program language="python" line-numbers="yes">
      <title>Seaborn histplot and pairplot</title>
      <code>
# --- NEW CODE FOR SEABORN PLOTS ---
import seaborn as sns
import pandas as pd

# Assuming df from previous code
sns.set_theme(style="whitegrid")
fig, ax = plt.subplots(figsize=(8, 5))
sns.histplot(df['Score'], kde=True, ax=ax)
ax.set_title('Histogram with KDE of Scores')
ax.set_xlabel('Score')
ax.set_ylabel('Count')
plt.savefig('seaborn-histplot.png', dpi=300)
plt.show()

# Pairplot for relationships
sns.pairplot(df[['Age', 'Score']], diag_kind='kde')
plt.savefig('seaborn-pairplot.png', dpi=300)
plt.show()
# --- END NEW CODE ---
      </code>
    </program>
    <p>
      <alert>Real-World Example:</alert> Load a larger dataset (e.g., from Kaggle) and visualize distributions and correlations.
    </p>
    <program language="python" line-numbers="yes">
      <title>EDA with a larger dataset</title>
      <code>

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sample larger dataset (simulated for book)
np.random.seed(42)
n = 100
data = pd.DataFrame({
    'Age': np.random.normal(25, 5, n),
    'Score': np.random.normal(85, 10, n),
    'Hours_Studied': np.random.normal(20, 5, n)
})
data['Score'] = data['Score'].clip(0, 100)  # Ensure valid scores

# Basic EDA
print(data.describe())
print("\nMissing values:\n", data.isnull().sum())

# Correlation matrix
print("\nCorrelation matrix:\n", data.corr())

# Visualization
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
sns.histplot(data['Score'], kde=True)
plt.title('Distribution of Scores')
plt.subplot(1, 2, 2)
sns.scatterplot(x='Hours_Studied', y='Score', data=data)
plt.title('Score vs. Hours Studied')
plt.tight_layout()
plt.savefig('./images/essential-probability-and-statistics/eda-large-dataset.png', dpi=300)
plt.show()

# Pairplot
sns.pairplot(data, diag_kind='kde')
plt.savefig('./images/essential-probability-and-statistics/eda-pairplot.png', dpi=300)
plt.show()

      </code>
    </program>
    <figure xml:id="fig-eda-large-dataset">
      <caption>EDA on a larger dataset: histogram and scatter plot.</caption>
      <image source="./images/essential-probability-and-statistics/eda-large-dataset.png">
        <shortdescription>EDA visualizations for larger dataset.</shortdescription>
      </image>
    </figure>
    <figure xml:id="fig-eda-pairplot">
      <caption>Pairplot showing relationships in larger dataset.</caption>
      <image source="./images/essential-probability-and-statistics/eda-pairplot.png">
        <shortdescription>Pairplot for larger dataset.</shortdescription>
      </image>
    </figure>
  </subsection>
  <conclusion>
    <p>
      NumPy, Pandas, Matplotlib, and Seaborn form a powerful toolkit for EDA. Start with NumPy for numerical operations, use Pandas for data manipulation and cleaning, and leverage Matplotlib/Seaborn for insightful visualizations. Practice with real datasets (e.g., from Kaggle) in Jupyter notebooks to build skills. For advanced machine learning pipelines, you can explore TensorFlow’s Data API later, but mastering these foundational tools is key for beginners. Resources like <url href="https://wesmckinney.com/book/" visual="wesmckinney.com">Python for Data Analysis</url> and <url href="https://www.kaggle.com/learn/pandas" visual="kaggle.com">Kaggle’s Pandas course</url> offer hands-on learning.
    </p>
  </conclusion>
</section>