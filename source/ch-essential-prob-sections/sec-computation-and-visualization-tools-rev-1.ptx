<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="sec-useful-descriptive-statistics-tools" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Computation and Visualization Tools</title>
  <introduction>
    <p>
      Exploratory Data Analysis (EDA) is a critical step in understanding your data before applying advanced techniques like machine learning. It involves summarizing the main characteristics of a dataset, often using visual methods, to uncover patterns, spot anomalies, test hypotheses, and check assumptions. 
    </p>  
    <p>
      In this section, we focus on Python-based tools that enable efficient and effective data analysis, tailored for machine learning workflows. While languages like R are powerful for statistics, we emphasize Python due to its widespread use in data science and machine learning communities. Key tools include NumPy for numerical computations, Pandas for data manipulation, and Matplotlib/Seaborn for visualization. These libraries integrate seamlessly, allowing you to load, clean, analyze, and visualize data in a streamlined manner.
    </p>
    <p>
      A typical EDA workflow includes: loading data, inspecting its structure, handling missing values, computing summary statistics, exploring distributions, and visualizing relationships. Using Jupyter notebooks ensures reproducibility and documentation of your analysis.
    </p>
  </introduction>
<subsection>
    <title>The Power of NumPy and SciPy</title>

    <p>
        While Python lists and loops are flexible, they are slow for large-scale numerical work. 
        The <c>NumPy</c> library provides fast, memory-efficient arrays and vectorized operations. 
        These make Python competitive with lower-level languages for scientific and machine learning tasks. 
        The <c>SciPy</c> library builds on NumPy, adding advanced tools for statistics, optimization, and more. 
    </p>

    <p>
        Let us begin with a simple example: computing descriptive statisticsand plotting a histogram (<xref ref="fig-np-die-histogram"/>) of rolls of a six-sided die. Notice that NumPy computes the mean and standard deviation in a single line. 
        This would require explicit loops in plain Python.
    </p>

    <program language="python">
    import numpy as np
    import matplotlib.pyplot as plt
    #Set Seed for reproducibility
    np.random.seed(seed=42)
    # Generate 10,000 simulated die rolls
    rolls = np.random.randint(1, 7, size=50)
    mean = np.mean(rolls)
    std = np.std(rolls)
    print(f"mean = {mean}, std = {std}") #(np.float64(3.4999), np.float64(1.7086251753968744))

    fig, ax = plt.subplots()

    ax.hist(rolls, bins=6, color="b", alpha=0.25)

    
    plt.xlabel('Face Value')
    plt.ylabel('Frequency')
    plt.title('Histogram of Die Rolls')
    plt.savefig("np-die-histogram.png")
    plt.show()
    </program>
        <figure xml:id="fig-np-die-histogram">
          <caption>Histogram of simulated die rolls using NumPy.</caption>
          <image source="./images/essential-probability-and-statistics/np-die-histogram.png">
            <shortdescription>Histogram of simulated die rolls using NumPy.</shortdescription>
          </image>
        </figure>
 

    <p>
        The real strength of NumPy comes from <term>vectorization</term>, which eliminates explicit loops.
    </p>

    <program language="python">
      <code>
      import time

      N = 10_000_000
      x = np.random.rand(N)

      # Vectorized: compute sum of squares
      t0 = time.time()
      s1 = np.sum(x**2)
      t1 = time.time()

      # Loop version
      s2 = 0.0
      for xi in x:
          s2 += xi**2
      t2 = time.time()

      (t1 - t0, t2 - t1)   # compare runtimes
      </code>
    </program>

    <p>
        The vectorized NumPy version runs in milliseconds, while the loop can take seconds. 
        This difference is crucial in machine learning, where datasets often have millions of entries.
    </p>

    <figure xml:id="fig-np-vectorization_timing">
        <caption>Vectorized NumPy operation vs. Python loop runtime.</caption>
        <image source="./images/essential-probability-and-statistics/vectorization_timing.png"/>
    </figure>

    <p>
        NumPy also includes a <c>linalg</c> package for linear algebra. The following code snippet demonstrates how NumPy solves systems of equations and computes eigenvalues—core operations in data science, physics, and engineering.
    </p>

    <program language="python">
      <code>
      A = np.array([[3, 1], [1, 2]])
      b = np.array([9, 8])

      # Solve Ax = b
      x = np.linalg.solve(A, b)

      # Eigenvalues and eigenvectors
      e_vals, e_vecs = np.linalg.eig(A)
      (x, e_vals)]
      </code>
    </program>
 

    <p>
        For advanced tasks, <c>SciPy</c> extends NumPy. For example, hypothesis testing or optimization. SciPy provides one-line solutions for statistical inference and numerical optimization.
    </p>
    <program language="python" line-numbers="yes">
      <code>
        from scipy import stats, optimize
        # Hypothesis test: is sample mean = 0?
        sample = np.random.normal(0, 1, size=100)
        t_stat, p_val = stats.ttest_1samp(sample, 0)
        print(f"t-statistic = {t_stat}, p-value={p_val}")
        # t-statistic = 0.8998073723146639, p-value=0.37040629150553495
      </code>
    </program>
    <program language="python" line-numbers="yes">
      <code>
        from scipy import stats, optimize
        # Optimization: minimize f(x) = (x-3)^2
        f = lambda x: (x-3)**2
        res = optimize.minimize(f, x0=0) # [2.99999998]
      </code>
    </program>


    <p>
         
        Together, NumPy and SciPy form the numerical backbone of Python’s scientific ecosystem. 
    </p>

</subsection>

  <subsection xml:id="subsec-Pandas">
    <title>Pandas: Data Manipulation and Analysis</title>
    <introduction>
      <p>
        Pandas is a powerful, flexible library for data manipulation and analysis, built on NumPy. Its core data structures are:
        <ol>
          <li><alert>Series</alert>: A one-dimensional labeled array for sequences of data.</li>
          <li><alert>DataFrame</alert>: A two-dimensional labeled table, similar to a spreadsheet or SQL table, ideal for tabular data.</li>
        </ol>
      </p>
      <p>
        Pandas is designed for cleaning, transforming, analyzing, and visualizing data. It supports multiple file formats (CSV, Excel, JSON, SQL) and integrates with NumPy, Matplotlib, Seaborn, and Scikit-learn, making it a cornerstone for EDA in machine learning.
      </p>
    </introduction>
    <p>
      <alert>Why Use Pandas?</alert>
      <ul>
        <li>Handles structured data efficiently (e.g., tabular data).</li>
        <li>Supports data cleaning (missing values, duplicates, outliers).</li>
        <li>Enables grouping, aggregation, and statistical summaries.</li>
        <li>Scales to large datasets with optimized performance.</li>
      </ul>
    </p>
    <p>
      <alert>EDA Workflow with Pandas:</alert>
      <ol>
        <li>Load data (<c>pd.read_csv()</c>, <c>pd.read_excel()</c>).</li>
        <li>Inspect structure (<c>head()</c>, <c>info()</c>, <c>describe()</c>).</li>
        <li>Clean data (handle missing values, remove duplicates).</li>
        <li>Compute statistics and explore distributions.</li>
        <li>Visualize (integrate with Matplotlib/Seaborn).</li>
      </ol>
    </p>
    <p>
      <alert>Example: Analyzing Student Data</alert> Let’s use a realistic dataset of student scores, including a missing value, loaded from a CSV file.
    </p>
    <program language="python" line-numbers="yes">
      <title>Creating and loading sample student data</title>
      <code>
import pandas as pd

# Create sample CSV data (in practice, load from disk)
data = """Name,Age,Score,Passed
Alice,25,85.5,True
Bob,30,90.0,True
Carol,27,88.0,True
Dave,22,76.5,False
Eve,28,,True"""

with open('students.csv', 'w') as f:
    f.write(data)

# Load data
df = pd.read_csv('students.csv')
print(df)
      </code>
    </program>
    <p>
      Output as a table:
    </p>
    <table xml:id="tab-students-dataframe">
      <title>Student DataFrame</title>
      <tabular>
        <row header="yes">
          <cell>Name</cell> <cell>Age</cell> <cell>Score</cell> <cell>Passed</cell>
        </row>
        <row>
          <cell>Alice</cell> <cell>25</cell> <cell>85.5</cell> <cell>True</cell>
        </row>
        <row>
          <cell>Bob</cell> <cell>30</cell> <cell>90.0</cell> <cell>True</cell>
        </row>
        <row>
          <cell>Carol</cell> <cell>27</cell> <cell>88.0</cell> <cell>True</cell>
        </row>
        <row>
          <cell>Dave</cell> <cell>22</cell> <cell>76.5</cell> <cell>False</cell>
        </row>
        <row>
          <cell>Eve</cell> <cell>28</cell> <cell>NaN</cell> <cell>True</cell>
        </row>
      </tabular>
    </table>
    <p>
      Inspect the data using common Pandas methods:
    </p>
    <program language="python" line-numbers="yes">
      <title>Inspecting DataFrame</title>
      <code>
# Inspect data
print("First 3 rows:")
print(df.head(3))
print("\nLast 2 rows:")
print(df.tail(2))
print("\nShape:", df.shape)  # (5, 4)
print("\nColumns:", df.columns.tolist())
print("\nInfo:")
print(df.info())
print("\nDescriptive Statistics:")
print(df.describe())
      </code>
    </program>
    <p>
      Output of <c>df.describe()</c>:
    </p>
    <table xml:id="tab-students-describe">
      <title>Descriptive Statistics from df.describe()</title>
      <tabular>
        <row header="yes">
          <cell></cell> <cell>Age</cell> <cell>Score</cell>
        </row>
        <row>
          <cell>count</cell> <cell>5.000000</cell> <cell>4.000000</cell>
        </row>
        <row>
          <cell>mean</cell> <cell>26.400000</cell> <cell>85.000000</cell>
        </row>
        <row>
          <cell>std</cell> <cell>3.209361</cell> <cell>5.958188</cell>
        </row>
        <row>
          <cell>min</cell> <cell>22.000000</cell> <cell>76.500000</cell>
        </row>
        <row>
          <cell>25%</cell> <cell>24.250000</cell> <cell>83.250000</cell>
        </row>
        <row>
          <cell>50%</cell> <cell>26.000000</cell> <cell>86.750000</cell>
        </row>
        <row>
          <cell>75%</cell> <cell>27.750000</cell> <cell>88.500000</cell>
        </row>
        <row>
          <cell>max</cell> <cell>30.000000</cell> <cell>90.000000</cell>
        </row>
      </tabular>
    </table>
    <p>
      Clean and transform the data (e.g., handle missing values, filter, add columns, group, sort):
    </p>
    <program language="python" line-numbers="yes">
      <title>Data cleaning and transformation</title>
      <code>
# Handle missing values
print("Missing values:\n", df.isnull())
df['Score'] = df['Score'].fillna(df['Score'].mean())  # Fill NaN with mean

# Filter rows
high_scorers = df[df['Score'] > 85]
print("\nHigh scorers:\n", high_scorers)

# Add new column
df['Grade'] = df['Score'].apply(lambda x: 'A' if x >= 90 else 'B' if x >= 80 else 'C')
print("\nDataFrame with Grade:\n", df)

# Group and aggregate
grouped = df.groupby('Passed')['Score'].agg(['mean', 'count'])
print("\nGrouped by Passed:\n", grouped)

# Sort by Score
df_sorted = df.sort_values(by='Score', ascending=False)
print("\nSorted by Score:\n", df_sorted)

# Chain operations
result = df[df['Age'] > 25][['Name', 'Score']].sort_values(by='Score')
print("\nChained operations (Age > 25, select columns, sort):\n", result)
      </code>
    </program>
    <p>
      Visualize the score distribution:
    </p>
    <figure xml:id="fig-pandas-histogram">
      <caption>Histogram of student scores using Pandas and Matplotlib.</caption>
      <image source="./images/essential-probability-and-statistics/pandas-histogram.png">
        <shortdescription>Histogram from Pandas DataFrame.</shortdescription>
      </image>
    </figure>
    <program language="python" line-numbers="yes">
      <title>Generating histogram from Pandas</title>
      <code>
import matplotlib.pyplot as plt
import pandas as pd

# Assuming df from previous code
df['Score'].hist(bins=5, edgecolor='black', alpha=0.7)
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.title('Distribution of Student Scores')
plt.grid(True, alpha=0.3)
plt.savefig('pandas-histogram.png', dpi=300)
plt.show()
      </code>
    </program>
    <p>
      For further learning, explore <url href="https://wesmckinney.com/book/" visual="wesmckinney.com">Python for Data Analysis</url> by Wes McKinney (free online) and <url href="https://www.kaggle.com/learn/pandas" visual="kaggle.com">Kaggle’s Pandas course</url>.
    </p>
  </subsection>
  <subsection xml:id="subsec-Visualization">
    <title>Visualization with Matplotlib and Seaborn</title>
    <p>
      Visualization is a cornerstone of EDA, making patterns and relationships in data intuitive. Matplotlib provides customizable, low-level plotting, while Seaborn, built on Matplotlib, offers high-level statistical visualizations with attractive defaults.
    </p>
    <p>
      <alert>Matplotlib Key Features:</alert>
      <ul>
        <li>Flexible plots: histograms, boxplots, scatter plots, line plots.</li>
        <li>Customizable axes, labels, and styles.</li>
        <li>Integration with Pandas for direct plotting.</li>
      </ul>
    </p>
    <p>
      <alert>Seaborn Advantages:</alert>
      <ul>
        <li>Statistical plots: histplot with KDE, boxplot, pairplot for correlations.</li>
        <li>Attractive themes and color palettes.</li>
        <li>Simplified syntax for complex visualizations.</li>
      </ul>
    </p>
    <p>
      <alert>Example: Visualizing Student Data</alert> Using the student DataFrame, create a histogram and boxplot with Matplotlib, and a histplot with KDE and pairplot with Seaborn.
    </p>
    <figure xml:id="fig-matplotlib-plots">
      <caption>Matplotlib histogram and boxplot of student scores.</caption>
      <image source="./images/essential-probability-and-statistics/matplotlib-plots.png">
        <shortdescription>Matplotlib plots from Pandas.</shortdescription>
      </image>
    </figure>
    <program language="python" line-numbers="yes">
      <title>Matplotlib histogram and boxplot</title>
      <code>

import matplotlib.pyplot as plt
import pandas as pd

# Assuming df from previous code
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))
df['Score'].hist(bins=5, ax=ax1, edgecolor='black', alpha=0.7)
ax1.set_title('Histogram of Scores')
ax1.set_xlabel('Score')
ax1.set_ylabel('Frequency')
ax1.grid(True, alpha=0.3)

df.boxplot(column='Score', ax=ax2)
ax2.set_title('Boxplot of Scores')
ax2.set_ylabel('Score')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('matplotlib-plots.png', dpi=300)
plt.show()

      </code>
    </program>

    <p>
      <alert>Real-World Example:</alert> Load a larger dataset (e.g., from Kaggle) and visualize distributions and correlations.
    </p>
    <program language="python" line-numbers="yes">
      <title>EDA with a larger dataset</title>
      <code>

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sample larger dataset (simulated for book)
np.random.seed(42)
n = 100
data = pd.DataFrame({
    'Age': np.random.normal(25, 5, n),
    'Score': np.random.normal(85, 10, n),
    'Hours_Studied': np.random.normal(20, 5, n)
})
data['Score'] = data['Score'].clip(0, 100)  # Ensure valid scores

# Basic EDA
print(data.describe())
print("\nMissing values:\n", data.isnull().sum())

# Correlation matrix
print("\nCorrelation matrix:\n", data.corr())

# Visualization
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
sns.histplot(data['Score'], kde=True)
plt.title('Distribution of Scores')
plt.subplot(1, 2, 2)
sns.scatterplot(x='Hours_Studied', y='Score', data=data)
plt.title('Score vs. Hours Studied')
plt.tight_layout()
plt.savefig('./images/essential-probability-and-statistics/eda-large-dataset.png', dpi=300)
plt.show()

# Pairplot
sns.pairplot(data, diag_kind='kde')
plt.savefig('./images/essential-probability-and-statistics/eda-pairplot.png', dpi=300)
plt.show()

      </code>
    </program>
    <figure xml:id="fig-eda-large-dataset">
      <caption>EDA on a larger dataset: histogram and scatter plot.</caption>
      <image source="./images/essential-probability-and-statistics/eda-large-dataset.png">
        <shortdescription>EDA visualizations for larger dataset.</shortdescription>
      </image>
    </figure>
    <figure xml:id="fig-eda-pairplot">
      <caption>Pairplot showing relationships in larger dataset.</caption>
      <image source="./images/essential-probability-and-statistics/eda-pairplot.png">
        <shortdescription>Pairplot for larger dataset.</shortdescription>
      </image>
    </figure>
  </subsection>
  <conclusion>
    <p>
      NumPy, Pandas, Matplotlib, and Seaborn form a powerful toolkit for EDA. Start with NumPy for numerical operations, use Pandas for data manipulation and cleaning, and leverage Matplotlib/Seaborn for insightful visualizations. Practice with real datasets (e.g., from Kaggle) in Jupyter notebooks to build skills. For advanced machine learning pipelines, you can explore TensorFlow’s Data API later, but mastering these foundational tools is key for beginners. Resources like <url href="https://wesmckinney.com/book/" visual="wesmckinney.com">Python for Data Analysis</url> and <url href="https://www.kaggle.com/learn/pandas" visual="kaggle.com">Kaggle’s Pandas course</url> offer hands-on learning.
    </p>
  </conclusion>
</section>