<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="sec-Basic-Probability">
    <title>Basic Probability for Machine Learning</title>
    <introduction>
        <p>
            Probability is the backbone of machine learning, helping us model uncertainty in data, predictions, and outcomes. In machine learning, probability underpins tasks like classification (e.g., predicting labels), evaluating model confidence, and handling noisy data. This section introduces probability concepts such as sample spaces, events, and axioms—and connects them to practical machine learning applications using Python. 
        </p>
        <p>
            An <alert>event</alert> is a specific outcome or set of outcomes from an experiment, represented as a set. For a coin toss, "heads" is <m>\{H\}</m>, "tails" is <m>\{T\}</m>, and "heads or tails" is <m>\{H, T\}</m>. Each trial answers whether an event occurred (yes/no). For a die roll yielding <m>2</m>, events like <m>\{2\}</m> or <m>\{1,2,3\}</m> occur if they include <m>2</m>. Sets allow combining events via union (<m>\cup</m>) or intersection (<m>\cap</m>), such as <m>\{H\} \cup \{T\} = \{H, T\}</m>.
        </p>
    </introduction>
    <subsection xml:id="subsec-Axiomatic-View-of-Probability">
        <title>Axiomatic View of Probability</title>
        <p>
            In 1933, Andrey Kolmogorov formalized probability with three axioms, providing a mathematical framework. Think of these as rules that ensure probabilities make sense, like ensuring a weather forecast never predicts negative rain or more than <m>100\%</m> chance.
        </p>
        <p>
            <alert>Sample Space <m>\Omega</m></alert>: The set of all possible outcomes. For a six-sided die, <m>\Omega = \{1, 2, 3, 4, 5, 6\}</m>. For a student passing an exam, <m>\Omega = \{\text{Pass}, \text{Fail}\}</m>.
        </p>
        <p>
            <alert>Event Space <m>F</m></alert>: All possible subsets of <m>\Omega</m>, including the empty set <m>\varnothing</m> (impossible event) and <m>\Omega</m> (event certain to happen). For a coin toss (<m>\Omega = \{H, T\}</m>), <m>F = \{\varnothing, \{H\}, \{T\}, \{H, T\}\}</m>. With <m>N</m> outcomes, <m>F</m> has <m>2^N</m> events.
        </p>
        <p>
            With every event <m>E</m> we can identify its complementary event or complement <m>E^c</m>. The complementary event <m>E^c</m> includes all other possibilities that excluded the event <m>E</m>. Thus, in a six-sided die, say <m>E = \{ 1, 3, 4 \}</m>. Its complement will be the event <m>E^c = \{ 2, 5, 6\}</m>. Clearly, their intersection will be the null event.
            <me>
                E \cap E^c = \varnothing.
            </me>
            
        </p>
        <p>
            <alert>Probability Measure <m>P</m></alert>: Assigns a number <m>P(E)</m> to each event <m>E \in F</m>, representing its likelihood. For example, for a fair die, <m>P(\{1\}) = 1/6</m>. You only need <m>P</m> for elementary events, which are the elements of <m>\Omega</m>, each taken as one event since you can use the Aditivity law below to get probability of any event in the entire event space <m>F</m>.
        </p>
        <p>
            The probability space is the triplet <m>(\Omega, F, P)</m>. Kolmogorov’s axioms are:
            <ol marker="1">
                <li><alert>Non-negativity</alert>: Although, negative probabilities may be taunting science fiction scenarios, they do not make sense in the probailities we deal with everyday. We require that
                    <men xml:id="eqn-first-axiom-non-negativity">
                        P(E) \ge 0 \text{ for all } E \in F.
                    </men>
                </li>
                <li><alert>Normalization</alert>: Since the event <m>\Omega</m> has all possible elementary events, except the null event, every possible event is inculded in <m>\Omega</m>. Therefor, <m>\Omega</m> is called event of <m>100\%</m> certainty. Thus,
                    <men xml:id="eqn-second-axiom-normalization">
                        P(\Omega) = 1</men>, 
                    ensures total certainty for event <m>\Omega</m>. This is why although frequencies are proportional to probabilities, we need to divide them by total number of trials to convert them into normalized probabilities. 
                </li>
                <li><alert>Additivity</alert>: If two events that are disjoint, i.e., there is no situation in which both events can occur together, i.e, <m>E_1 \cap E_2 = \varnothing</m>), the probability of either of them occuring, i.e., their union, must be sum of the probabilities of the events occuring separately.  
                <men xml:id="eqn-third-axiom-additivity">
                    P(E_1 \cup E_2) = P(E_1) + P(E_2),\quad \text{ if } E_1 \cap E_2 = \varnothing.
                </men>.
                Of course, if there was an overlap, between the two events, then, we would need to subtrat the overlap part since that would have been counted twice, once in <m>E_1</m> and another time in <m>E_2</m>.
                <men xml:id="eqn-sum-rule-as-fundamental">
                    P(E_1 \cup E_2) = P(E_1) + P(E_2) - P(E_1 \cap E_2).
                </men>
                
                
                </li>
            </ol>
        </p>
        <p>
            Derived results:
            <mdn>
                <mrow> \amp P(\varnothing) = 0. </mrow>
                <mrow> \amp P(E^c) = 1 - P(E), \text{ where } E^c \text{ is the complement of } E. </mrow>
                <mrow> \amp P(E_1 \cup E_2) = P(E_1) + P(E_2) - P(E_1 \cap E_2). </mrow>
            </mdn>
        </p>
        <p>
            
            <xref ref="fig-venn-diagram-E1-E2"/> illustrated the union formula in which two events <m>E_1 = \{1,3,5\}</m> (odd numbers), <m>E_2 = \{3,5,6\}</m> have an overlap. Theoretically,
            <me>
                P(E_1 \cup E_2) = P(\{1,3,5,6\}) = 4/6 = 2/3.
            </me>
            Let's see how it plays out in the <m>1000</m> rolls simulation shown in <xref ref="fig-venn-diagram-E1-E2"/>. The left region <m>(181)</m> counts rolls of <m>1</m> (in <m>E_1</m> only), the right region <m>(155)</m> counts rolls of <m>6</m> (in <m>E_2</m> only), the overlap <m>(326)</m> counts rolls of <m>3 \text{ or } 5</m> (in <m>E_1 \cap E_2</m>), and a total of <m>622</m> counts for <m>1\text{ or } 3 \text{ or } 5 \text{ or } 6</m>. From these counts we estimate probabilities. The counts <m>f_{E_1} = 181+326 = 507</m>, <m>f(E_2) = 155+326 = 481</m>, <m>f_{E_1 \cap E_2} = 326</m> and <m>f_{E_1 \cup E_2} = 622</m> in total rolls <m>N = 1000</m>.  From these counts we get
            <md>
                <mrow>\amp \hat{P}(E_1) = \frac{507}{1000} = 0.507 </mrow>
                <mrow>\amp \hat{P}(E_2) = \frac{481}{1000} = 0.481 </mrow>
                <mrow>\amp \hat{P}(E_1 \cap E_2) = \frac{326}{1000} = 0.326 </mrow>
                <mrow>\amp \hat{P}(E_1 \cup E_2) = \frac{622}{1000} = 0.622 </mrow>
            </md>
            Now let's check
            <me>
                \hat{P}(E_1) + \hat{P}(E_2) - \hat{P}(E_1 \cap E_2)= 0.507 + 0.481 - 0.326 = 0.662 =  \hat{P}(E_1 \cup E_2).
            </me>
        </p>
        <figure xml:id="fig-venn-diagram-E1-E2">
            <caption>Venn diagram illustrating events <m>E_1 = \{1,3,5\}</m> (odd numbers) and <m>E_2 = \{3,5,6\}</m> for 1,000 simulated rolls of a fair six-sided die. The code of the simulation is given below. </caption>
            <image source="./images/essential-probability-and-statistics/venn-diagram-E1-E2.png">
                <shortdescription>Venn diagram of intersecting events.</shortdescription>
            </image>
        </figure>
        <program language="python" line-numbers="yes">
            <title>Simulating die roll for union probability</title>
            <code>
            # --- DIE ROLL VENN DIAGRAM ---
            import numpy as np
            from matplotlib_venn import venn2
            import matplotlib.pyplot as plt

            np.random.seed(42)
            n_trials = 1000
            rolls = np.random.randint(1, 7, n_trials)

            # Events
            e1 = np.isin(rolls, [1, 3, 5])  # Odd numbers
            e2 = np.isin(rolls, [3, 5, 6])  # 3,5,6
            e1_only = np.sum(e1 \amp; ~e2)
            e2_only = np.sum(e2 \amp; ~e1)
            both = np.sum(e1 \amp; e2)

            # Venn diagram
            plt.figure(figsize=(6, 4))
            venn2(subsets=(e1_only, e2_only, both), set_labels=('E1 (Odd)', 'E2 (3,5,6)'))
            plt.title('Venn Diagram of Die Roll Events')
            plt.savefig('venn-diagram-E1-E2.png', dpi=300)
            plt.show()

            # Probabilities
            p_e1 = np.mean(e1)
            p_e2 = np.mean(e2)
            p_inter = np.mean(e1 \amp; e2)
            p_union = np.mean(e1 | e2)
            print(f"P(E1): {p_e1:.3f}, P(E2): {p_e2:.3f}, P(E1 ∩ E2): {p_inter:.3f}, P(E1 ∪ E2): {p_union:.3f}")
            # --- END CODE ---
            </code>
        </program>
    </subsection>

    <subsection xml:id="subsec-sum-product-rules">
    <title>Sum and Product Rules for Probability</title>
    <p>
        The sum and product rules are two cornerstones of probability theory. They allow us to compute probabilities of unions and intersections of events, which are essential in many machine learning applications, from estimating marginal distributions to building classifiers.
    </p>

    <p>
        <alert>Sum Rule</alert>: The probability of the union of two events <m>A</m> and <m>B</m> is given by:
        <men xml:id="eqn-sum-rule">P(A \cup B) = P(A) + P(B) - P(A \cap B).</men>
        The subtraction of <m>P(A \cap B)</m> avoids double-counting the overlap between the two events. This can be clearly understood using a Venn diagram.
    </p>

    <figure xml:id="fig-venn-sum-rule">
        <caption>Illustration of the sum rule. The probability of <m>A \cup B</m> is the sum of the shaded areas of <m>A</m> and <m>B</m>, minus the overlapping region <m>A \cap B</m> that would otherwise be counted twice.</caption>
        <image source="./images/essential-probability-and-statistics/sum-rule-venn.png">
        <shortdescription>Venn diagram showing the sum rule for two overlapping events.</shortdescription>
        </image>
    </figure>

    <p>
        <alert>Product Rule</alert>: The joint probability of two events <m>A</m> and <m>B</m> is:
        <men xml:id="eqn-product-rule">P(A \cap B) = P(A|B)P(B),</men>
        where <m>P(A|B)</m> is the conditional probability of <m>A</m> given <m>B</m>. This factorization is the basis for probabilistic models such as Naive Bayes.
    </p>

    </subsection>



    <subsection xml:id="subsec-conditional-probability-independence">
        <title>Conditional Probability and Independence</title>

        <p>
            <alert>Conditional Probability</alert>: The probability of an event <m>A</m> given that event <m>B</m> has occurred is written as
            <men xml:id="eqn-conditional-prob-defn">
            P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \text{ provided that } P(B) \gt; 0
            </men>.  
            Intuitively, this represents <em>updating our belief about <m>A</m></em> once we know that <m>B</m> is true.  
            For instance, the probability that a student passes an exam may be different depending on whether we already know they studied more than 20 hours.
        </p>
        <example><title>Probability of King if the Card is known to be Spade</title>
            <p>
                Imagine we have a standard deck of 52 playing cards.  
                Event <m>A</m> = "the card is a King".  
                Event <m>B</m> = "the card is a Spade".  
            </p>
            <p>
                The unconditional probability of drawing a King is <m>P(A) = 4/52 = 1/13</m>.  
                But suppose we are told that the card drawn is a Spade. Now, the sample space is only 13 Spade cards.  
                Out of these, exactly one is a King (the King of Spades).  
            </p>
            <p>
                Thus the conditional probability is
                <m>P(A \mid B) = \tfrac{1}{13}</m>, which differs from <m>P(A)</m>.  
                This illustrates how new information (that the card is a Spade) changes the probability of <m>A</m>.
            </p>
        </example>

        <p>
            <alert>Independence</alert>: Two events <m>A</m> and <m>B</m> are independent if the occurrence of one does not affect the probability of the other.  
            Formally, the eventa <m>A</m> and <m>B</m> are independent if
            <men xml:id="eqn-independent-events-def">
                P(A \cap B) = P(A)P(B).\quad \Leftrightarrow\quad  A \text{ and } B \text{ independent}.
            </men>. 
            Equivalently, 
            <men xml:id="eqn-independent-events-def-2">
                P(A \mid B) = P(A)\text{ when } P(B) &gt; 0.\quad \Leftrightarrow\quad  A \text{ and } B \text{ independent}.
            </men>
            Independence means that knowing whether <m>B</m> occurred does not provide any new information about <m>A</m>.
        </p>

        <example><title>Tosses of a fair coin are independent</title>
            <p>
                Suppose we toss a fair coin twice. Let event <m>A</m> be "the first toss is Heads" and event <m>B</m> be "the second toss is Heads."  
                The sample space is <m>\{HH, HT, TH, TT\}</m>.
            </p>

            <p>
                We have <m>P(A) = 1/2</m>, <m>P(B) = 1/2</m>, and <m>P(A \cap B) = 1/4</m>.  
                Therefore, <m>P(A \cap B) = P(A)P(B)</m>, which means the events are independent.  
            </p>

            <p>
                Now let event <m>C</m> be "at least one toss is Heads."  
                Then <m>P(C) = 3/4</m>, <m>P(A \cap C) = 1/2</m>, and <m>P(A \mid C) = (1/2) / (3/4) = 2/3</m>.  
                But <m>P(A) = 1/2</m>, so <m>P(A \mid C) \neq P(A)</m>.  
                Thus, <m>A</m> and <m>C</m> are not independent.
            </p>
        </example>



    <p>
        <alert> Example (Student Study Data):</alert> 
    </p>  
    <p>  
        Suppose we record whether students studied more than 20 hours (High Study) and whether they passed an exam (Pass). Using the dataset below, we will estimate probabilities empirically:
        <ul>
            <li>
                <p>
                    <m>P(\text{Pass})</m>: overall fraction of students who passed,
                </p>
            </li>    
            <li>
                <p>
                    <m>P(\text{High Study})</m>: fraction who studied more than 20 hours,
                </p>
                
            </li>
            <li>
                <p>
                    <m>P(\text{Pass} \cap \text{High Study})</m>: fraction who both passed and studied more than 20 hours.
                </p>
            </li>
            <li>
                <p>
                    <m>P(\text{Pass} \mid \text{High Study})</m>: Just look at the students who studied more than 20 hours (High Study), what fraction Passed the exam (Pass).
                </p>
            </li>
        </ul>
        The sum rule gives <m>P(\text{Pass} \cup \text{High Study}) = P(\text{Pass}) + P(\text{High Study}) - P(\text{Pass} \cap \text{High Study})</m>.  
        The product rule verifies that <m>P(\text{Pass} \cap \text{High Study}) = P(\text{Pass}|\text{High Study})P(\text{High Study})</m>.
    </p>

    <program language="python" line-numbers="yes">
        <title>Sum and product rules with student data</title>
        <code>
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns

        np.random.seed(42)
        data = pd.DataFrame({
            "Hours_Studied": np.random.normal(20, 5, 200).clip(0, 40),
            "Passed": np.random.binomial(1, 0.7, 200)
        })
        data["High_Study"] = data["Hours_Studied"] > 20

        # Probabilities
        p_pass = data["Passed"].mean()
        p_high = data["High_Study"].mean()
        p_both = ((data["Passed"] == 1) \amp; (data["High_Study"] == True)).mean()
        p_union = p_pass + p_high - p_both
        p_conditional = p_both / p_high

        print(f"P(Pass) = {p_pass:.3f}")
        print(f"P(High Study) = {p_high:.3f}")
        print(f"P(Pass ∩ High Study) = {p_both:.3f}")
        print(f"P(Pass ∪ High Study) = {p_union:.3f}")
        print(f"P(Pass|High Study) * P(High Study) = {p_conditional:.3f} * {p_high:.3f} = {p_conditional * p_high:.3f}")

        # Visualize joint distribution
        joint_table = pd.crosstab(data["Passed"], data["High_Study"], normalize="all")
        sns.heatmap(joint_table, annot=True, cmap="Blues", fmt=".3f")
        plt.xlabel("High Study Hours (>20)")
        plt.ylabel("Pass (0=No, 1=Yes)")
        plt.title("Joint Probability of Pass and High Study Hours")
        plt.savefig("joint-probability-heatmap.png", dpi=300)
        plt.show()
        </code>
    </program>

    <figure xml:id="fig-joint-probability-heatmap">
        <caption>Joint probability table of passing and high study hours. Each cell represents <m>P(\text{Pass}, \text{High Study})</m>. Row and column sums recover marginals (<m>P(\text{Pass})</m> and <m>P(\text{High Study})</m>), illustrating the sum rule. The product rule is verified by comparing the joint probability with <m>P(\text{Pass}|\text{High Study})P(\text{High Study})</m>.</caption>
        <image source="./images/essential-probability-and-statistics/joint-probability-heatmap.png">
        <shortdescription>Heatmap of joint probabilities for pass and study hours.</shortdescription>
        </image>
    </figure>
    <p>
        Let's see how we can read the heatmap in <xref ref="fig-joint-probability-heatmap"/>. I will read by the rows first. Let us do notation 
        <md>
            <mrow> \amp x_1 = \text{Not Studied }\gt 20\text{ hr}, x_2 = \text{Studied }\gt 20\text{ hr}</mrow>
            <mrow> \amp y_1 = \text{Passed }, y_2 = \text{Not Passed }</mrow>
        </md>
        Then the joint probabilities in the heatmap are:
        <md>
            <mrow> \amp P(x_1, y_2) = 0.120,\qquad P(x_2, y_2) = 0.130</mrow>
            <mrow> \amp P(x_1, y_1) = 0.420,\qquad P(x_2, y_1) = 0.330</mrow>
        </md>
        First we will check that the total probaility is actually <m>1</m>.
        <me>
            0.120 + 0.130 + 0.420 + 0.330 = 1.000.
        </me>
        Great! Now, let us the probability of Passing the exam, whether you studied or not. This is asking for probability of <m>y_1</m> regardless of the <m>X</m> values; So, we need to sum ovr the <m>X</m> values.
        <me>
            P(\text{Pass}) = P(y1) = P(x_1, y_1) + P(x_2, y_1) = 0.420 + 0.330 = 0.750.
        </me>
        That's pretty high chance of passing. The chance of not passing will just be it's complement.
        <me>
            P(y_2) = 1 - P(y_1) = 1 - 0.750 = 0.250.
        </me>
        Now, what is the chance that a random student has actullay studied hard regardless of whatever happened in the test. That will be <m>P(x_2)</m>, which we can get from the joint probabilities by summing over the <m>Y</m> values while keeping the <m>X</m> values to <m>x_2</m>.
        <me>
            P(x_2) = P(x_2, y_1) + P(x_2, y_2) = 0.330 + 0.130 = 0.460.
        </me>
        That would mean the probability of a random student having not studied excessively is
        <me>
            P(x_1) = 1 - P(x_2) = 1 - 0.460 = 0.540.
        </me>
        Now, how about the conditional probabilities? From this heatmap, it is easy to get conditional probabilities. For instance, suppose we want to know <q>Had you studied more than 20 hrs <m>x_2</m>, wat would be your change of passing <m>(y_1)</m></q>
        <me>
            P(y_1 \mid x_2) = \frac{ P(x_2, y_1) }{ P(x_2)} = \frac{0.330}{0.460} = 0.717. 
        </me>
        Wow, this data produced by simulation showing us that had you studied excessively, your chance of passing the exam actually went down from <m>0.750</m> to <m>0.717</m>. Wild! Okay, now your turn of computing sme other conditional probabilities.
    </p>

    </subsection>
    
    <subsection xml:id="subsec-probability-distributions">
        <title>Probability Distributions</title>
        <p>
            Probability distributions describe how probabilities are distributed over outcomes. In machine learning, distributions model data or predictions.
        </p>
        <p>
            <alert>Bernoulli Distribution</alert>: Models a binary outcome (e.g., pass/fail) with probability <m>p</m>. For passing an exam, <m>P(\text{Pass}) = p</m>, <m>P(\text{Fail}) = 1-p</m>.
        </p>
        <p>
            <alert>Binomial Distribution</alert>: Counts successes in <m>n</m> independent Bernoulli trials. For 10 students, the number who pass follows a binomial distribution.
        </p>
        <program language="python" line-numbers="yes">
            <title>Binomial distribution for student passes</title>
            <code>
# --- BINOMIAL DISTRIBUTION ---
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import binom

n, p = 10, 0.7  # 10 students, P(Pass) = 0.7
k = np.arange(0, 11)
pmf = binom.pmf(k, n, p)

plt.bar(k, pmf)
plt.xlabel('Number of Passes')
plt.ylabel('Probability')
plt.title('Binomial Distribution (n=10, p=0.7)')
plt.grid(True, alpha=0.3)
plt.savefig('./images/essential-probability-and-statistics/binomial-dist.png', dpi=300)
plt.show()
# --- END CODE ---
            </code>
        </program>
        <figure xml:id="fig-binomial-dist">
            <caption>Bar plot of the binomial probability mass function (PMF) for the number of students passing an exam out of 10, with a pass probability <m>p=0.7</m>. Each bar represents the probability of <m>k</m> students passing, calculated as <m>P(k) = \binom{n}{k} p^k (1-p)^{n-k}</m>. The peak around 7 passes reflects the high likelihood of most students passing given <m>p=0.7</m>. This distribution is critical in machine learning for modeling binary outcomes, such as predicting the number of successful predictions in a classification task.</caption>
            <image source="./images/essential-probability-and-statistics/binomial-dist.png">
                <shortdescription>Bar plot of binomial distribution.</shortdescription>
            </image>
        </figure>
    </subsection>
    <subsection xml:id="subsec-three-types-of-probabilities">
        <title>Three Types of Probabilities</title>
        <p>
            Probability can be approached theoretically, empirically (frequentist), or subjectively (Bayesian).
        </p>
        <ol>
            <li>
                <p>
                    <alert>Theoretical Probability</alert>: Uses symmetry. For a fair die, <m>P(\{1\}) = 1/6</m>. For even numbers, <m>P(\{2,4,6\}) = 3/6 = 0.5</m>.
                </p>
            </li>
            <li>
                <p>
                    <alert>Frequentist Probability</alert>: Estimates probability from trial frequencies: <men xml:id="eqn-frequentist-probability-definition">p = \lim_{N \to \infty} \frac{n}{N}</men>.
                </p>
                <program language="python" line-numbers="yes">
                    <title>Frequentist estimation for fair and biased dice</title>
                    <code>
                    # --- FREQUENTIST SIMULATION ---
                    import numpy as np
                    import matplotlib.pyplot as plt

                    np.random.seed(42)
                    n_trials = 1000
                    fair_rolls = np.random.randint(1, 7, n_trials)
                    biased_rolls = np.random.choice([1, 2, 3, 4, 5, 6], n_trials, 
                                                    p=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1])

                    # Cumulative probabilities
                    cum_fair = np.cumsum(fair_rolls == 1) / np.arange(1, n_trials + 1)
                    cum_biased = np.cumsum(biased_rolls == 1) / np.arange(1, n_trials + 1)

                    plt.plot(cum_fair, label='Fair Die (P=1/6)')
                    plt.plot(cum_biased, label='Biased Die (P=0.2)')
                    plt.axhline(1/6, color='red', linestyle='--', label='Theoretical P=1/6')
                    plt.xlabel('Trials')
                    plt.ylabel('Estimated P(1)')
                    plt.title('Frequentist Estimates: Fair vs. Biased Die')
                    plt.legend()
                    plt.grid(True, alpha=0.3)
                    plt.savefig('frequentist-convergence.png', dpi=300)
                    plt.show()
                    # --- END CODE ---
                    </code>
                </program>
                <figure xml:id="fig-frequentist-convergence">
                    <caption>Plot showing the convergence of frequentist probability estimates for rolling a 1 on a fair die (<m>P(1)=1/6 \approx 0.167</m>) and a biased die (<m>P(1)=0.2</m>) over 1,000 trials. The fair die’s estimate (blue) fluctuates but approaches 1/6 (red dashed line), while the biased die’s estimate (orange) converges to 0.2, reflecting the higher probability of rolling a 1. This visualization demonstrates how empirical frequencies approximate true probabilities in large samples, a technique used in machine learning to estimate probabilities from training data.</caption>
                    <image source="./images/essential-probability-and-statistics/frequentist-convergence.png">
                        <shortdescription>Convergence plot for frequentist estimates.</shortdescription>
                    </image>
                </figure>
            </li>
            <li>
                <p>
                    <alert>Bayesian Probability</alert>. This is also an empirical definition of probability. But, rather than give you one number for probability of an event, Bayesian gives you a probability distribution of the values of probability of the event. From that, you can work out the mean value, which you can use as one value for the probability of the event. 
                </p> 
                <p> 
                    It is based on incorporating belief about the probability of an outcome BEFORE we even conduct the experiment and then updated this so-called prior assumption or bias with what we observe in the experiment. The updated belief is the posterior, and improved value of the probability. 
                </p>  
                <p> 
                    Clearly, as we repeat the experiment infinitely many times, the effect of our initial belief would disappear and the answer will match the results of the frequentists' experiments. However, since we can never do infinite number of trials, the Bayesian gives an edge in cases where we have some information about the outcome even before we start the trials.
                </p>
                <p>
                    <alert>Example:</alert> This example is a little bit ahead of my presentation here as it requres a little bit of math to properly express how th Bayesian probability works. If you feel up to it, you can ahead and read on, but it's okay to skip it for now.
                </p> 
                <p>  
                    In the case of a six-sided die, suppose we want to estimate the probability <m>p_1</m> for one-dot face up as we illustrated in the frequentist case above. First, we would need to choose a prior belief, i.e., a probability distribution for <m>p_1</m>, i.e., how likely is any value of <m>p_1</m> between its range of values, which will be from <m>0</m> to <m>1</m>, inclusive, <m>0\le p_1 \le 1</m>. Since, we do not know which value is right, we might decide that it could be 1/2 times it will be face up and 1/2 of the time it will be not face up (I know a fair die will be 1/6 times face up, but I want to show you how even a very off prior will eventually converge to the proper value). In such cases and our trial each time being either face up true or false ( which is a case of Bernoulli trials ), it is traditional to choose a beta distribution, which has two parameters <m>\alpha</m> and <m>\beta</m>, with <m>\alpha=1</m>  and <m>\beta = 1</m>. Using symbol <m>x</m> for <m>p_1</m> and <m>P(x)</m>, probability density of <m>p_1</m>, we will write this as follows where <m>0 \le x \le 1</m>.
                    <men xml:id="eqn-beta-distribution-prior">
                        \text{P(x)} dx = \frac{1}{B(\alpha, \beta)}\, x^{\alpha - 1} (1-x)^{\beta - 1},
                    </men>
                    where <m>B(\alpha, \beta)</m> is beta function. The mean value of beta distribution is an important result and can be easily found.
                    <men xml:id="eqn-mean-of-beta-distribution">
                        \langle x \rangle = \int_0^1\, x P(x) dx = \frac{\alpha}{\alpha + \beta}.
                    </men>
                    Here, I have introduced physicists' notation for the mean of a quantity, <m>\langle \cdots \rangle</m>. 
                    Thus, by choosing <m>B(1,1)</m> as the prior distribution, we are assuming that somehow we suspect that <m>p_1</m> is close to <m>1/2</m>. 
                    <men xml:id="eqn-mean-beta-distribution">
                        \langle p_1 \rangle = \frac{\alpha}{\alpha + \beta} = \frac{1}{1+1} = \frac{1}{2} = 0.5.
                    </men>
                    So, we are basically, starting way off in our belief.
                </p>
                <p>
                    
                    Just a side math info: Beta function is usually written in terms of factorial or Gamma function.
                    <me>
                        B(\alpha, \beta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)},
                    </me>
                    where, for integer arguments <m>n</m>,
                    <me>
                        \Gamma(n) = (n-1)! = [ m! = (m)(m-1) \cdots 1 = m \times (m-1)!\ \text{with}\ 0! = 1.]
                    </me>
                    and in general,
                    <me>
                        \Gamma(\alpha) = \int_0^\infty\, e^{-t}\,t^{\alpha -1}\, dt.
                    </me>
                    To hide all the mathematical details in our work below, we will, as is normally done, just express the probability <m>P(p_1)</m> by a simpler notation and represent Eq. <xref ref="eqn-beta-distribution-prior" />
                    <men xml:id="eqn-probability-distribution-simple-notation">
                        P_1 \sim B(\alpha, \beta) = B(1,1),
                    </men>
                    where instead of lower case variable name <m>p_1</m>, we use the notation of upper case <m>P_1</m>.
                </p> 
                <p> 
                    Let's get back to our rolling experiment and see how our belief of the true value of <m>p_1</m> evolves with each roll's result.     
                    Suppose we roll the die and observe that the up face is not one, then without showing you the calculations here, which will be done later in the chapter, we use Bayes rule, to be discussed later, to show that the probability distribution now shifts to <m>B(1,2)</m>.
                    <me>
                        P_1 \sim B(1,1) \rightarrow \text{[Toss, No one]} \rightarrow \sim B(1,2) \Rightarrow \langle p_1 \rangle = \frac{1}{1+2} = \frac{1}{3}.
                    </me>
                    How did we go from distribution <m>B(1,1)</m> to <m>B(1,2)</m>? I used Bayesian theorem. We will not show the calculation here but differ to a later section.
                </p>  
                <p>  
                    Toss second time, let's say the result is a one. Then our belief will be update with this new data to <m>B(2,2)</m>.
                    <me>
                        P_1 \sim B(1,2) \rightarrow \text{[Toss, Yes one]} \rightarrow \sim B(2,2) \Rightarrow \langle p_1 \rangle = \frac{2}{4} = 0.5.
                    </me>
                    Toss again, say no one.
                    <me>
                        P_1 \sim B(2,2) \rightarrow \text{[Toss, No one]} \rightarrow \sim B(2,3) \Rightarrow \langle p_1 \rangle = \frac{2}{2+3} = \frac{2}{5}.
                    </me>                   
                    We keep updating the probability distribution of <m>p_1</m>. At any point, we can take the expectation value of the the variable <m>p_1</m> in the current distribution to give us the "best current value" for <m>p_1</m>. Thus, after three trials above, we will say that <m>p_1 = 0.4</m>.
                </p>  
                <p>  
                    Suppose you continued rolling and you had the following next 7 trials:
                    <me>
                        \text{1, not 1, not 1, not 1, not 1, 1, not 1}.
                    </me>
                    After these 10 trials in total, the distribution will be
                    <me>
                        P_1 \sim B(4, 8) \Rightarrow \langle p_1 \rangle = \frac{4}{12} = \frac{1}{3}.
                    </me>
                    This is still far away from <m>1/6</m> that you would expect from a fair die, but you don't know if the die was fair. So, empirical results are all you have to go by.
                </p>  
                <p>  
                    For the same rolling results, frequentists' probability will give us the following estimate:
                    <me>
                        p_1(\text{frequentist}) = \frac{n_1}{N} = \frac{3}{10} = 0.3.
                    </me>
                    
                </p>
                <p> 
                    They look similar. But, had you expected the die was fair, you would start with a better prior, with say <m>B(1,5)</m>. Then the 10 trials would update to
                    <me>
                        P_1 \sim B(4, 12) \Rightarrow \langle p_1\rangle = \frac{4}{4+12} = \frac{1}{4} = 0.25.
                    </me>
                    It would have revealed if the die was not a fair die. It's either not a fair die or we have rolled it too few times.
                </p>  

            </li>
        </ol>
    </subsection>

    <conclusion>
        <title>Conclusion</title>
        <p>
            
            Probability provides the foundation for modeling uncertainty in machine learning. Axioms define the rules, while theoretical, frequentist, and Bayesian approaches offer different perspectives. Conditional probability and distributions are used in machine learning models to make predictions. 
        </p>
    </conclusion>
</section>