<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<!--******************************************-->
<!--*  Authored with PreTeXt                 *-->
<!--*  pretextbook.org                       *-->
<!--*  Theme: default-modern                 *-->
<!--*  Palette:                              *-->
<!--******************************************-->
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Law of Large Numbers and Central Limit Theorem</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0">
<link href="_static/pretext/css/theme.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/ol-markers.css" rel="stylesheet" type="text/css">
<script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math"
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "_static/pretext/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="ML Notes">
<meta property="book:author" content="Samuel Ling">
<script src="_static/pretext/js/lib/jquery.min.js"></script><script src="_static/pretext/js/lib/jquery.sticky.js"></script><script src="_static/pretext/js/lib/jquery.espy.min.js"></script><script src="_static/pretext/js/pretext.js"></script><script src="_static/pretext/js/pretext_add_on.js?x=1"></script><script src="_static/pretext/js/user_preferences.js"></script><!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX_Course_Title_Here';
eBookConfig.basecourse = 'PTX_Base_Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.runestone_version = '7.9.8';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script src="_static/prefix-runtime.b215b0da62d655bd.bundle.js"></script><script src="_static/prefix-723.3e6434f80549315a.bundle.js"></script><script src="_static/prefix-runestone.28cc3c4821792be5.bundle.js"></script><link rel="stylesheet" type="text/css" href="_static/prefix-723.3bccd435914aa0ff.css">
<link rel="stylesheet" type="text/css" href="_static/prefix-runestone.8141ae22fd347e48.css">
<script src="_static/pretext/js/lti_iframe_resizer.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.js" integrity="sha512-dubtf8xMHSQlExGRQ5R7toxHLgSDZ0K7AunqPWHXmJQ8XyVIG19S1T95gBxlAeGOK02P4Da2RTnQz0Za0H0ebQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-highlight/prism-line-highlight.min.js" integrity="sha512-93uCmm0q+qO5Lb1huDqr7tywS8A2TFA+1/WHvyiWaK6/pvsFl6USnILagntBx8JnVbQH5s3n0vQZY6xNthNfKA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="_static/pretext/js/pretext_search.js"></script><script src="_static/pretext/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script>
</head>
<body id="ML-Notes" class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner"><div class="title-container">
<h1 class="heading"><a href="my-ML-Notes.html"><span class="title">ML Notes</span> <span class="subtitle">Theoretical and Practical ML Concepts</span></a></h1>
<p class="byline">Samuel Ling</p>
</div></div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><div class="ptx-navbar-contents">
<button class="toc-toggle button" title="Contents"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5d2;</span><span class="name">Contents</span></button><div class="searchbox">
<div class="searchwidget"><button id="searchbutton" class="searchbutton button" type="button" title="Search book"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe8b6;</span><span class="name">Search Book</span></button></div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<div class="search-results-controls">
<input aria-label="Search term" id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search term"><button title="Close search" id="closesearchresults" class="closesearchresults"><span class="material-symbols-outlined">close</span></button>
</div>
<h2 class="search-results-heading">Search Results: </h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div>
<span class="nav-other-controls"><button id="light-dark-button" class="light-dark-button button" title="Dark Mode"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe51c;</span><span class="name">Dark Mode</span></button></span><span class="treebuttons"><a class="previous-button button" href="sec-Example-Continuous-Probability-Distributions.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="up-button button" href="ch-Essential-Probability-and-Statistics.html" title="Up"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Up</span></a><a class="next-button button" href="backmatter.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a></span>
</div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\N}{\mathbb N} \newcommand{\Z}{\mathbb Z} \newcommand{\Q}{\mathbb Q} \newcommand{\R}{\mathbb R}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2 focused" data-preexpanded-levels="0" data-max-levels="2"><ul class="structural toc-item-list contains-active">
<li class="toc-item toc-frontmatter"><div class="toc-title-box"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div></li>
<li class="toc-item toc-chapter contains-active">
<div class="toc-title-box"><a href="ch-Essential-Probability-and-Statistics.html" class="internal"><span class="codenumber">1</span> <span class="title">Essential Probability and Statistics</span></a></div>
<ul class="structural toc-item-list contains-active">
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Descriptive Statistics</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Useful Descriptive Statistics Tools</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#subsec-Pandas" class="internal"><span class="codenumber">1.2.1</span> <span class="title">Pandas</span></a></div></li></ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec-Numerical-and-Categorical-Data.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Numerical and Categorical Data</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Basic-Probability.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Basic Probability</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-Axiomatic-View-of-Probability" class="internal"><span class="codenumber">1.4.1</span> <span class="title">Axiomatic View of Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-three-types-of-probabilities" class="internal"><span class="codenumber">1.4.2</span> <span class="title">Three Types of Probabilities</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Joint, Conditional and Marginal Probabilities</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Random-Variables" class="internal"><span class="codenumber">1.5.1</span> <span class="title">Random Variables, Probabilities, and Expections</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Joint-Probability" class="internal"><span class="codenumber">1.5.2</span> <span class="title">Joint ad Marginal Probabilities</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsubsec-Covariance-and-Correlation" class="internal"><span class="codenumber">1.5.2.1</span> <span class="title">Covariance and Correlation</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Conditional-Probability" class="internal"><span class="codenumber">1.5.3</span> <span class="title">Conditional Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-conditional-probability-from-joint-probability" class="internal"><span class="codenumber">1.5.4</span> <span class="title">Bayes’ Rule</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Independent-Variables" class="internal"><span class="codenumber">1.5.5</span> <span class="title">Independent Variables</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Complications-For-Continuous-Variables" class="internal"><span class="codenumber">1.5.6</span> <span class="title">Complications-For-Continuous-Variables</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsubsec-Probability-Density" class="internal"><span class="codenumber">1.5.6.1</span> <span class="title">Probability Density</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsubsec-Cumulative-Distribution-Function" class="internal"><span class="codenumber">1.5.6.2</span> <span class="title">Cumulative Distribution Function (CDF)</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Example Discrete Probability Distributions</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Bernoulli-Distribution" class="internal"><span class="codenumber">1.6.1</span> <span class="title">Bernoulli Distribution</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Binomial-Distribution" class="internal"><span class="codenumber">1.6.2</span> <span class="title">Binomial Distribution</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Poisson-Distribution" class="internal"><span class="codenumber">1.6.3</span> <span class="title">Poisson Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsub-Poisson-Process" class="internal"><span class="codenumber">1.6.3.1</span> <span class="title">Poisson Process</span></a></div></li></ul>
</li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Example Continuous Probability Distributions</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Uniform-Distribution" class="internal"><span class="codenumber">1.7.1</span> <span class="title">Uniform Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsubsec-Inverse-Uniform-CDF" class="internal"><span class="codenumber">1.7.1.1</span> <span class="title">Inverse Uniform CDF</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Normal-Distribution" class="internal"><span class="codenumber">1.7.2</span> <span class="title">Normal (Gaussian) Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsubsec-Inverse-CDF-and-Sampling" class="internal"><span class="codenumber">1.7.2.1</span> <span class="title">Inverse CDF and Sampling</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Exponential-Distribution" class="internal"><span class="codenumber">1.7.3</span> <span class="title">Exponential Distribution</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section contains-active">
<div class="toc-title-box"><a href="sec-LLN-and-CLT.html" class="internal"><span class="codenumber">1.8</span> <span class="title">Law of Large Numbers and Central Limit Theorem</span></a></div>
<ul class="structural toc-item-list active">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Law-of-Large-Numbers" class="internal"><span class="codenumber">1.8.1</span> <span class="title">Law of Large Numbers (LLN)</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Central-Limit-Theorem" class="internal"><span class="codenumber">1.8.2</span> <span class="title">Central Limit Theorem</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Why-Large-n-Matters" class="internal"><span class="codenumber">1.8.3</span> <span class="title">Why LLN and CLT Matter?</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li class="toc-item toc-backmatter"><div class="toc-title-box"><a href="backmatter.html" class="internal"><span class="title">Backmatter</span></a></div></li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-LLN-and-CLT"><h2 class="heading hide-type">
<span class="type">Section</span><span class="space"> </span><span class="codenumber">1.8</span><span class="space"> </span><span class="title">Law of Large Numbers and Central Limit Theorem</span>
</h2>
<section class="introduction" id="sec-LLN-and-CLT-2"><div class="para" id="sec-LLN-and-CLT-2-1">The Law of Large Numbers (LLN) is often hand-waved as “averages go to the mean,” but there are really two distinct theorems (weak vs strong), different modes of convergence, and subtle conditions. Similary, the Central Limit Theorem (CLT) is one of the deepest ideas in probability, and it’s often glossed over as “averages look normal.”<div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="sec-LLN-and-CLT-2-2">Let’s take a slow, detailed walk through them. Although I do not intend our treatment here to be exhaustive, but there will be enough detail for you to get a fuller understanding of what they represent and how to use them.<div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="sec-LLN-and-CLT-2-3">
<em class="alert">The Setup:</em><div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="sec-LLN-and-CLT-2-4">
<div class="para">The set up for both LLN and CLT is the same. Suppose you have a number of independent random variables <span class="process-math">\(X_1, X_2, \cdots, X_n\text{,}\)</span> all with identical distribution functions <span class="process-math">\(P(X)\text{,}\)</span> same for every <span class="process-math">\(X_i\text{.}\)</span> Let <span class="process-math">\(\mu\)</span> be the man and <span class="process-math">\(\sigma^2\)</span> the variance of the common distribution.</div>
<div class="displaymath process-math" id="sec-LLN-and-CLT-2-4-6">
\begin{align}
\amp \mu  = \langle X_i\rangle,\qquad \text{same for every }X_i \tag{1.8.1}\\
\amp \sigma^2  = \langle X_i^2\rangle - \mu^2,\qquad \text{same for every }X_i \tag{1.8.2}
\end{align}
</div>
<div class="para">We will call these values <em class="alert">true mean</em> and <em class="alert">true variance</em>. Now, we introduce a new random variable, called the <em class="alert">sample mean</em> by</div>
<div class="displaymath process-math" id="eqn-sample-mean-random-variable">
\begin{equation}
\bar{X}_n = \frac{1}{n}\,\left( X_1 + X_2 + \cdots + X_n  \right).\tag{1.8.3}
\end{equation}
</div>
<div class="para">The bar over <span class="process-math">\(X\)</span> just distinguishes it from the <span class="process-math">\(n^\text{th}\, X\)</span> in the collection of random variables. More importantly, <span class="process-math">\(\bar{X}_n\)</span> is not one number, but a random variable, which will take values in the range given by the components <span class="process-math">\(X_i\text{.}\)</span> For instance, if <span class="process-math">\(X_i \in \{ 0, 1 \}\text{,}\)</span> a Bernoulli random variable, then, <span class="process-math">\(\bar{X}_n\)</span> would actually take many values, here  <span class="process-math">\(\bar{X}_n \in \{ 0, 1/n, 2/n, \cdots, (n-1)/n, 1\}\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="sec-LLN-and-CLT-2-5">
<div class="para">The random variable <span class="process-math">\(\bar{X}_n\)</span> will have it’s own probability distribution, <span class="process-math">\(P(\bar{X}_n)\text{.}\)</span> We call the mean and variance of this dstribution <em class="alert">sample mean</em> and <em class="alert">sample variance</em>.</div>
<div class="displaymath process-math" id="eqn-">
\begin{equation}
\bar{\mu}_n = \langle \bar{X}_n \rangle,\qquad \bar{\sigma}_n^2 =  \langle \bar{X}_n^2 \rangle - \bar{\mu}^2.\tag{1.8.4}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div></section><section class="subsection" id="subsec-Law-of-Large-Numbers"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.1</span><span class="space"> </span><span class="title">Law of Large Numbers (LLN)</span>
</h3>
<div class="para" id="subsec-Law-of-Large-Numbers-2">The LLN addresses the question: <em class="alert">What can we say about the mean of the sample mean <span class="process-math">\(\bar{X}_n\)</span></em> as <span class="process-math">\(n\)</span> grows large? Clearly, the probability distribution of <span class="process-math">\(\bar{X}_n\)</span> varies if we change <span class="process-math">\(n\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Law-of-Large-Numbers-3">
<div class="para">
<em class="alert">The weak law of LLN</em> asserts that probablity that <span class="process-math">\(|\bar{X}_n - \mu|\text{,}\)</span> where <span class="process-math">\(\mu\)</span> is the true mean defined above in Eq. <a href="sec-LLN-and-CLT.html#sec-LLN-and-CLT-2-4-6" class="xref" data-knowl="./knowl/xref/eqn-true-mean.html" data-reveal-label="Reveal" data-close-label="Close" title="Equation 1.8.1">(1.8.1)</a>, can be made smaller than any positive real number as long s you go sufficiently large <span class="process-math">\(n\text{.}\)</span> Mathematically, we express it as the complement of this probility.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/eqn-true-mean.html">
\begin{equation*}
\lim_{n\rightarrow\infty}P(|\bar{X}_n - \mu| \gt \epsilon ) = 0,\qquad \text{for all } \epsilon\gt 0.
\end{equation*}
</div>
<div class="para">That is, the probability that <span class="process-math">\(\bar{X}_n\)</span> strays outside of <span class="process-math">\(\mu \pm \epsilon\)</span> goes to zero as <span class="process-math">\(\text{}\)</span>. This result is also expressed in a more compact notation, with a letter <span class="process-math">\(P\)</span> above arrow implying “in probability”.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/eqn-true-mean.html">
\begin{equation*}
\bar{X}_n \xrightarrow{P}\, \mu.
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Law-of-Large-Numbers-4">
<div class="para">
<em class="alert">The stron LLN</em> uses a different criteria. You look at the sequency of sample random variables <span class="process-math">\(\bar{X}_n\)</span> with increasing value of <span class="process-math">\(n\)</span> and ask if these random variables themselves ted to <span class="process-math">\(\mu\text{.}\)</span> The claim is</div>
<div class="displaymath process-math">
\begin{equation*}
P(\lim_{n\rightarrow \infty} = \mu) = 1.
\end{equation*}
</div>
<div class="para">We say that <span class="process-math">\(\bar{X}_n\)</span> <em class="alert">almost surely</em> converges to <span class="process-math">\(\mu\text{,}\)</span> the true mean.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Law-of-Large-Numbers-5">Although nt that hard, the proofs of these results are beyond these notes.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Law-of-Large-Numbers-6">
<div class="para">For an <em class="alert">intuitive feel</em>, imagine tossing a fair coin. Suppose you toss it <span class="process-math">\(n\)</span> times. For varying values of <span class="process-math">\(n\)</span> you might find:</div>
<ul class="disc" id="subsec-Law-of-Large-Numbers-6-4">
<li id="subsec-Law-of-Large-Numbers-6-4-1">
<div class="para" id="subsec-Law-of-Large-Numbers-6-4-1-1">
<span class="process-math">\(n=1\text{:}\)</span> <span class="process-math">\(X_1\)</span> = 1 if heads and 0 if tails, with <span class="process-math">\(\mu = \langle X_1 \rangle = 0.5\text{.}\)</span> <span class="process-math">\(\bar{X}_1 = X_1\text{,}\)</span> hence, <span class="process-math">\(\langle \bar{X}_1 \rangle = \mu\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-6-4-1-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-Law-of-Large-Numbers-6-4-1" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">🔗</a></div>
</li>
<li id="subsec-Law-of-Large-Numbers-6-4-2">
<div class="para" id="subsec-Law-of-Large-Numbers-6-4-2-1">Suppose you flip the coin 10 times, now you have 10 variables, since outcome of each flip is a random variable in its own right. We usually, think of the tosses same experiment done 10 times. With this, <span class="process-math">\(n = 10\text{.}\)</span> Suppose, you got <span class="process-math">\((1,1,0,0, 1, 1, 1, 1, 0, 1)\text{.}\)</span> That would mean, for this experiment, you got the following value of the sample mean, <span class="process-math">\(\bar{X}_{10} = 0.7\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-6-4-2-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-Law-of-Large-Numbers-6-4-2" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">🔗</a></div>
</li>
<li id="subsec-Law-of-Large-Numbers-6-4-3">
<div class="para" id="subsec-Law-of-Large-Numbers-6-4-3-1">f you flip 100 times, the value of the sample mean variable in any one set of 100 tosses will usually be close to <span class="process-math">\(0.5\text{,}\)</span> say <span class="process-math">\(0.501\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-6-4-3-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-Law-of-Large-Numbers-6-4-3" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">🔗</a></div>
</li>
<li id="subsec-Law-of-Large-Numbers-6-4-4">
<div class="para" id="subsec-Law-of-Large-Numbers-6-4-4-1">Now, if you tossed the coin then <span class="process-math">\(10,000\text{,}\)</span> you would get even closer to <span class="process-math">\(o.5\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-6-4-4-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-Law-of-Large-Numbers-6-4-4" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">🔗</a></div>
</li>
</ul>
<div class="para">This is LLN in action. The strong law says: with probability 1, the sequence of averages converges to 0.5.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-6" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.1: Law of Large Numbers (LLN)"><a href="#subsec-Law-of-Large-Numbers" title="Copy heading and permalink for Subsection 1.8.1: Law of Large Numbers (LLN)" aria-label="Copy heading and permalink for Subsection 1.8.1: Law of Large Numbers (LLN)">🔗</a></div></section><section class="subsection" id="subsec-Central-Limit-Theorem"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.2</span><span class="space"> </span><span class="title">Central Limit Theorem</span>
</h3>
<div class="para logical" id="subsec-Central-Limit-Theorem-2">
<div class="para">The Central Limit Theorem says that regardless of the distribution <span class="process-math">\(P(X_i)\)</span> of <span class="process-math">\(X_i\)</span>’s, which may be Bernouli, Binomial, Exponential, or whatever, the distribution of a <span class="process-math">\(\bar{X}_n\)</span> tends towards a bell-shaped Gaussian wil larger and larger values of <span class="process-math">\(n\text{.}\)</span> Specifically,</div>
<div class="displaymath process-math" id="eqn-CLT">
\begin{equation}
\lim_{n\rightarrow \infty}\, \bar{X}_n \xrightarrow{d} \, \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right),          \tag{1.8.5}
\end{equation}
</div>
<div class="para">where <span class="process-math">\(d\)</span> above arrow just indicates the result is to be understood as converging “in distribution” and <span class="process-math">\(\sigma^2\)</span> is the true variance of the component <span class="process-math">\(X_i\)</span> variables. In terms ofprobability this means</div>
<div class="displaymath process-math">
\begin{equation*}
P(x \le \bar{X}_n \le x+dx) = \frac{1}{\sqrt{2\pi\sigma^2}}\, \exp\left( - \frac{( x - \mu )^2}{2 \sigma^2/n}  \right)\, dx.
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Central-Limit-Theorem-3">
<div class="para">In applications of this formula, it is convenient to express it in another form by shifting the random variable <span class="process-math">\(\bar{X}_n\)</span> and scaling the result.</div>
<div class="displaymath process-math" id="eqn-the-Zn-variable">
\begin{equation}
\bar{Z}_n = \frac{ \sqrt{n}\left( \bar{X}_n -\mu \right) }{\sigma}.\tag{1.8.6}
\end{equation}
</div>
<div class="para">Then, you can show that <span class="process-math">\(\bar{Z}_n\)</span> has a standard normal distribution, which lends itself to looking up standard tables and standard computations.</div>
<div class="displaymath process-math" id="eqn-the-normalized-CLT">
\begin{equation}
\bar{Z}_n \sim \mathcal{N}(0, 1).\tag{1.8.7}
\end{equation}
</div>
<div class="para">the CDF of standard normal is denoted by <span class="process-math">\(\Phi\)</span> instead of <span class="process-math">\(F\text{.}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\Phi(z) = P( \bar{Z}_n \le z ) = \int_{-\infty}^z\frac{1}{\sqrt{2\pi}}\, \exp\left( - \frac{z^2}{2}  \right)\, dz.
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Central-Limit-Theorem-4">Let’s emphasize once again the fact that the convergence to a Gaussian happens regarless of the original distribution of <span class="process-math">\(X_i\)</span>’s. This is why we see Gaussian curves everywhere in nature — measurement errors, heights, test scores, etc. aren’t inherently normal, but they are aggregates of many small random effects.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.2: Central Limit Theorem"><a href="#subsec-Central-Limit-Theorem" title="Copy heading and permalink for Subsection 1.8.2: Central Limit Theorem" aria-label="Copy heading and permalink for Subsection 1.8.2: Central Limit Theorem">🔗</a></div></section><section class="subsection" id="subsec-Why-Large-n-Matters"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.3</span><span class="space"> </span><span class="title">Why LLN and CLT Matter?</span>
</h3>
<div class="para" id="subsec-Why-Large-n-Matters-2">
<em class="alert">Why LLN Matter?</em><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-3">In statistics, we distinguish between a sample mean and a population mean. The population mean, also called true mean <span class="process-math">\(\mu\text{,}\)</span> is usually not known since we either do not have access to every point of interest, we only look at a small part. For instance, when we poll the population on some issue, we do not ask everybody, we just take <em class="alert">sample</em>. The LLN gives us confidence that if <span class="process-math">\(n\)</span> is <em class="alert">large enough</em>, sample mean will be close to the population mean.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Why-Large-n-Matters-4">
<div class="para">As a numerical illustration of how sample mean <span class="process-math">\(\bar{X}_n\)</span> “hugs” the true mean as <span class="process-math">\(n\)</span> gets large, consider rolls of a fair six-sided die, whose faces are labeled <span class="process-math">\(1, 2, 3, 4, 5, 6\text{.}\)</span> The true mean of these rolls will be just</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-die-rolls-sample-mean-vs-true-mean.html">
\begin{equation*}
\text{True Mean}, \mu = 3.5,\qquad \text{Estimated Mean}, \bar{X}_n \approx 3.5.
\end{equation*}
</div>
<div class="para">Can you see how this can be shown? Anyway, let’s roll this die <span class="process-math">\(n\)</span> times and plot the sample means of the results obtained in rolls for various <span class="process-math">\(n\)</span> values. This is shown in <a href="sec-LLN-and-CLT.html#fig-die-rolls-sample-mean-vs-true-mean" class="xref" data-knowl="./knowl/xref/fig-die-rolls-sample-mean-vs-true-mean.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.8.1">Figure 1.8.1</a>. You can see that As the number of rolls increases, the sample mean stabilizes around <span class="process-math">\(3.5\)</span> <figure class="figure figure-like" id="fig-die-rolls-sample-mean-vs-true-mean"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/die-rolls-sample-mean-vs-true-mean.png" class="contained" alt="Illustration of the Law of Large Numbers with rolls of a fair six-sided die."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.8.1<span class="period">.</span></span><span class="space"> </span>Illustration of the Law of Large Numbers with rolls of a fair six-sided die.<div class="autopermalink" data-description="Figure 1.8.1"><a href="#fig-die-rolls-sample-mean-vs-true-mean" title="Copy heading and permalink for Figure 1.8.1" aria-label="Copy heading and permalink for Figure 1.8.1">🔗</a></div></figcaption></figure>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-5">Maybe an example from Physics as well: In statistical mechanics, we often can’t observe all particles in a macroscopic system. Instead, suppose we observe one particle over a long time. LLN guarantees that if the system is <em class="alert">ergodic</em>, the time average converges to the ensemble (population) average.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-6">
<em class="alert">Why CLT Matter? The Confidence Interval</em><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-6" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-7">Although LLN tells us that in the large <span class="process-math">\(n\)</span> limit sample mean will be close to the population or true mean <span class="process-math">\(\mu\text{.}\)</span> But, we don’t only want to know the approximate value of the true mean. We also would like to know the <em class="alert">uncertainty</em> in this knowledge, especially since we often do not know the value of true mean. This is where we <em class="alert">need the Central Limit Theorem</em>. The CLT says that <span class="process-math">\(\bar{X}_n\)</span> is approximately Gaussian, which gives as tools to build <em class="alert">confidence intervals</em>.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-7" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Why-Large-n-Matters-8">
<div class="para">Let us look at the fair six-sided die rolls. Suppose, want to answer the question: what is the mean of face value of a roll of a single die? The result of a signle roll is a random variable, which are calling <span class="process-math">\(X\text{.}\)</span> Of course, each time you roll the die, you will get a single value from <span class="process-math">\(1, 2, 3, 4, 5, \text{or}, 6\)</span> in a equiprobable way. From this you can calculate the true mean to be <span class="process-math">\(\mu = 3.5\text{,}\)</span> and standard deviation <span class="process-math">\(\sigma = \sqrt{35/12}\text{,}\)</span> which is left as an exercise for you. (Just use the mean and variance formulas.)</div>
<div class="displaymath process-math">
\begin{equation*}
\mu = 3.5,\quad \sigma = \sqrt{35/12}.
\end{equation*}
</div>
<div class="para">Now, we are going to pretend that we didn’t know these values and want to figure out the mean by doing experiments and generating data.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-8" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-9">To get the estimates of mean and standard deviation, we can just roll the die <span class="process-math">\(n\)</span> times, say for <span class="process-math">\(n=100\text{.}\)</span> The outcome of this experiment will be a sequence of face values, <span class="process-math">\(\{X_1 = 2, X_2 = 5, X_3 = 1, X_4 = 3, \cdots, X_{100}=4 \}\text{.}\)</span> The average, denoted by <span class="process-math">\(\bar{X}_{n}\)</span> and standard deviation of this data can be an estimate of the corresponding true quantities. Since <span class="process-math">\(n=100\)</span> is fairly large number, the law of large numbers tells us that the average will be a good estimate of <span class="process-math">\(\mu\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-9" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-10">Suppose you got a value of <span class="process-math">\(\bar{X}_{n} = 3.6\)</span> in our first try of a 100 rolls. Now, when you repeat another <span class="process-math">\(100\)</span> rolls, you will get another set of data, <span class="process-math">\(\{X_1 = 5, X_2 = 1, X_3 = 6, X_4 = 1, \cdots, X_{100}=2 \}\text{.}\)</span> Their average and standard deviation will be different from what you got the first time. Say, for average you got this time <span class="process-math">\(\bar{X}_{n}= 3.55\)</span> this time.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-10" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-11">A simulation of <span class="process-math">\(N=10000\)</span> repeats of this <span class="process-math">\(100\)</span>-roll experimets is presented in <a href="sec-LLN-and-CLT.html#fig-confidence-interval-die-roll" class="xref" data-knowl="./knowl/xref/fig-confidence-interval-die-roll.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.8.2">Figure 1.8.2</a> as a histogram. The theoretical true mean is near the peak of the Gaussian as expected. But, if we didn’t know the value of the true mean, we will need to guess where it is. That guess can be quantified with a degree of confidence in the guess. The figure shows a range of values of the sample mean (the abscissa in the plot) within which there is <span class="process-math">\(95\%\)</span> chance of finding the true <span class="process-math">\(\mu\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-11" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Why-Large-n-Matters-12">
<div class="para">Here is the breakdown of how the confidence interval was obtained. Let’s recall that as per CLT for a large <span class="process-math">\(n\text{.}\)</span> </div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html" id="eqn-clt-gaussian-approx">
\begin{equation}
\bar{X}_n  \sim  \mathcal{N}\left( \mu, \frac{ \sigma^2 }{n}\right),\tag{1.8.8}
\end{equation}
</div>
<div class="para">where <span class="process-math">\(\mu\)</span> and <span class="process-math">\(\sigma\)</span> are the true mean and standard deviation of the random variabel <span class="process-math">\(X_1\text{.}\)</span> The last quantity is sample variance</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html" id="eqn-sample-variance">
\begin{equation}
\text{Sample Variance} = \frac{ \sigma^2 }{n}.\tag{1.8.9}
\end{equation}
</div>
<div class="para">This is often referred to as theoretical result. When we simulate the experiment as done in <a href="sec-LLN-and-CLT.html#fig-confidence-interval-die-roll" class="xref" data-knowl="./knowl/xref/fig-confidence-interval-die-roll.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.8.2">Figure 1.8.2</a>, you can get estimated sample mean as well the estimated sample variance directly from the experiment and don’t need to divide it further by <span class="process-math">\(\sqrt{n}\text{.}\)</span> Thus, using the quatities from the simulation, we will write the CLT as follows.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html" id="eqn-clt-gaussian-approx-simulation">
\begin{equation}
\bar{X}_n  \sim  \mathcal{N}\left( \mu_\text{sim}, \sigma_\text{sim}^2 \right),\tag{1.8.10}
\end{equation}
</div>
<div class="para">where I am using the subscript <span class="process-math">\(\text{sim}\)</span> to indicate the simulation quantities.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-12" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<div class="para logical" id="subsec-Why-Large-n-Matters-13">
<div class="para">Here, we want a <span class="process-math">\(95\%\)</span> confidence interval (in other applications you may want <span class="process-math">\(99\%\)</span> CI or whatever), which is just the range of values around the mean that covers the <span class="process-math">\(95\%\)</span> of the area under the curve in the Gaussian function. That will leave <span class="process-math">\(5\%\)</span> area outside, which will be <span class="process-math">\(2.5\%\)</span> on the right and <span class="process-math">\(2.5\%\)</span> on the left. That’s where we can use the inverse of the CDF <span class="process-math">\(F(x)\text{.}\)</span> If we solve</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html">
\begin{equation*}
F(x) = 0.95 + 0.025 = 0.975, 
\end{equation*}
</div>
<div class="para">we will get the value of <span class="process-math">\(x\)</span> that is the right edge. By symmetry, we will go to the left edge, or for the left edge solve</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html">
\begin{equation*}
F(x) = 0.025.
\end{equation*}
</div>
<div class="para">These points will be</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html">
\begin{equation*}
x_\text{right} = F^{-1}(0.975),\quad x_\text{left} = F^{-1}(0.025).
\end{equation*}
</div>
<div class="para">Altough plot in <a href="sec-LLN-and-CLT.html#fig-confidence-interval-die-roll" class="xref" data-knowl="./knowl/xref/fig-confidence-interval-die-roll.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.8.2">Figure 1.8.2</a> does not show the normalized Gaussian, in practice it is common to shift and scale to the <span class="process-math">\(Z\)</span> vartiable as defined above.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html">
\begin{equation*}
\bar{Z}_n \equiv \frac{\left( \bar{X}_n -\mu_\text{sim} \right)}{\sigma_\text{sim}} \sim \mathcal{N}\left( 0, 1\right).
\end{equation*}
</div>
<div class="para">Then, it is easy to get the left and right values of <span class="process-math">\(\bar{Z}_n\)</span> by using a standard library function, such as ppf() shown in the program listed below. This gives</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html">
\begin{equation*}
x_\text{right} =  \mu_\text{est} + z_\text{right} \times \sigma_\text{sim},
\end{equation*}
</div>
<div class="para">and</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html">
\begin{equation*}
x_\text{left} =  \mu_\text{est} + z_\text{left} \times \sigma_\text{sim}.
\end{equation*}
</div>
<div class="para">The range <span class="process-math">\([x_\text{left}, x_\text{right}]\)</span> gives the range of <span class="process-math">\(\bar{X}_n\)</span> values within which at the chosen confidence level, here illustrated for <span class="process-math">\(95\%\)</span> that the true <span class="process-math">\(\mu\)</span> is expected to reside.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/fig-confidence-interval-die-roll.html" id="eqn-confidence-interval">
\begin{equation}
\mu \in [x_\text{left}, x_\text{right}] = [\mu_\text{est} + z_\text{right} \times \sigma_\text{sim},  \mu_\text{est} + z_\text{left} \times \sigma_\text{sim} ].\tag{1.8.11}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-13" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">🔗</a></div>
</div>
<figure class="figure figure-like" id="fig-confidence-interval-die-roll"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/confidence-interval-die-roll.png" class="contained" alt="Confidence interval for 10000 trials of the computation of the distribution of mean of face values in 100 rolls of a siz-sided fair die with marking 1, 2, 3, 4, 5, 6."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.8.2<span class="period">.</span></span><span class="space"> </span>Confidence interval for 10000 trials of the computation of the distribution of mean of face values in 100 rolls of a siz-sided fair die with marking 1, 2, 3, 4, 5, 6. The true mean id just <span class="process-math">\((1+ 2+ 3+ 4+ 5+ 6)/6 = 3.5\text{.}\)</span><div class="autopermalink" data-description="Figure 1.8.2"><a href="#fig-confidence-interval-die-roll" title="Copy heading and permalink for Figure 1.8.2" aria-label="Copy heading and permalink for Figure 1.8.2">🔗</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable"><code class="language-py">import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# --- Step 1: Simulate dice rolls ---
np.random.seed(42)
n_trials = 10000   # number of experiments
n_rolls = 100      # dice per experiment

# Each experiment = 100 dice rolls
data = np.random.randint(1, 7, size=(n_trials, n_rolls))
sample_means = data.mean(axis=1)

# --- Step 2: Compute 95% CI using sample statistics ---
mean_est = np.mean(sample_means)
std_est = np.std(sample_means, ddof=1)
z_975 = norm.ppf(0.975)

margin = z_975 * std_est
ci_lower, ci_upper = mean_est - margin, mean_est + margin

print(f"Estimated mean = {mean_est:.3f}")
print(f"95% CI ≈ [{ci_lower:.3f}, {ci_upper:.3f}]")

# --- Step 3: Plot histogram + CI arrow ---
fig, ax = plt.subplots(figsize=(8,5))
counts, bins, patches = ax.hist(sample_means, bins=50, density=True, 
                                alpha=0.6, color='skyblue', edgecolor='black')

# Vertical line for mean
plt.axvline(mean_est, color='red', linestyle='--', label="Mean of sample means")

# Place CI arrow at 1/3 of max histogram height
y_arrow = counts.max() / 3  

# Horizontal CI arrow
plt.annotate(
    '', 
    xy=(ci_lower, y_arrow), xycoords='data',
    xytext=(ci_upper, y_arrow), textcoords='data',
    arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=2)
)
plt.text(mean_est, y_arrow * 1.1, "95% CI", ha='center', fontsize=12)

# --- New: Vertical dashed lines at CI endpoints ---
plt.axvline(ci_lower, color='black', linestyle='dashed', ymax=0.9, label="CI lower/upper")
plt.axvline(ci_upper, color='black', linestyle='dashed', ymax=0.9)

plt.title("Sampling Distribution of Dice Means (100 rolls, 10,000 trials)")
plt.xlabel("Sample Mean")
plt.ylabel("Density")
plt.legend()
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsection 1.8.3: Why LLN and CLT Matter?"><a href="#subsec-Why-Large-n-Matters" title="Copy heading and permalink for Subsection 1.8.3: Why LLN and CLT Matter?" aria-label="Copy heading and permalink for Subsection 1.8.3: Why LLN and CLT Matter?">🔗</a></div></section><div class="autopermalink" data-description="Section 1.8: Law of Large Numbers and Central Limit Theorem"><a href="#sec-LLN-and-CLT" title="Copy heading and permalink for Section 1.8: Law of Large Numbers and Central Limit Theorem" aria-label="Copy heading and permalink for Section 1.8: Law of Large Numbers and Central Limit Theorem">🔗</a></div></section></div>
<div id="ptx-content-footer" class="ptx-content-footer">
<a class="previous-button button" href="sec-Example-Continuous-Probability-Distributions.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Top</span></a><a class="next-button button" href="backmatter.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" height="100%" viewBox="338 3000 8772 6866" role="img"><title>PreTeXt logo</title><g style="stroke-width:.025in; stroke:currentColor; fill:none"><polyline points="472,3590 472,9732 " style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png" alt="Runstone Academy logo"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png" alt="MathJax logo"></a>
</div>
</body>
</html>
