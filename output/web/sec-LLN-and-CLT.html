<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<!--******************************************-->
<!--*  Authored with PreTeXt                 *-->
<!--*  pretextbook.org                       *-->
<!--*  Theme: default-modern                 *-->
<!--*  Palette:                              *-->
<!--******************************************-->
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Law of Large Numbers and Central Limit Theorem</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0">
<link href="_static/pretext/css/theme.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/ol-markers.css" rel="stylesheet" type="text/css">
<script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math"
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "_static/pretext/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="ML Notes">
<meta property="book:author" content="Samuel Ling">
<script src="_static/pretext/js/lib/jquery.min.js"></script><script src="_static/pretext/js/lib/jquery.sticky.js"></script><script src="_static/pretext/js/lib/jquery.espy.min.js"></script><script src="_static/pretext/js/pretext.js"></script><script src="_static/pretext/js/pretext_add_on.js?x=1"></script><script src="_static/pretext/js/user_preferences.js"></script><!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX_Course_Title_Here';
eBookConfig.basecourse = 'PTX_Base_Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.runestone_version = '7.9.8';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script src="_static/prefix-runtime.b215b0da62d655bd.bundle.js"></script><script src="_static/prefix-723.3e6434f80549315a.bundle.js"></script><script src="_static/prefix-runestone.28cc3c4821792be5.bundle.js"></script><link rel="stylesheet" type="text/css" href="_static/prefix-723.3bccd435914aa0ff.css">
<link rel="stylesheet" type="text/css" href="_static/prefix-runestone.8141ae22fd347e48.css">
<script src="_static/pretext/js/lti_iframe_resizer.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.js" integrity="sha512-dubtf8xMHSQlExGRQ5R7toxHLgSDZ0K7AunqPWHXmJQ8XyVIG19S1T95gBxlAeGOK02P4Da2RTnQz0Za0H0ebQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-highlight/prism-line-highlight.min.js" integrity="sha512-93uCmm0q+qO5Lb1huDqr7tywS8A2TFA+1/WHvyiWaK6/pvsFl6USnILagntBx8JnVbQH5s3n0vQZY6xNthNfKA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="_static/pretext/js/pretext_search.js"></script><script src="_static/pretext/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script>
</head>
<body id="ML-Notes" class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner"><div class="title-container">
<h1 class="heading"><a href="my-ML-Notes.html"><span class="title">ML Notes</span> <span class="subtitle">Theoretical and Practical ML Concepts</span></a></h1>
<p class="byline">Samuel Ling</p>
</div></div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><div class="ptx-navbar-contents">
<button class="toc-toggle button" title="Contents"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5d2;</span><span class="name">Contents</span></button><div class="searchbox">
<div class="searchwidget"><button id="searchbutton" class="searchbutton button" type="button" title="Search book"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe8b6;</span><span class="name">Search Book</span></button></div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<div class="search-results-controls">
<input aria-label="Search term" id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search term"><button title="Close search" id="closesearchresults" class="closesearchresults"><span class="material-symbols-outlined">close</span></button>
</div>
<h2 class="search-results-heading">Search Results: </h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div>
<span class="nav-other-controls"><button id="light-dark-button" class="light-dark-button button" title="Dark Mode"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe51c;</span><span class="name">Dark Mode</span></button></span><span class="treebuttons"><a class="previous-button button" href="sec-Example-Continuous-Probability-Distributions.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="up-button button" href="ch-Essential-Probability-and-Statistics.html" title="Up"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Up</span></a><a class="next-button button" href="sec-Inferential-Statistics.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a></span>
</div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\N}{\mathbb N} \newcommand{\Z}{\mathbb Z} \newcommand{\Q}{\mathbb Q} \newcommand{\R}{\mathbb R}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2 focused" data-preexpanded-levels="0" data-max-levels="2"><ul class="structural toc-item-list contains-active">
<li class="toc-item toc-frontmatter"><div class="toc-title-box"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div></li>
<li class="toc-item toc-chapter contains-active">
<div class="toc-title-box"><a href="ch-Essential-Probability-and-Statistics.html" class="internal"><span class="codenumber">1</span> <span class="title">Essential Probability and Statistics</span></a></div>
<ul class="structural toc-item-list contains-active">
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Descriptive-Statistics.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Descriptive Statistics</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#subsec-Central-Tendency" class="internal"><span class="codenumber">1.1.1</span> <span class="title">Measures of Central Tendency</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#subsec-Dispersion" class="internal"><span class="codenumber">1.1.2</span> <span class="title">Measures of Dispersion</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#subsec-Distribution-Shape" class="internal"><span class="codenumber">1.1.3</span> <span class="title">Distribution Shape</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis" class="internal"><span class="codenumber">1.1.4</span> <span class="title">Kurtosis: Checking Out the Tails</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#types-of-kurtosis" class="internal"><span class="codenumber">1.1.4.1</span> <span class="title">Types of Kurtosis</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-formula" class="internal"><span class="codenumber">1.1.4.2</span> <span class="title">How‚Äôs It Calculated?</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-examples" class="internal"><span class="codenumber">1.1.4.3</span> <span class="title">Real-World Examples</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-visual" class="internal"><span class="codenumber">1.1.4.4</span> <span class="title">Seeing Kurtosis in Action</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-python" class="internal"><span class="codenumber">1.1.4.5</span> <span class="title">Calculating Kurtosis with Python</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-wrapup" class="internal"><span class="codenumber">1.1.4.6</span> <span class="title">Why Kurtosis Matters</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Useful Tools for Descriptive Statistics and Exploratory Data Analysis</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#subsec-NumPy" class="internal"><span class="codenumber">1.2.1</span> <span class="title">NumPy: Foundation for Numerical Operations</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#subsec-Pandas" class="internal"><span class="codenumber">1.2.2</span> <span class="title">Pandas: Data Manipulation and Analysis</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#subsec-Visualization" class="internal"><span class="codenumber">1.2.3</span> <span class="title">Visualization with Matplotlib and Seaborn</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-data-types-for-machine-learning.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Data Types for Machine Learning</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-data-types-for-machine-learning.html#subsec-structured-vs-unstructured" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Structured vs. Unstructured Data</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-data-types-for-machine-learning.html#subsec-sequence-vs-non-sequence" class="internal"><span class="codenumber">1.3.2</span> <span class="title">Sequence vs. Non-Sequence Data</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-data-types-for-machine-learning.html#subsec-numerical-categorical-ordinal" class="internal"><span class="codenumber">1.3.3</span> <span class="title">Numerical, Categorical, and Ordinal Data</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-data-types-for-machine-learning.html#subsec-unstructured-text" class="internal"><span class="codenumber">1.3.4</span> <span class="title">Handling Unstructured Text Data</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Basic-Probability.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Basic Probability for Machine Learning</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-Axiomatic-View-of-Probability" class="internal"><span class="codenumber">1.4.1</span> <span class="title">Axiomatic View of Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-sum-product-rules" class="internal"><span class="codenumber">1.4.2</span> <span class="title">Sum and Product Rules for Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-conditional-probability-independence" class="internal"><span class="codenumber">1.4.3</span> <span class="title">Conditional Probability and Independence</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-probability-distributions" class="internal"><span class="codenumber">1.4.4</span> <span class="title">Probability Distributions</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-three-types-of-probabilities" class="internal"><span class="codenumber">1.4.5</span> <span class="title">Three Types of Probabilities</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Joint, Marginal, and Conditional Probabilities</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Random-Variables" class="internal"><span class="codenumber">1.5.1</span> <span class="title">Random Variables, Probabilities, and Expectations</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Joint-Probability" class="internal"><span class="codenumber">1.5.2</span> <span class="title">Joint and Marginal Probabilities</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Covariance-and-Correlation" class="internal"><span class="codenumber">1.5.3</span> <span class="title">Covariance and Correlation</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Conditional-Probability" class="internal"><span class="codenumber">1.5.4</span> <span class="title">Conditional Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-conditional-probability-from-joint-probability" class="internal"><span class="codenumber">1.5.5</span> <span class="title">Bayes‚Äô Rule</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Continuous-Random-Variables" class="internal"><span class="codenumber">1.5.6</span> <span class="title">Continuous Random Variables</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsubsec-Probability-Density" class="internal"><span class="codenumber">1.5.6.1</span> <span class="title">Probability Density</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsubsec-Cumulative-Distribution-Function" class="internal"><span class="codenumber">1.5.6.2</span> <span class="title">Cumulative Distribution Function</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Independent-Variables" class="internal"><span class="codenumber">1.5.7</span> <span class="title">Independent Random Variables</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Joint-Conditional-and-Marginal-Probabilities.html#subsec-Application-Medical-Diagnosis" class="internal"><span class="codenumber">1.5.8</span> <span class="title">Application: Medical Diagnosis</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Example Discrete Probability Distributions</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Bernoulli-Distribution" class="internal"><span class="codenumber">1.6.1</span> <span class="title">Bernoulli Distribution</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Binomial-Distribution" class="internal"><span class="codenumber">1.6.2</span> <span class="title">Binomial Distribution</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Poisson-Distribution" class="internal"><span class="codenumber">1.6.3</span> <span class="title">Poisson Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsub-Poisson-Process" class="internal"><span class="codenumber">1.6.3.1</span> <span class="title">Poisson Process</span></a></div></li></ul>
</li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Example Continuous Probability Distributions</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Uniform-Distribution" class="internal"><span class="codenumber">1.7.1</span> <span class="title">Uniform Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsubsec-Inverse-Uniform-CDF" class="internal"><span class="codenumber">1.7.1.1</span> <span class="title">Inverse Uniform CDF</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Normal-Distribution" class="internal"><span class="codenumber">1.7.2</span> <span class="title">Normal (Gaussian) Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsubsec-Inverse-CDF-and-Sampling" class="internal"><span class="codenumber">1.7.2.1</span> <span class="title">Inverse CDF and Sampling</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Exponential-Distribution" class="internal"><span class="codenumber">1.7.3</span> <span class="title">Exponential Distribution</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section contains-active">
<div class="toc-title-box"><a href="sec-LLN-and-CLT.html" class="internal"><span class="codenumber">1.8</span> <span class="title">Law of Large Numbers and Central Limit Theorem</span></a></div>
<ul class="structural toc-item-list active">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Law-of-Large-Numbers" class="internal"><span class="codenumber">1.8.1</span> <span class="title">Law of Large Numbers</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Central-Limit-Theorem" class="internal"><span class="codenumber">1.8.2</span> <span class="title">Central Limit Theorem</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-LLN-vs-CLT" class="internal"><span class="codenumber">1.8.3</span> <span class="title">LLN vs. CLT</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Berry-Esseen" class="internal"><span class="codenumber">1.8.4</span> <span class="title">Berry-Esseen Theorem</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Why-Large-n-Matters" class="internal"><span class="codenumber">1.8.5</span> <span class="title">Why LLN and CLT Matter</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Inferential-Statistics.html" class="internal"><span class="codenumber">1.9</span> <span class="title">Inferential Statistics</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Point-Estimation" class="internal"><span class="codenumber">1.9.1</span> <span class="title">Point Estimation</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Sampling-Distributions" class="internal"><span class="codenumber">1.9.2</span> <span class="title">Sampling Distributions</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Hypothesis-Testing" class="internal"><span class="codenumber">1.9.3</span> <span class="title">Hypothesis Testing</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Confidence-Intervals" class="internal"><span class="codenumber">1.9.4</span> <span class="title">Confidence Intervals</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Types-of-Errors" class="internal"><span class="codenumber">1.9.5</span> <span class="title">Types of Errors</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Power-Effect-Size" class="internal"><span class="codenumber">1.9.6</span> <span class="title">Statistical Power and Effect Size</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Multiple-Testing" class="internal"><span class="codenumber">1.9.7</span> <span class="title">Multiple Testing</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Other-Tests" class="internal"><span class="codenumber">1.9.8</span> <span class="title">Common Statistical Tests</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li class="toc-item toc-backmatter"><div class="toc-title-box"><a href="backmatter.html" class="internal"><span class="title">Backmatter</span></a></div></li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-LLN-and-CLT"><h2 class="heading hide-type">
<span class="type">Section</span><span class="space"> </span><span class="codenumber">1.8</span><span class="space"> </span><span class="title">Law of Large Numbers and Central Limit Theorem</span>
</h2>
<section class="introduction" id="sec-LLN-and-CLT-2"><div class="para" id="sec-LLN-and-CLT-2-1">The Law of Large Numbers (LLN) and Central Limit Theorem (CLT) are foundational results in probability and statistics, underpinning many inferential techniques. The LLN ensures that sample averages converge to the population mean, while the CLT describes the distribution of those averages as approximately normal for large samples. This section provides a detailed yet accessible exploration of these theorems, their assumptions, and their applications.<div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="sec-LLN-and-CLT-2-2">
<em class="alert">The Setup:</em><div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para logical" id="sec-LLN-and-CLT-2-3">
<div class="para">Consider a sequence of independent and identically distributed (i.i.d.) random variables <span class="process-math">\(X_1, X_2, \dots, X_n\text{,}\)</span> each with the same probability distribution, mean <span class="process-math">\(\mu = E[X_i]\text{,}\)</span> and variance <span class="process-math">\(\sigma^2 = \text{Var}(X_i) = E[X_i^2] - \mu^2\text{,}\)</span> where <span class="process-math">\(E[\cdot]\)</span> denotes the expected value. These are called the <em class="alert">true mean</em> and <em class="alert">true variance</em>. We define the <em class="alert">sample mean</em> as:</div>
<div class="displaymath process-math" id="eqn-sample-mean-random-variable">
\begin{equation}
\bar{X}_n = \frac{1}{n} (X_1 + X_2 + \cdots + X_n).\tag{1.8.1}
\end{equation}
</div>
<div class="para">The sample mean <span class="process-math">\(\bar{X}_n\)</span> is itself a random variable with its own distribution. For example, if <span class="process-math">\(X_i\)</span> is a Bernoulli random variable with <span class="process-math">\(X_i \in \{0, 1\}\)</span> and <span class="process-math">\(p = 0.5\text{,}\)</span> then <span class="process-math">\(\bar{X}_n\)</span> takes values in <span class="process-math">\(\{0, \frac{1}{n}, \frac{2}{n}, \dots, 1\}\text{.}\)</span> The LLN and CLT describe the behavior of <span class="process-math">\(\bar{X}_n\)</span> as <span class="process-math">\(n\)</span> increases.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="sec-LLN-and-CLT-2-4">The LLN and CLT require that the <span class="process-math">\(X_i\)</span> are i.i.d. with finite mean <span class="process-math">\(\mu\text{.}\)</span> The CLT additionally requires finite variance <span class="process-math">\(\sigma^2\text{,}\)</span> and the Strong LLN requires a slightly stronger condition on the moments of <span class="process-math">\(X_i\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#sec-LLN-and-CLT-2-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div></section><section class="subsection" id="subsec-Law-of-Large-Numbers"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.1</span><span class="space"> </span><span class="title">Law of Large Numbers</span>
</h3>
<div class="para" id="subsec-Law-of-Large-Numbers-2">The LLN addresses the question: <em class="alert">What happens to the sample mean <span class="process-math">\(\bar{X}_n\)</span> as the sample size <span class="process-math">\(n\)</span> grows large?</em> It comes in two forms: the Weak LLN and the Strong LLN, which differ in their modes of convergence.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para logical" id="subsec-Law-of-Large-Numbers-3">
<div class="para">
<em class="alert">Weak LLN:</em> The Weak LLN states that the probability that <span class="process-math">\(\bar{X}_n\)</span> deviates from the true mean <span class="process-math">\(\mu\)</span> by more than any positive amount <span class="process-math">\(\epsilon\)</span> approaches zero as <span class="process-math">\(n \to \infty\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\lim_{n \to \infty} P(|\bar{X}_n - \mu| &gt; \epsilon) = 0, \quad \text{for all } \epsilon &gt; 0.
\end{equation*}
</div>
<div class="para">This is called convergence <em class="alert">in probability</em>, denoted:</div>
<div class="displaymath process-math">
\begin{equation*}
\bar{X}_n \xrightarrow{P} \mu.
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para logical" id="subsec-Law-of-Large-Numbers-4">
<div class="para">
<em class="alert">Strong LLN:</em> The Strong LLN states that the sequence of sample means <span class="process-math">\(\bar{X}_n\)</span> converges to <span class="process-math">\(\mu\)</span> with probability 1:</div>
<div class="displaymath process-math">
\begin{equation*}
P(\lim_{n \to \infty} \bar{X}_n = \mu) = 1.
\end{equation*}
</div>
<div class="para">This is called <em class="alert">almost sure convergence</em>, a stronger condition implying that almost all sample paths of <span class="process-math">\(\bar{X}_n\)</span> converge to <span class="process-math">\(\mu\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Law-of-Large-Numbers-5">
<em class="alert">Intuitive Example:</em> Consider tossing a fair coin with <span class="process-math">\(P(\text{heads}) = 0.5\text{,}\)</span> so <span class="process-math">\(X_i = 1\)</span> for heads and <span class="process-math">\(0\)</span> for tails, with <span class="process-math">\(\mu = E[X_i] = 0.5\text{.}\)</span> For <span class="process-math">\(n = 1\text{,}\)</span> <span class="process-math">\(\bar{X}_1 = X_1\)</span> is either 0 or 1. For <span class="process-math">\(n = 10\text{,}\)</span> suppose we observe 7 heads, so <span class="process-math">\(\bar{X}_{10} = 7/10 = 0.7\text{.}\)</span> For <span class="process-math">\(n = 100\text{,}\)</span> we might get <span class="process-math">\(\bar{X}_{100} \approx 0.51\text{,}\)</span> and for <span class="process-math">\(n = 10,000\text{,}\)</span> <span class="process-math">\(\bar{X}_{10,000} \approx 0.5002\text{.}\)</span> As <span class="process-math">\(n\)</span> increases, <span class="process-math">\(\bar{X}_n\)</span> gets closer to <span class="process-math">\(\mu = 0.5\text{,}\)</span> illustrating the LLN. The Strong LLN guarantees this convergence occurs almost surely.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Law-of-Large-Numbers-6">
<em class="alert">Visualization:</em> The following figure shows the sample mean of rolls of a fair six-sided die (with true mean <span class="process-math">\(\mu = (1+2+3+4+5+6)/6 = 3.5\)</span>) for increasing <span class="process-math">\(n\text{,}\)</span> converging to <span class="process-math">\(3.5\text{.}\)</span> <figure class="figure figure-like" id="fig-die-rolls-sample-mean-vs-true-mean"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/die-rolls-sample-mean-vs-true-mean.png" class="contained" alt="Sample means of die rolls converging to 3.5."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.8.1<span class="period">.</span></span><span class="space"> </span>Illustration of the Law of Large Numbers: Sample means of fair six-sided die rolls converge to the true mean <span class="process-math">\(\mu = 3.5\)</span> as <span class="process-math">\(n\)</span> increases.<div class="autopermalink" data-description="Figure 1.8.1"><a href="#fig-die-rolls-sample-mean-vs-true-mean" title="Copy heading and permalink for Figure 1.8.1" aria-label="Copy heading and permalink for Figure 1.8.1">üîó</a></div></figcaption></figure><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Law-of-Large-Numbers-6" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.1: Law of Large Numbers"><a href="#subsec-Law-of-Large-Numbers" title="Copy heading and permalink for Subsection 1.8.1: Law of Large Numbers" aria-label="Copy heading and permalink for Subsection 1.8.1: Law of Large Numbers">üîó</a></div></section><section class="subsection" id="subsec-Central-Limit-Theorem"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.2</span><span class="space"> </span><span class="title">Central Limit Theorem</span>
</h3>
<div class="para logical" id="subsec-Central-Limit-Theorem-2">
<div class="para">The CLT states that for i.i.d. random variables <span class="process-math">\(X_1, X_2, \dots, X_n\)</span> with finite mean <span class="process-math">\(\mu\)</span> and variance <span class="process-math">\(\sigma^2\text{,}\)</span> the distribution of the sample mean <span class="process-math">\(\bar{X}_n\)</span> becomes approximately normal as <span class="process-math">\(n\)</span> increases:</div>
<div class="displaymath process-math" id="eqn-CLT">
\begin{equation}
\bar{X}_n \xrightarrow{d} \mathcal{N}\left( \mu, \frac{\sigma^2}{n} \right),\tag{1.8.2}
\end{equation}
</div>
<div class="para">where <span class="process-math">\(\xrightarrow{d}\)</span> denotes convergence in distribution. Equivalently, the standardized sample mean:</div>
<div class="displaymath process-math" id="eqn-the-Zn-variable">
\begin{equation}
\bar{Z}_n = \frac{\sqrt{n} (\bar{X}_n - \mu)}{\sigma},\tag{1.8.3}
\end{equation}
</div>
<div class="para">converges to a standard normal distribution:</div>
<div class="displaymath process-math" id="eqn-the-normalized-CLT">
\begin{equation}
\bar{Z}_n \xrightarrow{d} \mathcal{N}(0, 1).\tag{1.8.4}
\end{equation}
</div>
<div class="para">The probability density of <span class="process-math">\(\bar{X}_n\)</span> for large <span class="process-math">\(n\)</span> is approximately:</div>
<div class="displaymath process-math">
\begin{equation*}
f_{\bar{X}_n}(x) \approx \frac{1}{\sqrt{2\pi \sigma^2 / n}} \exp\left( -\frac{(x - \mu)^2}{2 \sigma^2 / n} \right).
\end{equation*}
</div>
<div class="para">The cumulative distribution function (CDF) of <span class="process-math">\(\bar{Z}_n\)</span> is:</div>
<div class="displaymath process-math">
\begin{equation*}
P(\bar{Z}_n \leq z) \approx \Phi(z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}} \exp\left( -\frac{t^2}{2} \right) dt.
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Central-Limit-Theorem-3">The CLT is remarkable because it holds regardless of the underlying distribution of <span class="process-math">\(X_i\)</span> (e.g., Bernoulli, exponential, or normal), as long as <span class="process-math">\(\mu\)</span> and <span class="process-math">\(\sigma^2\)</span> are finite. This explains why normal distributions appear in phenomena like measurement errors, test scores, or heights, which are aggregates of many small random effects.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Central-Limit-Theorem-4">
<em class="alert">Example:</em> For an exponential distribution with rate <span class="process-math">\(\lambda = 1\)</span> (mean <span class="process-math">\(\mu = 1\text{,}\)</span> variance <span class="process-math">\(\sigma^2 = 1\)</span>), the sample mean of <span class="process-math">\(n = 100\)</span> observations is approximately <span class="process-math">\(\mathcal{N}(1, 1/100)\text{.}\)</span> The CLT allows us to compute probabilities, such as <span class="process-math">\(P(\bar{X}_{100} &lt; 1.1)\text{,}\)</span> using the normal distribution.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Central-Limit-Theorem-5">
<em class="alert">Visualization:</em> <a href="sec-LLN-and-CLT.html#fig-clt-convergence" class="xref" data-knowl="./knowl/xref/fig-clt-convergence.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.8.2">Figure¬†1.8.2</a> shows histograms of <span class="process-math">\(\bar{X}_n\)</span> for a fair six-sided die for different sample sizes, illustrating convergence to a normal distribution. <figure class="figure figure-like" id="fig-clt-convergence"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/clt-convergence.png" class="contained" alt="Histograms showing CLT convergence for die rolls."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.8.2<span class="period">.</span></span><span class="space"> </span>Histograms of sample means of fair six-sided die rolls for <span class="process-math">\(n = 10, 100, 500\text{,}\)</span> visually showing convergence to a normal distribution per the CLT.<div class="autopermalink" data-description="Figure 1.8.2"><a href="#fig-clt-convergence" title="Copy heading and permalink for Figure 1.8.2" aria-label="Copy heading and permalink for Figure 1.8.2">üîó</a></div></figcaption></figure><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Central-Limit-Theorem-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.2: Central Limit Theorem"><a href="#subsec-Central-Limit-Theorem" title="Copy heading and permalink for Subsection 1.8.2: Central Limit Theorem" aria-label="Copy heading and permalink for Subsection 1.8.2: Central Limit Theorem">üîó</a></div></section><section class="subsection" id="subsec-LLN-vs-CLT"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.3</span><span class="space"> </span><span class="title">LLN vs. CLT</span>
</h3>
<div class="para logical" id="subsec-LLN-vs-CLT-2">
<div class="para">The LLN and CLT are complementary:</div>
<ul class="disc" id="subsec-LLN-vs-CLT-2-1">
<li id="subsec-LLN-vs-CLT-2-1-1">
<div class="para" id="subsec-LLN-vs-CLT-2-1-1-1">
<em class="alert">LLN:</em> Ensures that <span class="process-math">\(\bar{X}_n \to \mu\)</span> (in probability or almost surely), describing the convergence of the sample mean to the true mean.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-LLN-vs-CLT-2-1-1-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-LLN-vs-CLT-2-1-1" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">üîó</a></div>
</li>
<li id="subsec-LLN-vs-CLT-2-1-2">
<div class="para" id="subsec-LLN-vs-CLT-2-1-2-1">
<em class="alert">CLT:</em> Describes the distribution of fluctuations around <span class="process-math">\(\mu\text{,}\)</span> stating that <span class="process-math">\(\sqrt{n} (\bar{X}_n - \mu) / \sigma \xrightarrow{d} \mathcal{N}(0, 1)\text{,}\)</span> with deviations of order <span class="process-math">\(1/\sqrt{n}\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-LLN-vs-CLT-2-1-2-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-LLN-vs-CLT-2-1-2" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">üîó</a></div>
</li>
</ul>
<div class="para">In essence, the LLN tells us where the sample mean goes, while the CLT tells us how it fluctuates around that value.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-LLN-vs-CLT-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.3: LLN vs. CLT"><a href="#subsec-LLN-vs-CLT" title="Copy heading and permalink for Subsection 1.8.3: LLN vs. CLT" aria-label="Copy heading and permalink for Subsection 1.8.3: LLN vs. CLT">üîó</a></div></section><section class="subsection" id="subsec-Berry-Esseen"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.4</span><span class="space"> </span><span class="title">Berry-Esseen Theorem</span>
</h3>
<div class="para logical" id="subsec-Berry-Esseen-2">
<div class="para">The CLT states that <span class="process-math">\(\bar{X}_n\)</span> is approximately normal for large <span class="process-math">\(n\text{,}\)</span> but how large must <span class="process-math">\(n\)</span> be? The Berry-Esseen Theorem quantifies the rate of convergence. Let <span class="process-math">\(S_n = \frac{X_1 + \cdots + X_n - n\mu}{\sigma \sqrt{n}}\)</span> be the standardized sum, with CDF <span class="process-math">\(F_n(x) = P(S_n \leq x)\text{.}\)</span> The theorem states:</div>
<div class="displaymath process-math" id="eqn-Berry-Esseen-Theorem">
\begin{equation}
\sup_{x \in \mathbb{R}} |F_n(x) - \Phi(x)| \leq \frac{C \rho}{\sigma^3 \sqrt{n}},\tag{1.8.5}
\end{equation}
</div>
<div class="para">where <span class="process-math">\(\rho = E[|X_i - \mu|^3]\)</span> is the third absolute moment, <span class="process-math">\(\Phi(x)\)</span> is the standard normal CDF, and <span class="process-math">\(C\)</span> is a constant (<span class="process-math">\(C \leq 0.4748\text{,}\)</span> Shevtsova 2011). This implies that the error in the normal approximation decreases as <span class="process-math">\(1/\sqrt{n}\text{,}\)</span> modulated by the ‚Äútail-heaviness‚Äù factor <span class="process-math">\(\rho / \sigma^3\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Berry-Esseen-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Berry-Esseen-3">For example, for a fair six-sided die, <span class="process-math">\(\rho\)</span> is finite, and for <span class="process-math">\(n = 100\text{,}\)</span> the approximation error is small, ensuring reliable use of the CLT in practice.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Berry-Esseen-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.4: Berry-Esseen Theorem"><a href="#subsec-Berry-Esseen" title="Copy heading and permalink for Subsection 1.8.4: Berry-Esseen Theorem" aria-label="Copy heading and permalink for Subsection 1.8.4: Berry-Esseen Theorem">üîó</a></div></section><section class="subsection" id="subsec-Why-Large-n-Matters"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.8.5</span><span class="space"> </span><span class="title">Why LLN and CLT Matter</span>
</h3>
<div class="para" id="subsec-Why-Large-n-Matters-2">
<em class="alert">LLN Applications:</em> The LLN justifies using sample means to estimate population means. For example, in polling, we survey a sample to estimate voter preferences. The LLN ensures that with a large enough sample, the sample mean is close to the true population mean.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-3">Consider rolling a fair six-sided die with true mean <span class="process-math">\(\mu = (1+2+3+4+5+6)/6 = 3.5\)</span> and variance <span class="process-math">\(\sigma^2 = \frac{1}{6} \sum_{i=1}^6 (i - 3.5)^2 = \frac{35}{12} \approx 2.9167\text{.}\)</span> For <span class="process-math">\(n = 100\)</span> rolls, suppose we compute <span class="process-math">\(\bar{X}_{100} = 3.6\text{.}\)</span> The LLN suggests <span class="process-math">\(\bar{X}_{100} \approx 3.5\text{.}\)</span> <a href="sec-LLN-and-CLT.html#fig-die-rolls-sample-mean-vs-true-mean" class="xref" data-knowl="./knowl/xref/fig-die-rolls-sample-mean-vs-true-mean.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.8.1">Figure¬†1.8.1</a>illustrates this convergence.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-4">In statistical mechanics, the LLN applies to time averages in ergodic systems, ensuring that long-term observations of a particle‚Äôs behavior approximate the population average.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para logical" id="subsec-Why-Large-n-Matters-5">
<div class="para">
<em class="alert">CLT and Confidence Intervals:</em> The CLT enables us to quantify uncertainty in sample means via confidence intervals. For the die example, suppose we roll <span class="process-math">\(n = 100\)</span> times and compute <span class="process-math">\(\bar{X}_{100} = 3.6\)</span> and sample standard deviation <span class="process-math">\(s = \sqrt{\frac{1}{99} \sum_{i=1}^{100} (X_i - 3.6)^2}\text{.}\)</span> The CLT implies:</div>
<div class="displaymath process-math" id="eqn-clt-gaussian-approx">
\begin{equation}
\bar{X}_n \approx \mathcal{N}\left( \mu, \frac{\sigma^2}{n} \right).\tag{1.8.6}
\end{equation}
</div>
<div class="para">Using the sample standard deviation <span class="process-math">\(s \approx \sqrt{2.9167} \approx 1.7078\text{,}\)</span> the standard error is <span class="process-math">\(s / \sqrt{n} \approx 1.7078 / \sqrt{100} = 0.17078\text{.}\)</span> A 95% confidence interval is:</div>
<div class="displaymath process-math">
\begin{equation*}
\bar{X}_n \pm z_{0.975} \cdot \frac{s}{\sqrt{n}} \approx 3.6 \pm 1.96 \cdot 0.17078 \approx [3.265, 3.935].
\end{equation*}
</div>
<div class="para">This interval suggests that we are 95% confident that <span class="process-math">\(\mu\)</span> lies between 3.265 and 3.935, consistent with the true mean <span class="process-math">\(\mu = 3.5\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-6">
<em class="alert">Simulation:</em> The following Python code simulates 10,000 trials of 100 die rolls, computes sample means, and plots a histogram with a 95% confidence interval: <div class="code-box"><pre class="program clipboardable"><code class="language-py">import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Step 1: Simulate dice rolls
np.random.seed(42)
n_trials = 10000
n_rolls = 100
data = np.random.randint(1, 7, size=(n_trials, n_rolls))
sample_means = data.mean(axis=1)

# Step 2: Compute 95% CI
mean_est = np.mean(sample_means)
std_est = np.std(sample_means, ddof=1)
z_975 = norm.ppf(0.975)
margin = z_975 * std_est
ci_lower, ci_upper = mean_est - margin, mean_est + margin

print(f"Estimated mean = {mean_est:.3f}")
print(f"95% CI ‚âà [{ci_lower:.3f}, {ci_upper:.3f}]")

# Step 3: Plot histogram with CI
fig, ax = plt.subplots(figsize=(8,5))
counts, bins, patches = ax.hist(sample_means, bins=50, density=True, 
                                alpha=0.6, color='skyblue', edgecolor='black')
plt.axvline(mean_est, color='red', linestyle='--', label="Mean of sample means")
plt.axvline(ci_lower, color='black', linestyle='dashed', label="95% CI")
plt.axvline(ci_upper, color='black', linestyle='dashed')
y_arrow = counts.max() / 3
plt.annotate('', xy=(ci_lower, y_arrow), xytext=(ci_upper, y_arrow),
             arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=2))
plt.text(mean_est, y_arrow * 1.1, "95% CI", ha='center', fontsize=12)
plt.title("Sampling Distribution of Dice Means (100 rolls, 10,000 trials)")
plt.xlabel("Sample Mean")
plt.ylabel("Density")
plt.legend()
plt.show()
</code></pre></div> <figure class="figure figure-like" id="fig-confidence-interval-die-roll"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/confidence-interval-die-roll.png" class="contained" alt="Histogram of die roll sample means with 95% CI."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.8.3<span class="period">.</span></span><span class="space"> </span>Histogram of sample means from 10,000 trials of 100 fair six-sided die rolls, with a 95% confidence interval (dashed lines and arrow) around the estimated mean.<div class="autopermalink" data-description="Figure 1.8.3"><a href="#fig-confidence-interval-die-roll" title="Copy heading and permalink for Figure 1.8.3" aria-label="Copy heading and permalink for Figure 1.8.3">üîó</a></div></figcaption></figure><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-6" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="para" id="subsec-Why-Large-n-Matters-7">
<em class="alert">Other Applications:</em> The CLT is crucial for hypothesis testing (e.g., z-tests) and approximating probabilities for sums of random variables, such as total customer purchases in a store.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Why-Large-n-Matters-7" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">üîó</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.8.5: Why LLN and CLT Matter"><a href="#subsec-Why-Large-n-Matters" title="Copy heading and permalink for Subsection 1.8.5: Why LLN and CLT Matter" aria-label="Copy heading and permalink for Subsection 1.8.5: Why LLN and CLT Matter">üîó</a></div></section><div class="autopermalink" data-description="Section 1.8: Law of Large Numbers and Central Limit Theorem"><a href="#sec-LLN-and-CLT" title="Copy heading and permalink for Section 1.8: Law of Large Numbers and Central Limit Theorem" aria-label="Copy heading and permalink for Section 1.8: Law of Large Numbers and Central Limit Theorem">üîó</a></div></section></div>
<div id="ptx-content-footer" class="ptx-content-footer">
<a class="previous-button button" href="sec-Example-Continuous-Probability-Distributions.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Top</span></a><a class="next-button button" href="sec-Inferential-Statistics.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" height="100%" viewBox="338 3000 8772 6866" role="img"><title>PreTeXt logo</title><g style="stroke-width:.025in; stroke:currentColor; fill:none"><polyline points="472,3590 472,9732 " style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png" alt="Runstone Academy logo"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png" alt="MathJax logo"></a>
</div>
</body>
</html>
