<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<!--******************************************-->
<!--*  Authored with PreTeXt                 *-->
<!--*  pretextbook.org                       *-->
<!--*  Theme: default-modern                 *-->
<!--*  Palette:                              *-->
<!--******************************************-->
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Two or More Random Variables</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0">
<link href="_static/pretext/css/theme.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/ol-markers.css" rel="stylesheet" type="text/css">
<script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math"
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "_static/pretext/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="ML Notes">
<meta property="book:author" content="Samuel Ling">
<script src="_static/pretext/js/lib/jquery.min.js"></script><script src="_static/pretext/js/lib/jquery.sticky.js"></script><script src="_static/pretext/js/lib/jquery.espy.min.js"></script><script src="_static/pretext/js/pretext.js"></script><script src="_static/pretext/js/pretext_add_on.js?x=1"></script><script src="_static/pretext/js/user_preferences.js"></script><!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX_Course_Title_Here';
eBookConfig.basecourse = 'PTX_Base_Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.runestone_version = '7.9.8';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script src="_static/prefix-runtime.b215b0da62d655bd.bundle.js"></script><script src="_static/prefix-723.3e6434f80549315a.bundle.js"></script><script src="_static/prefix-runestone.28cc3c4821792be5.bundle.js"></script><link rel="stylesheet" type="text/css" href="_static/prefix-723.3bccd435914aa0ff.css">
<link rel="stylesheet" type="text/css" href="_static/prefix-runestone.8141ae22fd347e48.css">
<script src="_static/pretext/js/lti_iframe_resizer.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.js" integrity="sha512-dubtf8xMHSQlExGRQ5R7toxHLgSDZ0K7AunqPWHXmJQ8XyVIG19S1T95gBxlAeGOK02P4Da2RTnQz0Za0H0ebQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-highlight/prism-line-highlight.min.js" integrity="sha512-93uCmm0q+qO5Lb1huDqr7tywS8A2TFA+1/WHvyiWaK6/pvsFl6USnILagntBx8JnVbQH5s3n0vQZY6xNthNfKA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="_static/pretext/js/pretext_search.js"></script><script src="_static/pretext/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script>
</head>
<body id="ML-Notes" class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner"><div class="title-container">
<h1 class="heading"><a href="my-ML-Notes.html"><span class="title">ML Notes</span> <span class="subtitle">Theoretical and Practical ML Concepts</span></a></h1>
<p class="byline">Samuel Ling</p>
</div></div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><div class="ptx-navbar-contents">
<button class="toc-toggle button" title="Contents"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5d2;</span><span class="name">Contents</span></button><div class="searchbox">
<div class="searchwidget"><button id="searchbutton" class="searchbutton button" type="button" title="Search book"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe8b6;</span><span class="name">Search Book</span></button></div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<div class="search-results-controls">
<input aria-label="Search term" id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search term"><button title="Close search" id="closesearchresults" class="closesearchresults"><span class="material-symbols-outlined">close</span></button>
</div>
<h2 class="search-results-heading">Search Results: </h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div>
<span class="nav-other-controls"><button id="light-dark-button" class="light-dark-button button" title="Dark Mode"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe51c;</span><span class="name">Dark Mode</span></button></span><span class="treebuttons"><a class="previous-button button" href="sec-Random-Variables-and-Probabilities.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="up-button button" href="ch-Essential-Probability-and-Statistics.html" title="Up"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Up</span></a><a class="next-button button" href="sec-Example-Discrete-Probability-Distributions.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a></span>
</div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\N}{\mathbb N} \newcommand{\Z}{\mathbb Z} \newcommand{\Q}{\mathbb Q} \newcommand{\R}{\mathbb R}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2 focused" data-preexpanded-levels="0" data-max-levels="2"><ul class="structural toc-item-list contains-active">
<li class="toc-item toc-frontmatter"><div class="toc-title-box"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div></li>
<li class="toc-item toc-chapter contains-active">
<div class="toc-title-box"><a href="ch-Essential-Probability-and-Statistics.html" class="internal"><span class="codenumber">1</span> <span class="title">Essential Probability and Statistics</span></a></div>
<ul class="structural toc-item-list contains-active">
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Descriptive-Statistics.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Descriptive Statistics</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#subsec-Central-Tendency" class="internal"><span class="codenumber">1.1.1</span> <span class="title">Measures of Central Tendency</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#subsec-Dispersion" class="internal"><span class="codenumber">1.1.2</span> <span class="title">Measures of Dispersion</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#subsec-Distribution-Shape" class="internal"><span class="codenumber">1.1.3</span> <span class="title">Distribution Shape</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis" class="internal"><span class="codenumber">1.1.4</span> <span class="title">Kurtosis: Checking Out the Tails</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#types-of-kurtosis" class="internal"><span class="codenumber">1.1.4.1</span> <span class="title">Types of Kurtosis</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-formula" class="internal"><span class="codenumber">1.1.4.2</span> <span class="title">Howâ€™s It Calculated?</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-examples" class="internal"><span class="codenumber">1.1.4.3</span> <span class="title">Real-World Examples</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-visual" class="internal"><span class="codenumber">1.1.4.4</span> <span class="title">Seeing Kurtosis in Action</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-python" class="internal"><span class="codenumber">1.1.4.5</span> <span class="title">Calculating Kurtosis with Python</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Descriptive-Statistics.html#kurtosis-wrapup" class="internal"><span class="codenumber">1.1.4.6</span> <span class="title">Why Kurtosis Matters</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Computation and Visualization Tools</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#sec-useful-descriptive-statistics-tools-3" class="internal"><span class="codenumber">1.2.1</span> <span class="title">The Power of NumPy and SciPy</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#subsec-Pandas" class="internal"><span class="codenumber">1.2.2</span> <span class="title">Pandas: Data Manipulation and Analysis</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-useful-descriptive-statistics-tools.html#subsec-Visualization" class="internal"><span class="codenumber">1.2.3</span> <span class="title">Visualization with Matplotlib and Seaborn</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Numerical-and-Categorical-Data.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Numerical and Categorical Data</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Numerical-and-Categorical-Data.html#subsec-Categorical-Data" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Categorical Data and One-Hot Encoding</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Numerical-and-Categorical-Data.html#subsec-Ordinal-Data" class="internal"><span class="codenumber">1.3.2</span> <span class="title">Ordinal Data and Safe Encoding</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Numerical-and-Categorical-Data.html#subsec-Numerical-Data" class="internal"><span class="codenumber">1.3.3</span> <span class="title">Numerical Data: Discrete vs Continuous</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Numerical-and-Categorical-Data.html#subsec-data-type-summary" class="internal"><span class="codenumber">1.3.4</span> <span class="title">Data Type Summary</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Basic-Probability.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Basic Probability for Machine Learning</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-Axiomatic-View-of-Probability" class="internal"><span class="codenumber">1.4.1</span> <span class="title">Axiomatic View of Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-sum-product-rules" class="internal"><span class="codenumber">1.4.2</span> <span class="title">Sum and Product Rules for Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-conditional-probability-independence" class="internal"><span class="codenumber">1.4.3</span> <span class="title">Conditional Probability and Independence</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-probability-distributions" class="internal"><span class="codenumber">1.4.4</span> <span class="title">Probability Distributions</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Basic-Probability.html#subsec-three-types-of-probabilities" class="internal"><span class="codenumber">1.4.5</span> <span class="title">Three Types of Probabilities</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Random-Variables-and-Probabilities.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Random Variables and Probabilities</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Random-Variables-and-Probabilities.html#subsec-Random-Variables" class="internal"><span class="codenumber">1.5.1</span> <span class="title">Random Variables, Probabilities, and Expectations</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Random-Variables-and-Probabilities.html#subsec-Probability-Mass-Function" class="internal"><span class="codenumber">1.5.2</span> <span class="title">Probability Mass Function</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Random-Variables-and-Probabilities.html#subsec-Expectation-Values" class="internal"><span class="codenumber">1.5.3</span> <span class="title">Expectation Values</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Random-Variables-and-Probabilities.html#subsec-Probability-Distribution-of-Continuous-Variable" class="internal"><span class="codenumber">1.5.4</span> <span class="title">Probability Density of Continuous Variables</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Random-Variables-and-Probabilities.html#subsec-Cumulative-Distribution-Function" class="internal"><span class="codenumber">1.5.5</span> <span class="title">Cumulative Distribution Function (CDF)</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section contains-active">
<div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Two or More Random Variables</span></a></div>
<ul class="structural toc-item-list active">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Joint-Probability" class="internal"><span class="codenumber">1.6.1</span> <span class="title">Joint Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Marginal-Probability" class="internal"><span class="codenumber">1.6.2</span> <span class="title">Marginal Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Conditional-Probability" class="internal"><span class="codenumber">1.6.3</span> <span class="title">Conditional Probability</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-conditional-probability-from-joint-probability" class="internal"><span class="codenumber">1.6.4</span> <span class="title">Bayesâ€™ Rule</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Covariance-and-Correlation" class="internal"><span class="codenumber">1.6.5</span> <span class="title">Covariance and Correlation</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Continuous-Random-Variables" class="internal"><span class="codenumber">1.6.6</span> <span class="title">Continuous Random Variables</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsubsec-Probability-Density" class="internal"><span class="codenumber">1.6.6.1</span> <span class="title">Probability Density</span></a></div></li>
<li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsubsec-Cumulative-Distribution-Function" class="internal"><span class="codenumber">1.6.6.2</span> <span class="title">Cumulative Distribution Function</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Independent-Variables" class="internal"><span class="codenumber">1.6.7</span> <span class="title">Independent Random Variables</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Two-or-More-Random-Variables.html#subsec-Application-Medical-Diagnosis" class="internal"><span class="codenumber">1.6.8</span> <span class="title">Application: Medical Diagnosis</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Example Discrete Probability Distributions</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Bernoulli-Distribution" class="internal"><span class="codenumber">1.7.1</span> <span class="title">Bernoulli Distribution</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Binomial-Distribution" class="internal"><span class="codenumber">1.7.2</span> <span class="title">Binomial Distribution</span></a></div></li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsec-Poisson-Distribution" class="internal"><span class="codenumber">1.7.3</span> <span class="title">Poisson Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Discrete-Probability-Distributions.html#subsub-Poisson-Process" class="internal"><span class="codenumber">1.7.3.1</span> <span class="title">Poisson Process</span></a></div></li></ul>
</li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html" class="internal"><span class="codenumber">1.8</span> <span class="title">Example Continuous Probability Distributions</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Uniform-Distribution" class="internal"><span class="codenumber">1.8.1</span> <span class="title">Uniform Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsubsec-Inverse-Uniform-CDF" class="internal"><span class="codenumber">1.8.1.1</span> <span class="title">Inverse Uniform CDF</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection">
<div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Normal-Distribution" class="internal"><span class="codenumber">1.8.2</span> <span class="title">Normal (Gaussian) Distribution</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsubsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsubsec-Inverse-CDF-and-Sampling" class="internal"><span class="codenumber">1.8.2.1</span> <span class="title">Inverse CDF and Sampling</span></a></div></li></ul>
</li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Example-Continuous-Probability-Distributions.html#subsec-Exponential-Distribution" class="internal"><span class="codenumber">1.8.3</span> <span class="title">Exponential Distribution</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-LLN-and-CLT.html" class="internal"><span class="codenumber">1.9</span> <span class="title">Law of Large Numbers and Central Limit Theorem</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Law-of-Large-Numbers" class="internal"><span class="codenumber">1.9.1</span> <span class="title">Law of Large Numbers</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Central-Limit-Theorem" class="internal"><span class="codenumber">1.9.2</span> <span class="title">Central Limit Theorem</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-LLN-vs-CLT" class="internal"><span class="codenumber">1.9.3</span> <span class="title">LLN vs. CLT</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Berry-Esseen" class="internal"><span class="codenumber">1.9.4</span> <span class="title">Berry-Esseen Theorem</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-LLN-and-CLT.html#subsec-Why-Large-n-Matters" class="internal"><span class="codenumber">1.9.5</span> <span class="title">Why LLN and CLT Matter</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-Inferential-Statistics.html" class="internal"><span class="codenumber">1.10</span> <span class="title">Inferential Statistics</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Point-Estimation" class="internal"><span class="codenumber">1.10.1</span> <span class="title">Point Estimation</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Sampling-Distributions" class="internal"><span class="codenumber">1.10.2</span> <span class="title">Sampling Distributions</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Hypothesis-Testing" class="internal"><span class="codenumber">1.10.3</span> <span class="title">Hypothesis Testing</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Confidence-Intervals" class="internal"><span class="codenumber">1.10.4</span> <span class="title">Confidence Intervals</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Types-of-Errors" class="internal"><span class="codenumber">1.10.5</span> <span class="title">Types of Errors</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Power-Effect-Size" class="internal"><span class="codenumber">1.10.6</span> <span class="title">Statistical Power and Effect Size</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Multiple-Testing" class="internal"><span class="codenumber">1.10.7</span> <span class="title">Multiple Testing</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-Inferential-Statistics.html#subsec-Other-Tests" class="internal"><span class="codenumber">1.10.8</span> <span class="title">Common Statistical Tests</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li class="toc-item toc-backmatter"><div class="toc-title-box"><a href="backmatter.html" class="internal"><span class="title">Backmatter</span></a></div></li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-Two-or-More-Random-Variables"><h2 class="heading hide-type">
<span class="type">Section</span><span class="space"> </span><span class="codenumber">1.6</span><span class="space"> </span><span class="title">Two or More Random Variables</span>
</h2>
<section class="introduction" id="sec-Two-or-More-Random-Variables-2"><div class="para logical" id="sec-Two-or-More-Random-Variables-2-1">
<div class="para">Suppose we have two or more random variables that characterize our data. For example, we may be interested in studying heights and weights and weights of all children in age <span class="process-math">\(1\)</span> to <span class="process-math">\(18\text{.}\)</span> Our probabilities of interest will look like</div>
<div class="displaymath process-math">
\begin{equation*}
P( 2\,\text{ft} \le \text{Height} \le 4\,\text{ft}\quad \textrm{AND}\quad  20\,\text{kg} \le \text{Weight} \le 50\,\text{kg} ).
\end{equation*}
</div>
<div class="para">This kind of probability is called a <dfn class="terminology">joint probability</dfn> - it is probability of two events together. You might think of the expressions on either side of <span class="process-math">\(\textrm{AND}\)</span> as events <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> and replace <span class="process-math">\(\textrm{AND}\)</span> by the set symbol <span class="process-math">\(\cap\text{,}\)</span> and write it more abstractly as</div>
<div class="displaymath process-math">
\begin{equation*}
P( A \cap B).
\end{equation*}
</div>
<div class="para">Or, more generally, you might think of this as a statement about random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> and write it as</div>
<div class="displaymath process-math">
\begin{equation*}
P(X,Y).
\end{equation*}
</div>
<div class="para">Sometimes, a more verbose notation is used:</div>
<div class="displaymath process-math">
\begin{equation*}
P_{X,Y}(x,y).
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#sec-Two-or-More-Random-Variables-2-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="sec-Two-or-More-Random-Variables-2-2">
<div class="para">We may also be interested in just to probability of some range of Height itself, regardless of the weights.</div>
<div class="displaymath process-math">
\begin{equation*}
P( 2\,\text{ft} \le \text{Height} \le 4\,\text{ft} ) \equiv P(A) \equiv P(X) \equiv P_X(x).
\end{equation*}
</div>
<div class="para">Since we have collected data on two variables, but we are looking at only one of the variables, we say that we have <em class="alert">margined out</em> the weight variable. This type of probability is called <dfn class="terminology">marginal probability</dfn>, here of Height.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#sec-Two-or-More-Random-Variables-2-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="sec-Two-or-More-Random-Variables-2-3">
<div class="para">We may instead be interested in a more complicated type of probaility: what if we look at children of Weight between <span class="process-math">\(20\text{ kg}\)</span> and <span class="process-math">\(50\text{ kg}\text{,}\)</span> what will be the probability of a Height range?</div>
<div class="displaymath process-math">
\begin{equation*}
\text{ Given } \left( 20\,\text{kg} \le \text{Weight} \le 50\,\text{kg}\right),\ P( 2\,\text{ft} \le \text{Height} \le 4\,\text{ft} ) = ?
\end{equation*}
</div>
<div class="para">We write these using a different symbol to indicate the constraining part of this sentence, i.e, the given part.</div>
<div class="displaymath process-math">
\begin{equation*}
P( \left( 2\,\text{ft} \le \text{Height} \le 4\,\text{ft}\right) \mid  \left( 20\,\text{kg} \le \text{Weight} \le 40 \right) ) \equiv P (X \mid Y)\equiv P_{X\mid Y}(x).
\end{equation*}
</div>
<div class="para">Or, we may be interested in a question that is other way around,</div>
<div class="displaymath process-math">
\begin{equation*}
P( \left( 20\,\text{kg} \le \text{Weight} \le 40 \right) \mid  \left( 2\,\text{ft} \le \text{Height} \le 4\,\text{ft}\right)  ) \equiv P (Y \mid X) \equiv P_{Y\mid X}(y).
\end{equation*}
</div>
<div class="para">The answers to the two questions will be different since you would be selcting different distibutions based on the given condition; <span class="process-math">\(P_{X\mid Y}(x)\)</span> is probability in the <span class="process-math">\(X\)</span>-space and <span class="process-math">\(P_{Y\mid X}(y)\)</span> is probability in the <span class="process-math">\(Y\)</span>-space. These types of probability are called <dfn class="terminology">Conditional Probability</dfn>. Conditional probability plays an important role in Machine Learning Algorithms.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#sec-Two-or-More-Random-Variables-2-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para" id="sec-Two-or-More-Random-Variables-2-4">Below, we will look at these probabilities in more detail.<div class="autopermalink" data-description="Paragraph"><a href="#sec-Two-or-More-Random-Variables-2-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div></section><section class="subsection" id="subsec-Joint-Probability"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.1</span><span class="space"> </span><span class="title">Joint Probability</span>
</h3>
<div class="para" id="subsec-Joint-Probability-2">Now, letâ€™s dig in a little deeper into joint probability and work out an example.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Joint-Probability-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="subsec-Joint-Probability-3">
<div class="para">Suppose we have two discrete random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\text{.}\)</span> Suppose the unique values that <span class="process-math">\(A\)</span> can take are <span class="process-math">\(a_1, a_2, \cdots, a_m\)</span> and <span class="process-math">\(B\)</span> can take are <span class="process-math">\(b_1, b_2, \cdots, b_n\text{.}\)</span> Then, the pair <span class="process-math">\((A, B)\)</span> can take <span class="process-math">\(m\times n \)</span> value pairs <span class="process-math">\((a_i, b_j)\)</span> with <span class="process-math">\(1 \le i \le m\)</span> and <span class="process-math">\(1 \le j \le n\text{.}\)</span> Joint porbability  <span class="process-math">\(P(A,B)\text{,}\)</span> i.e., the Joint PMF, assigns probabilities to every unique pairs <span class="process-math">\((a_i, b_j)\)</span> so that they are normalized to sum to <span class="process-math">\(1\text{.}\)</span>
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" id="eqn-discrete-joint-probability">
\begin{equation}
P(A=a_i, B=b_j) = p_{ij}, \quad \sum_i \sum_j p_{ij} = 1.\tag{1.6.1}
\end{equation}
</div>
<div class="para">If you are dealing with continuous variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\text{,}\)</span> then we can only talk about probabilities in ranges since both <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> take values on the real line <span class="process-math">\(\mathbb{R}\text{.}\)</span> Here, the space of all possibilities will be the <span class="process-math">\(xy\)</span>-plane, which is <span class="process-math">\(\mathbb{R}^2\text{.}\)</span> Thus joint probability in an infinitesimal rectangle will be</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" id="eqn-continuous-joint-probability">
\begin{equation}
P(x \le X \le x+dx, y \le Y \le y+dy) = \rho(x,y)\,dxdy,\tag{1.6.2}
\end{equation}
</div>
<div class="para">where the Joint PDF <span class="process-math">\(\rho(x,y)\)</span> wil be normalized by the following integral:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
\int_{-\infty}^\infty \int_{-\infty}^\infty\,\rho(x,y)\,dxdy= 1.
\end{equation*}
</div>
<div class="para">In a weird way the Joint PMF <span class="process-math">\(p_{ij}\)</span> of the discrete case corresponds to a  the Joint PDF except that you need to take integral of the later in place of sum for the PMF.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" id="eqn-Joint-PMF-Joint-PDF-correspondence">
\begin{equation}
\text{Discrete : PMF, Sum} \longleftrightarrow \text{Continuous : PDF, Integral}.\tag{1.6.3}
\end{equation}
</div>
<div class="para"><article class="example example-like" id="ex-Patient-disease-and-test-results"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.1</span><span class="period">.</span><span class="space"> </span><span class="title">Patient disease and test results.</span>
</h4>
<div class="para logical" id="ex-Patient-disease-and-test-results-2">
<div class="para">Consider a dataset of 1,000 patients, with two discrete random variables <span class="process-math">\(X\)</span> indicating disease status and <span class="process-math">\(Y\)</span> indicating test result on a partcular test for the said disease. For each patient, the disease status variable <span class="process-math">\(X\)</span> has on of the two values:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
X = \begin{cases}
\textrm{D} \amp \text{if the patient has disease}\\
\textrm{N} \amp \text{if the patient has no disease}
\end{cases}
\end{equation*}
</div>
<div class="para">Similarly, the test result variable <span class="process-math">\(Y\)</span> for each patient has one of the two values</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
Y = \begin{cases}
+ \amp \text{if the test was positive}\\
- \amp \text{if the test was negative}
\end{cases}
\end{equation*}
</div>
<div class="para">Suppose, in <span class="process-math">\(1000\)</span> people in the dataset you found <span class="process-math">\(150\)</span> people had tested positive and also had the disease. This will be the joint probability</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
p_{D+} = \frac{150}{1000} = 0.150.
\end{equation*}
</div>
<div class="para">Suppose, you found that <span class="process-math">\(50\)</span> patients who had the disease but somehow tested negative. That would be</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
p_{D-} = \frac{50}{1000} = 0.050
\end{equation*}
</div>
<div class="para">Now, it turned out that <span class="process-math">\(300\)</span> people who didnâ€™t have the disease but their tests came out positive.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
p_{N+} = \frac{300}{1000} = 0.300.
\end{equation*}
</div>
<div class="para">Finally, <span class="process-math">\(500\)</span> people that didnâ€™t have the disease were also found to be negative on the test.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html">
\begin{equation*}
p_{N-} = \frac{500}{1000} = 0.500.
\end{equation*}
</div>
<div class="para">These joint probabilities are usually organized in a table form as shown in <a href="sec-Two-or-More-Random-Variables.html#tab-Patient-Disease-and-Test-Results" class="xref" data-knowl="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" data-reveal-label="Reveal" data-close-label="Close" title="Table 1.6.2: Disease and Test Results">TableÂ 1.6.2</a>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#ex-Patient-disease-and-test-results-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<figure class="table table-like" id="tab-Patient-Disease-and-Test-Results"><figcaption><span class="type">Table</span><span class="space"> </span><span class="codenumber">1.6.2<span class="period">.</span></span><span class="space"> </span>Disease and Test Results<div class="autopermalink" data-description="Table 1.6.2: Disease and Test Results"><a href="#tab-Patient-Disease-and-Test-Results" title="Copy heading and permalink for Table 1.6.2: Disease and Test Results" aria-label="Copy heading and permalink for Table 1.6.2: Disease and Test Results">ðŸ”—</a></div></figcaption><div class="tabular-box natural-width"><table class="tabular">
<tr>
<td class="l m b3 r0 l0 t0 lines"></td>
<td class="l m b3 r0 l0 t0 lines"></td>
<td class="l m b3 r0 l0 t0 lines"></td>
</tr>
<tr>
<td class="l m b1 r1 l0 t0 lines"></td>
<td class="l m b1 r1 l0 t0 lines">Test: <span class="process-math">\(+\)</span>
</td>
<td class="l m b1 r0 l0 t0 lines">Test: <span class="process-math">\(-\)</span>
</td>
</tr>
<tr>
<td class="l m b0 r1 l0 t0 lines">Disease (D)</td>
<td class="l m b0 r1 l0 t0 lines"><span class="process-math">\(p_{D+} = 0.150\)</span></td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(p_{D-} = 0.050\)</span></td>
</tr>
<tr>
<td class="l m b3 r1 l0 t0 lines">No Disease (N)</td>
<td class="l m b3 r1 l0 t0 lines"><span class="process-math">\(p_{N+}=0.300\)</span></td>
<td class="l m b3 r0 l0 t0 lines"><span class="process-math">\(p_{N-}=0.500\)</span></td>
</tr>
</table></div></figure><div class="autopermalink" data-description="Example 1.6.1: Patient disease and test results"><a href="#ex-Patient-disease-and-test-results" title="Copy heading and permalink for Example 1.6.1: Patient disease and test results" aria-label="Copy heading and permalink for Example 1.6.1: Patient disease and test results">ðŸ”—</a></div></article></div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Joint-Probability-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Subsection 1.6.1: Joint Probability"><a href="#subsec-Joint-Probability" title="Copy heading and permalink for Subsection 1.6.1: Joint Probability" aria-label="Copy heading and permalink for Subsection 1.6.1: Joint Probability">ðŸ”—</a></div></section><section class="subsection" id="subsec-Marginal-Probability"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.2</span><span class="space"> </span><span class="title">Marginal Probability</span>
</h3>
<div class="para" id="subsec-Marginal-Probability-2">
<dfn class="terminology">Marginal probability</dfn> is an unconditional probability of a single event. for instance marginal probability of event <span class="process-math">\(A\)</span> is the same old regular probability of <span class="process-math">\(A\text{,}\)</span> viz. <span class="process-math">\(P(A)\)</span> we are aware of. In the context of joint probabilities, we use the phrase marginal probability. Outside of this context, it is just probability.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Marginal-Probability-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para" id="subsec-Marginal-Probability-3">So, what is itâ€™s relation to the joint probability? To present the answer, letâ€™s look at joint probability in the context of two discrete random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\text{,}\)</span> which take values in finite sets <span class="process-math">\(\{x_1, x_2, \cdots x_m \}\)</span>  and <span class="process-math">\(\{y_1, y_2, \cdots y_n \}\text{,}\)</span> respectively. Let <span class="process-math">\(P(X,Y)\)</span> be their joint probability, meaning collections of <span class="process-math">\(P(X=x_i,\,Y=y_j)\)</span> pairs. Marginalized probabilities will be probabilities of events like <span class="process-math">\(P(X=x_1)\text{,}\)</span> <span class="process-math">\(P(X=x_2)\text{,}\)</span> etc. without any consideration of the variable <span class="process-math">\(Y\text{.}\)</span> Or, alternatively, <span class="process-math">\(P(Y=y_1)\text{,}\)</span> <span class="process-math">\(P(Y=y_2)\text{,}\)</span> etc. without any consideration of the variable <span class="process-math">\(X\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Marginal-Probability-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="subsec-Marginal-Probability-4">
<div class="para">We can get <span class="process-math">\(P(X=x_1)\)</span> from <span class="process-math">\(P(X=x_1, Y=\text{any }y_j\text{.}\)</span> That means, we need to sum over all the values of <span class="process-math">\(Y\)</span> in <span class="process-math">\(P(X=x_1, Y=y)\text{.}\)</span> Rather than clutter the formula  we are going to use the following notation in equations.</div>
<div class="displaymath process-math">
\begin{equation*}
P(x_i, y_j) \equiv P(X=x_i,\, Y=y_j)
\end{equation*}
</div>
<div class="para">Therefore, marginal probability <span class="process-math">\(P(x_1) \equiv P(X=x_1)\text{:}\)</span>
</div>
<div class="displaymath process-math" id="eqn-Marginal-Prob-From-Joint-Prob">
\begin{equation}
P(x_1) = P(x_1, y_1) + P(x_1, y_2) + \cdots + P(x_1, y_n).\tag{1.6.4}
\end{equation}
</div>
<div class="para">For arbitrary <span class="process-math">\(x_i\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
P(x_i) = P(x_i, y_1) + P(x_i, y_2) + \cdots + P(x_i, y_n).
\end{equation*}
</div>
<div class="para">Of course, we can write this in a compact notation and drop the subscripts.</div>
<div class="displaymath process-math">
\begin{equation*}
P(x) = \sum_y\, P(x,y).
\end{equation*}
</div>
<div class="para">If <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> were continuois variables, we will work with the PDF and replace sum by an integral, in this case integral over <span class="process-math">\(y\text{.}\)</span>
</div>
<div class="displaymath process-math" id="eqn-marginal-continuous-from-joint-PDF">
\begin{equation}
\rho(x) = \int_{-\infty}^{\infty}\, \rho(x,y)\, dy.\tag{1.6.5}
\end{equation}
</div>
<div class="para">Note that we are using same symbol <span class="process-math">\(\rho\)</span> for TWO DIFFERENT PDFs. To remove the confusion, subscripts are used to remind the random variable names.</div>
<div class="displaymath process-math">
\begin{equation*}
\rho_X(x) = \int_{-\infty}^{\infty}\, \rho_{XY}(x,y)\, dy.
\end{equation*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Marginal-Probability-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsec-Marginal-Probability-5"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.3</span><span class="period">.</span><span class="space"> </span><span class="title">Marginal Probabilites from Joint Probability Table.</span>
</h4>
<div class="para logical" id="subsec-Marginal-Probability-5-2">
<div class="para">Letâ€™s work out Marginal probabilities <span class="process-math">\(P(D)\text{,}\)</span> <span class="process-math">\(P(N)\text{,}\)</span> <span class="process-math">\(P(+)\text{,}\)</span> anbd <span class="process-math">\(P(-)\)</span> from the joint probabilites given in <a href="sec-Two-or-More-Random-Variables.html#tab-Patient-Disease-and-Test-Results" class="xref" data-knowl="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" data-reveal-label="Reveal" data-close-label="Close" title="Table 1.6.2: Disease and Test Results">TableÂ 1.6.2</a>.</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" id="subsec-Marginal-Probability-5-2-6">
\begin{align*}
\amp P(D) = P(D, +) + P(D, -) = 0.150 + 0.050 = 0.200 \\
\amp P(N) = P(N, +) + P(N, -) = 0.300 + 0.500 = 0.800
\end{align*}
</div>
<div class="para">These make up the PMF of the random variable â€œDisease Statusâ€, regardless of what ever happened in the tests. The PMF of the â€œTest Resultâ€ variable regarless of the â€œDisease Statusâ€ are</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-Patient-Disease-and-Test-Results.html" id="subsec-Marginal-Probability-5-2-10">
\begin{align*}
\amp P(+) = P(D, +) + P(N, +) = 0.150 + 0.300 = 0.450 \\
\amp P(-) = P(D, -) + P(N, -) = 0.050 + 0.500 = 0.550
\end{align*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Marginal-Probability-5-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para" id="subsec-Marginal-Probability-5-3">Often, we display joint and marginal probabilities in a heatmap as shown in <a href="sec-Two-or-More-Random-Variables.html#fig-joint-heatmap" class="xref" data-knowl="./knowl/xref/fig-joint-heatmap.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 1.6.4">FigureÂ 1.6.4</a> with the marginals shown in the margins outside the Table.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Marginal-Probability-5-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<figure class="figure figure-like" id="fig-joint-heatmap"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/joint_heatmap.png" class="contained" alt="Heatmap of joint probabilities with marginals."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.4<span class="period">.</span></span><span class="space"> </span>Heatmap of joint probabilities for disease status (<span class="process-math">\(X \in \{D, N\}\)</span>) and test result (<span class="process-math">\(Y \in \{+, -\}\)</span>) from <span class="process-math">\(1,000\)</span> patients (<a href="sec-Two-or-More-Random-Variables.html#tab-patient-data-for-jt-and-conditional-probs" class="xref" data-knowl="./knowl/xref/tab-patient-data-for-jt-and-conditional-probs.html" data-reveal-label="Reveal" data-close-label="Close" title="Table 1.6.6: Patient counts (disease vs. test)">TableÂ 1.6.6</a>). Darker shades indicate higher probabilities. Marginal probabilities (<span class="process-math">\(P(X)\text{,}\)</span> <span class="process-math">\(P(Y)\)</span>) are shown in the margins.<div class="autopermalink" data-description="Figure 1.6.4"><a href="#fig-joint-heatmap" title="Copy heading and permalink for Figure 1.6.4" aria-label="Copy heading and permalink for Figure 1.6.4">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py">import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Joint probabilities from patient table
joint = np.array([[0.15, 0.05], [0.30, 0.50]])  # Rows: X=D, X=N; Cols: Y=+, Y=-
marginal_x = np.sum(joint, axis=1)  # P(D), P(N)
marginal_y = np.sum(joint, axis=0)  # P(+), P(-)

# Heatmap with marginals
fig, ax = plt.subplots()
sns.heatmap(joint, annot=True, fmt=".3f", cmap="Blues", cbar=False,
            xticklabels=["$Y=+$", "$Y=-$"], yticklabels=["$X=D$", "$X=N$"],
            annot_kws={"size": 16}, ax=ax)
for i, m in enumerate(marginal_x):
    ax.text(2.1, i + 0.5, f"{m:.3f}", va="center")
for j, m in enumerate(marginal_y):
    ax.text(j + 0.33, 2.2, f"{m:.3f}", ha="center")
ax.text(2.2, 2.2, "1.000", va="center", ha="center")
plt.title("Joint Probability Heatmap with Marginals")
plt.tight_layout()
plt.savefig("joint_heatmap.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Example 1.6.3: Marginal Probabilites from Joint Probability Table"><a href="#subsec-Marginal-Probability-5" title="Copy heading and permalink for Example 1.6.3: Marginal Probabilites from Joint Probability Table" aria-label="Copy heading and permalink for Example 1.6.3: Marginal Probabilites from Joint Probability Table">ðŸ”—</a></div></article><div class="autopermalink" data-description="Subsection 1.6.2: Marginal Probability"><a href="#subsec-Marginal-Probability" title="Copy heading and permalink for Subsection 1.6.2: Marginal Probability" aria-label="Copy heading and permalink for Subsection 1.6.2: Marginal Probability">ðŸ”—</a></div></section><section class="subsection" id="subsec-Conditional-Probability"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.3</span><span class="space"> </span><span class="title">Conditional Probability</span>
</h3>
<div class="para logical" id="subsec-Conditional-Probability-2">
<div class="para">
<dfn class="terminology">Conditional probability</dfn> is probability of one event <span class="process-math">\(A\)</span> given the knowledge that another event <span class="process-math">\(B\)</span> has occured. That is, you are allowed to look into the world in which <span class="process-math">\(B\)</span> should occur and then in that world, ask what fraction of that world is where <span class="process-math">\(A\)</span> would also occur, i.e., the event <span class="process-math">\(A\cap B\text{.}\)</span> Thus, conditional probability, denoted by <span class="process-math">\(P(A \mid B)\)</span>  will be the ratio of <span class="process-math">\(P(A\cap B)\)</span> to <span class="process-math">\(P(B)\text{.}\)</span>
</div>
<div class="displaymath process-math" id="eqn-conditonal-probability-conceptual-def">
\begin{equation}
P(A | B) = \frac{P(A\cap B)}{ P(B)},\quad P(B) \ne 0.\tag{1.6.6}
\end{equation}
</div>
<div class="para">Of course, <span class="process-math">\(P(B) \ne 0\)</span> from the setup itself, since we are assuming <span class="process-math">\(B\)</span> has occured, i.e., its unconditional probability must have been zero.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Conditional-Probability-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para" id="subsec-Conditional-Probability-3">So, how is it related to joint and marginal probabilities?<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Conditional-Probability-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="subsec-Conditional-Probability-4">
<div class="para">The <em class="alert">conditional probability</em> of <span class="process-math">\(X=x_i\)</span> given <span class="process-math">\(Y=y_j\)</span> is:</div>
<div class="displaymath process-math" id="eqn-conditional-definition">
\begin{equation}
P(X=x_i \mid Y=y_j) = \frac{P(X=x_i, Y=y_j)}{P(Y=y_j)}, \quad P(Y=y_j) &gt; 0.\tag{1.6.7}
\end{equation}
</div>
<div class="para">By the product rule:</div>
<div class="displaymath process-math" id="eqn-product-rule-in-joint-prob-section">
\begin{equation}
P(X=x_i, Y=y_j) = P(X=x_i \mid Y=y_j) P(Y=y_j).\tag{1.6.8}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Conditional-Probability-4" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para" id="subsec-Conditional-Probability-5">Conditional probabilities form a distribution over <span class="process-math">\(X\)</span> for fixed <span class="process-math">\(Y=y_j\text{,}\)</span> summing to 1: <span class="process-math">\(\sum_i P(X=x_i \mid Y=y_j) = 1\text{.}\)</span><div class="autopermalink" data-description="Paragraph"><a href="#subsec-Conditional-Probability-5" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsec-Conditional-Probability-6"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.5</span><span class="period">.</span><span class="space"> </span><span class="title">Patient disease and test results.</span>
</h4>
<div class="para logical" id="subsec-Conditional-Probability-6-2">
<div class="para">Using the patient dataset (<a href="sec-Two-or-More-Random-Variables.html#tab-patient-data-for-jt-and-conditional-probs" class="xref" data-knowl="./knowl/xref/tab-patient-data-for-jt-and-conditional-probs.html" data-reveal-label="Reveal" data-close-label="Close" title="Table 1.6.6: Patient counts (disease vs. test)">TableÂ 1.6.6</a>), compute all conditional probabilities: <figure class="table table-like" id="tab-patient-data-for-jt-and-conditional-probs"><figcaption><span class="type">Table</span><span class="space"> </span><span class="codenumber">1.6.6<span class="period">.</span></span><span class="space"> </span>Patient counts (disease vs. test)<div class="autopermalink" data-description="Table 1.6.6: Patient counts (disease vs. test)"><a href="#tab-patient-data-for-jt-and-conditional-probs" title="Copy heading and permalink for Table 1.6.6: Patient counts (disease vs. test)" aria-label="Copy heading and permalink for Table 1.6.6: Patient counts (disease vs. test)">ðŸ”—</a></div></figcaption><div class="tabular-box natural-width"><table class="tabular">
<tr>
<td class="l m b0 r0 l0 t0 lines"></td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(+\)</span></td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(-\)</span></td>
<td class="l m b0 r0 l0 t0 lines">Marginal</td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(D\)</span></td>
<td class="l m b0 r0 l0 t0 lines">150</td>
<td class="l m b0 r0 l0 t0 lines">50</td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(n_D=200\)</span></td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(N\)</span></td>
<td class="l m b0 r0 l0 t0 lines">300</td>
<td class="l m b0 r0 l0 t0 lines">500</td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(n_N=800\)</span></td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines">Marginal</td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(n_+=450\)</span></td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(n_-=550\)</span></td>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(n_T=1000\)</span></td>
</tr>
</table></div></figure> Joint probabilities:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-patient-data-for-jt-and-conditional-probs.html">
\begin{equation*}
P(D, +) = 0.150, \quad P(D, -) = 0.050, \quad P(N, +) = 0.300, \quad P(N, -) = 0.500.
\end{equation*}
</div>
<div class="para">Marginals: <span class="process-math">\(P(D) = 0.200\text{,}\)</span> <span class="process-math">\(P(N) = 0.800\text{,}\)</span> <span class="process-math">\(P(+) = 0.450\text{,}\)</span> <span class="process-math">\(P(-) = 0.550\text{.}\)</span> Conditional probabilities:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/tab-patient-data-for-jt-and-conditional-probs.html" id="subsec-Conditional-Probability-6-2-8">
\begin{gather*}
P(D \mid +) = \frac{0.150}{0.450} \approx 0.3333, \quad P(N \mid +) = \frac{0.300}{0.450} \approx 0.6667, \\
P(D \mid -) = \frac{0.050}{0.550} \approx 0.0909, \quad P(N \mid -) = \frac{0.500}{0.550} \approx 0.9091, \\
P(+ \mid D) = \frac{0.150}{0.200} = 0.750, \quad P(- \mid D) = \frac{0.050}{0.200} = 0.250, \\
P(+ \mid N) = \frac{0.300}{0.800} = 0.375, \quad P(- \mid N) = \frac{0.500}{0.800} = 0.625. 
\end{gather*}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Conditional-Probability-6-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Example 1.6.5: Patient disease and test results"><a href="#subsec-Conditional-Probability-6" title="Copy heading and permalink for Example 1.6.5: Patient disease and test results" aria-label="Copy heading and permalink for Example 1.6.5: Patient disease and test results">ðŸ”—</a></div></article><figure class="figure figure-like" id="fig-patient-bar-conditional"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/patient_conditional_bars.png" class="contained" alt="Grouped bar chart of conditional probabilities."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.7<span class="period">.</span></span><span class="space"> </span>Grouped bar chart of conditional probabilities for disease status (<span class="process-math">\(X \in \{D, N\}\)</span>) given test result (<span class="process-math">\(Y \in \{+, -\}\)</span>) and test result given disease status, based on <a href="sec-Two-or-More-Random-Variables.html#tab-patient-data-for-jt-and-conditional-probs" class="xref" data-knowl="./knowl/xref/tab-patient-data-for-jt-and-conditional-probs.html" data-reveal-label="Reveal" data-close-label="Close" title="Table 1.6.6: Patient counts (disease vs. test)">TableÂ 1.6.6</a>. Each group shows a probability distribution (summing to 1), illustrating how conditional probabilities slice the joint distribution.<div class="autopermalink" data-description="Figure 1.6.7"><a href="#fig-patient-bar-conditional" title="Copy heading and permalink for Figure 1.6.7" aria-label="Copy heading and permalink for Figure 1.6.7">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py"># === Grouped bar chart for all conditional probabilities ===
import matplotlib.pyplot as plt
import numpy as np

# Joint counts and probabilities
counts = {"D+": 150, "D-": 50, "N+": 300, "N-": 500}
total = 1000
P_D_plus = counts["D+"]/total
P_D_minus = counts["D-"]/total
P_N_plus = counts["N+"]/total
P_N_minus = counts["N-"]/total
P_plus = P_D_plus + P_N_plus
P_minus = P_D_minus + P_N_minus
P_D = P_D_plus + P_D_minus
P_N = P_N_plus + P_N_minus

# Conditional probabilities
probs = {
    "P(D|+)": P_D_plus / P_plus, "P(N|+)": P_N_plus / P_plus,
    "P(D|-)": P_D_minus / P_minus, "P(N|-)": P_N_minus / P_minus,
    "P(+|D)": P_D_plus / P_D, "P(-|D)": P_D_minus / P_D,
    "P(+|N)": P_N_plus / P_N, "P(-|N)": P_N_minus / P_N
}

# Grouped bar plot
labels = ["Given $Y=+$", "Given $Y=-$", "Given $X=D$", "Given $X=N$"]
values = [[probs["P(D|+)"], probs["P(N|+)"]], [probs["P(D|-)"], probs["P(N|-)"]],
          [probs["P(+|D)"], probs["P(-|D)"]], [probs["P(+|N)"], probs["P(-|N)"]]]
x = np.arange(len(labels))
width = 0.2
fig, ax = plt.subplots(figsize=(10, 6))
ax.bar(x - width/2, [v[0] for v in values], width, label="First Outcome", color="blue")
ax.bar(x + width/2, [v[1] for v in values], width, label="Second Outcome", color="red")
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.set_ylabel("Conditional Probability")
ax.set_title("Conditional Probabilities from Patient Table")
ax.legend(["$P(D|Â·)$, $P(+|Â·)$", "$P(N|Â·)$, $P(-|Â·)$"])
ax.set_ylim(0, 1)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("patient_conditional_bars.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsection 1.6.3: Conditional Probability"><a href="#subsec-Conditional-Probability" title="Copy heading and permalink for Subsection 1.6.3: Conditional Probability" aria-label="Copy heading and permalink for Subsection 1.6.3: Conditional Probability">ðŸ”—</a></div></section><section class="subsection" id="subsec-conditional-probability-from-joint-probability"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.4</span><span class="space"> </span><span class="title">Bayesâ€™ Rule</span>
</h3>
<div class="para logical" id="subsec-conditional-probability-from-joint-probability-2">
<div class="para">Bayesâ€™s theorem updates probabilities based on new evidence, derived from the product rule:</div>
<div class="displaymath process-math" id="eqn-bayes-general">
\begin{equation}
P(X=x_i \mid Y=y_j) = \frac{P(Y=y_j \mid X=x_i) P(X=x_i)}{P(Y=y_j)},\tag{1.6.9}
\end{equation}
</div>
<div class="para">where the denominator is the marginal probability:</div>
<div class="displaymath process-math" id="eqn-bayes-denominator">
\begin{equation}
P(Y=y_j) = \sum_k P(Y=y_j \mid X=x_k) P(X=x_k).\tag{1.6.10}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-conditional-probability-from-joint-probability-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsec-conditional-probability-from-joint-probability-3"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.8</span><span class="period">.</span><span class="space"> </span><span class="title">Breast cancer screening.</span>
</h4>
<div class="para logical" id="subsec-conditional-probability-from-joint-probability-3-2">
<div class="para">For a population with breast cancer prevalence <span class="process-math">\(P(C) = 0.01\text{,}\)</span> a mammogram has:</div>
<ul class="disc" id="subsec-conditional-probability-from-joint-probability-3-2-2">
<li id="subsec-conditional-probability-from-joint-probability-3-2-2-1">
<div class="para" id="p-derived-subsec-conditional-probability-from-joint-probability-3-2-2-1">
<em class="alert">Sensitivity</em>: <span class="process-math">\(P(+ \mid C) = 0.80\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-conditional-probability-from-joint-probability-3-2-2-1" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">ðŸ”—</a></div>
</li>
<li id="subsec-conditional-probability-from-joint-probability-3-2-2-2">
<div class="para" id="p-derived-subsec-conditional-probability-from-joint-probability-3-2-2-2">
<em class="alert">Specificity</em>: <span class="process-math">\(P(- \mid N) = 0.95\text{,}\)</span> so <span class="process-math">\(P(+ \mid N) = 1 - 0.95 = 0.05\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Item"><a href="#subsec-conditional-probability-from-joint-probability-3-2-2-2" title="Copy heading and permalink for Item" aria-label="Copy heading and permalink for Item">ðŸ”—</a></div>
</li>
</ul>
<div class="para">Compute <span class="process-math">\(P(C \mid +)\text{.}\)</span> First, the marginal probability:</div>
<div class="displaymath process-math">
\begin{equation*}
P(+) = P(+ \mid C)P(C) + P(+ \mid N)P(N) = 0.80 \cdot 0.01 + 0.05 \cdot 0.99 = 0.008 + 0.0495 = 0.0575.
\end{equation*}
</div>
<div class="para">Then:</div>
<div class="displaymath process-math" id="eqn-bayes-numeric">
\begin{equation}
P(C \mid +) = \frac{P(+ \mid C)P(C)}{P(+)} = \frac{0.008}{0.0575} \approx 0.1391.\tag{1.6.11}
\end{equation}
</div>
<div class="para">Thus, a positive test increases the probability of cancer from 1% to 13.91%.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-conditional-probability-from-joint-probability-3-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Example 1.6.8: Breast cancer screening"><a href="#subsec-conditional-probability-from-joint-probability-3" title="Copy heading and permalink for Example 1.6.8: Breast cancer screening" aria-label="Copy heading and permalink for Example 1.6.8: Breast cancer screening">ðŸ”—</a></div></article><figure class="figure figure-like" id="fig-bayes-tree"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/bayes_tree.png" class="contained" alt="Tree diagram for Bayesâ€™ rule in screening."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.9<span class="period">.</span></span><span class="space"> </span>Tree diagram for breast cancer screening, showing prior probabilities (<span class="process-math">\(P(C)\text{,}\)</span> <span class="process-math">\(P(N)\)</span>), likelihoods (<span class="process-math">\(P(+ \mid C)\text{,}\)</span> etc.), and joint probabilities leading to <span class="process-math">\(P(C \mid +)\text{.}\)</span> This visualizes Bayesâ€™ rule for medical diagnostics.<div class="autopermalink" data-description="Figure 1.6.9"><a href="#fig-bayes-tree" title="Copy heading and permalink for Figure 1.6.9" aria-label="Copy heading and permalink for Figure 1.6.9">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py"># === NEW CODE: Tree diagram using graphviz ===
from graphviz import Digraph

dot = Digraph(comment="Bayes Tree")
dot.attr(rankdir="LR")
dot.node("A", "Population\nP(C)=0.01\nP(N)=0.99", shape="box")
dot.node("B", "Cancer\nP(C)=0.01", shape="box")
dot.node("C", "No Cancer\nP(N)=0.99", shape="box")
dot.node("D", "Positive\nP(+|C)=0.80", shape="box")
dot.node("E", "Negative\nP(-|C)=0.20", shape="box")
dot.node("F", "Positive\nP(+|N)=0.05", shape="box")
dot.node("G", "Negative\nP(-|N)=0.95", shape="box")
dot.edges(["AB", "AC", "BD", "BE", "CF", "CG"])
dot.edge("B", "D", label="P(+|C)=0.80\nP(+,C)=0.008")
dot.edge("B", "E", label="P(-|C)=0.20\nP(-,C)=0.002")
dot.edge("C", "F", label="P(+|N)=0.05\nP(+,N)=0.0495")
dot.edge("C", "G", label="P(-|N)=0.95\nP(-,N)=0.9405")
dot.render("bayes_tree", format="png", cleanup=True)
</code></pre></div>
<div class="autopermalink" data-description="Subsection 1.6.4: Bayesâ€™ Rule"><a href="#subsec-conditional-probability-from-joint-probability" title="Copy heading and permalink for Subsection 1.6.4: Bayesâ€™ Rule" aria-label="Copy heading and permalink for Subsection 1.6.4: Bayesâ€™ Rule">ðŸ”—</a></div></section><section class="subsection" id="subsec-Covariance-and-Correlation"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.5</span><span class="space"> </span><span class="title">Covariance and Correlation</span>
</h3>
<div class="para logical" id="subsec-Covariance-and-Correlation-2">
<div class="para">The <em class="alert">covariance</em> between random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> measures their joint variability:</div>
<div class="displaymath process-math" id="eqn-covariance">
\begin{equation}
\mathrm{Cov}(X,Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y].\tag{1.6.12}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Covariance-and-Correlation-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="subsec-Covariance-and-Correlation-3">
<div class="para">The <em class="alert">correlation</em> normalizes covariance:</div>
<div class="displaymath process-math" id="eqn-correlation">
\begin{equation}
\mathrm{Corr}(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y}, \quad \mathrm{Corr}(X,Y) \in [-1, 1],\tag{1.6.13}
\end{equation}
</div>
<div class="para">where <span class="process-math">\(\sigma_X = \sqrt{\mathrm{Var}(X)}\text{,}\)</span> <span class="process-math">\(\sigma_Y = \sqrt{\mathrm{Var}(Y)}\text{.}\)</span> Positive correlation means <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> tend to increase together; negative means they move oppositely. Correlation does not imply causation.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Covariance-and-Correlation-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsec-Covariance-and-Correlation-4"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.10</span><span class="period">.</span><span class="space"> </span><span class="title">Patient symptom severity and test score.</span>
</h4>
<div class="para" id="subsec-Covariance-and-Correlation-4-2">For 1,000 patients, let <span class="process-math">\(X\)</span> be symptom severity (normal, mean 5 for disease, 3 for no disease, std 1.5) and <span class="process-math">\(Y\)</span> be test score (normal, mean 80 for disease, 60 for no disease, std 10). The code below computes covariance and correlation, showing a positive relationship.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Covariance-and-Correlation-4-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Example 1.6.10: Patient symptom severity and test score"><a href="#subsec-Covariance-and-Correlation-4" title="Copy heading and permalink for Example 1.6.10: Patient symptom severity and test score" aria-label="Copy heading and permalink for Example 1.6.10: Patient symptom severity and test score">ðŸ”—</a></div></article><figure class="figure figure-like" id="fig-correlation-scatter"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/correlation_examples.png" class="contained" alt="Scatter plot with regression lines for correlation."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.11<span class="period">.</span></span><span class="space"> </span>Scatter plot of symptom severity vs. test score for 1,000 patients, with regression lines for disease (D) and no disease (N) groups. The computed correlation coefficient is shown, indicating a positive relationship between features, relevant for medical diagnostics.<div class="autopermalink" data-description="Figure 1.6.11"><a href="#fig-correlation-scatter" title="Copy heading and permalink for Figure 1.6.11" aria-label="Copy heading and permalink for Figure 1.6.11">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py"># === Scatter plot with correlation and regression lines ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


np.random.seed(42)

# Synthetic patient data
counts = {"D+": 150, "D-": 50, "N+": 300, "N-": 500}
data = []
for status, _, count in [("D", 1, 200), ("N", 0, 800)]:
    severity = np.random.normal(5 if status == "D" else 3, 1.5, count)
    score = np.random.normal(80 if status == "D" else 60, 10, count)
    data.extend([[s, t, 1 if status == "D" else 0] for s, t in zip(severity, score)])
data = pd.DataFrame(data, columns=["Severity", "Score", "Disease"])

# Compute correlation
corr = data[["Severity", "Score"]].corr().iloc[0, 1]

# Plot with regression lines
plt.figure(figsize=(8, 6))
for d, color, label in [(1, "red", "Disease"), (0, "blue", "No Disease")]:
    subset = data[data["Disease"] == d]
    plt.scatter(subset["Severity"], subset["Score"], c=color, alpha=0.5, label=label)
    z = np.polyfit(subset["Severity"], subset["Score"], 1)
    p = np.poly1d(z)
    plt.plot(subset["Severity"], p(subset["Severity"]), color=color, linestyle="--")
plt.xlabel("Symptom Severity")
plt.ylabel("Test Score")
plt.title(f"Correlation: {corr:.3f}")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("correlation_examples.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsection 1.6.5: Covariance and Correlation"><a href="#subsec-Covariance-and-Correlation" title="Copy heading and permalink for Subsection 1.6.5: Covariance and Correlation" aria-label="Copy heading and permalink for Subsection 1.6.5: Covariance and Correlation">ðŸ”—</a></div></section><section class="subsection" id="subsec-Continuous-Random-Variables"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.6</span><span class="space"> </span><span class="title">Continuous Random Variables</span>
</h3>
<section class="introduction" id="subsec-Continuous-Random-Variables-2"><div class="para" id="subsec-Continuous-Random-Variables-2-1">For continuous random variables, probabilities are defined via density functions, extending discrete concepts to uncountable outcome spaces.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Continuous-Random-Variables-2-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div></section><section class="subsubsection" id="subsubsec-Probability-Density"><h4 class="heading hide-type">
<span class="type">Subsubsection</span><span class="space"> </span><span class="codenumber">1.6.6.1</span><span class="space"> </span><span class="title">Probability Density</span>
</h4>
<div class="para logical" id="subsubsec-Probability-Density-2">
<div class="para">A continuous random variable <span class="process-math">\(X\)</span> has a <em class="alert">probability density function (PDF)</em> <span class="process-math">\(f_X(x)\)</span> such that the probability over an interval <span class="process-math">\([a, b]\)</span> is:</div>
<div class="displaymath process-math" id="eqn-density-interval">
\begin{equation}
P(a \leq X \leq b) = \int_a^b f_X(x) \, dx.\tag{1.6.14}
\end{equation}
</div>
<div class="para">The density normalizes:</div>
<div class="displaymath process-math" id="eqn-density-normalize">
\begin{equation}
\int_{-\infty}^{\infty} f_X(x) \, dx = 1.\tag{1.6.15}
\end{equation}
</div>
<div class="para">Expectation and variance are:</div>
<div class="displaymath process-math" id="eqn-continuous-expectation">
\begin{equation}
\mathbb{E}[X] = \int_{-\infty}^{\infty} x f_X(x) \, dx, \quad \mathrm{Var}(X) = \int_{-\infty}^{\infty} (x - \mathbb{E}[X])^2 f_X(x) \, dx.\tag{1.6.16}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsubsec-Probability-Density-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="subsubsec-Probability-Density-3">
<div class="para">For two continuous variables <span class="process-math">\(X\text{,}\)</span> <span class="process-math">\(Y\text{,}\)</span> the <em class="alert">joint density</em> <span class="process-math">\(f_{X,Y}(x, y)\)</span> gives:</div>
<div class="displaymath process-math" id="eqn-joint-density">
\begin{equation}
P(a \leq X \leq b, c \leq Y \leq d) = \int_c^d \int_a^b f_{X,Y}(x, y) \, dx \, dy.\tag{1.6.17}
\end{equation}
</div>
<div class="para">The marginal density of <span class="process-math">\(X\)</span> is:</div>
<div class="displaymath process-math" id="eqn-marginal-density">
\begin{equation}
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dy.\tag{1.6.18}
\end{equation}
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsubsec-Probability-Density-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsubsec-Probability-Density-4"><h5 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.12</span><span class="period">.</span><span class="space"> </span><span class="title">Bivariate normal distribution.</span>
</h5>
<div class="para logical" id="subsubsec-Probability-Density-4-2">
<div class="para">A bivariate normal distribution for <span class="process-math">\(X\text{,}\)</span> <span class="process-math">\(Y\)</span> with means <span class="process-math">\(\mu_X = \mu_Y = 0\text{,}\)</span> variances <span class="process-math">\(\sigma_X^2 = \sigma_Y^2 = 1\text{,}\)</span> and correlation <span class="process-math">\(\rho = 0.5\)</span> has joint density:</div>
<div class="displaymath process-math" id="eqn-bivariate-normal">
\begin{equation}
f_{X,Y}(x, y) = \frac{1}{2\pi \sqrt{1 - \rho^2}} \exp\left(-\frac{x^2 - 2\rho xy + y^2}{2(1 - \rho^2)}\right).\tag{1.6.19}
\end{equation}
</div>
<div class="para">The marginal density of <span class="process-math">\(X\)</span> is the standard normal: <span class="process-math">\(f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsubsec-Probability-Density-4-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Example 1.6.12: Bivariate normal distribution"><a href="#subsubsec-Probability-Density-4" title="Copy heading and permalink for Example 1.6.12: Bivariate normal distribution" aria-label="Copy heading and permalink for Example 1.6.12: Bivariate normal distribution">ðŸ”—</a></div></article><figure class="figure figure-like" id="fig-bivariate-normal"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/bivariate_normal.png" class="contained" alt="Contour plot of bivariate normal joint density."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.13<span class="period">.</span></span><span class="space"> </span>Contour plot of the joint density of a bivariate normal distribution (<span class="process-math">\(\mu_X = \mu_Y = 0\text{,}\)</span> <span class="process-math">\(\sigma_X = \sigma_Y = 1\text{,}\)</span> <span class="process-math">\(\rho = 0.5\)</span>). Marginal densities of <span class="process-math">\(X\)</span> is shown on the right, illustrating marginalization by integrating over <span class="process-math">\(Y\text{.}\)</span><div class="autopermalink" data-description="Figure 1.6.13"><a href="#fig-bivariate-normal" title="Copy heading and permalink for Figure 1.6.13" aria-label="Copy heading and permalink for Figure 1.6.13">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py"># === Bivariate normal contour plot ===
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal

# Bivariate normal parameters
mu = [0, 0]
cov = [[1, 0.5], [0.5, 1]]  # Correlation rho = 0.5
rv = multivariate_normal(mean=mu, cov=cov)
x = np.linspace(-3, 3, 100)
y = np.linspace(-3, 3, 100)
X, Y = np.meshgrid(x, y)
pos = np.dstack((X, Y))
Z = rv.pdf(pos)

# Marginal density for X
marginal_x = np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)

# Plot
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
ax1.contour(X, Y, Z, cmap="Blues")
ax1.set_xlabel("X")
ax1.set_ylabel("Y")
ax1.set_title("Bivariate Normal Joint Density (Ï=0.5)")
ax1.grid(True, alpha=0.3)
ax2.plot(x, marginal_x)
ax2.set_xlabel("X")
ax2.set_ylabel("Density")
ax2.set_title("Marginal Density of X")
ax2.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("bivariate_normal.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsubsection 1.6.6.1: Probability Density"><a href="#subsubsec-Probability-Density" title="Copy heading and permalink for Subsubsection 1.6.6.1: Probability Density" aria-label="Copy heading and permalink for Subsubsection 1.6.6.1: Probability Density">ðŸ”—</a></div></section><section class="subsubsection" id="subsubsec-Cumulative-Distribution-Function"><h4 class="heading hide-type">
<span class="type">Subsubsection</span><span class="space"> </span><span class="codenumber">1.6.6.2</span><span class="space"> </span><span class="title">Cumulative Distribution Function</span>
</h4>
<div class="para logical" id="subsubsec-Cumulative-Distribution-Function-2">
<div class="para">The <em class="alert">cumulative distribution function (CDF)</em> of a continuous random variable <span class="process-math">\(X\)</span> is:</div>
<div class="displaymath process-math" id="eqn-cdf">
\begin{equation}
F_X(x) = P(X \leq x) = \int_{-\infty}^x f_X(t) \, dt.\tag{1.6.20}
\end{equation}
</div>
<div class="para">The density is the derivative: <span class="process-math">\(f_X(x) = \frac{d F_X}{dx}\text{,}\)</span> where differentiable.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsubsec-Cumulative-Distribution-Function-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para logical" id="subsubsec-Cumulative-Distribution-Function-3">
<div class="para">For a standard normal distribution (<span class="process-math">\(\mu = 0\text{,}\)</span> <span class="process-math">\(\sigma = 1\)</span>):</div>
<div class="displaymath process-math" id="eqn-normal-pdf">
\begin{equation}
f_X(x) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{x^2}{2}\right).\tag{1.6.21}
\end{equation}
</div>
<div class="para">Its CDF is <span class="process-math">\(F_X(x) = \Phi(x)\text{,}\)</span> the standard normal CDF.</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsubsec-Cumulative-Distribution-Function-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<figure class="figure figure-like" id="fig-normal-pdf-cdf"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/normal_pdf_cdf.png" class="contained" alt="Two-panel plot of standard normal PDF and CDF."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.14<span class="period">.</span></span><span class="space"> </span>PDF and CDF of a standard normal distribution (<span class="process-math">\(\mu=0\text{,}\)</span> <span class="process-math">\(\sigma=1\)</span>). The left panel shows the bell-shaped density, and the right panel shows the cumulative probability, illustrating <span class="process-math">\(F_X(x) = \int_{-\infty}^x f_X(t) \, dt\text{.}\)</span><div class="autopermalink" data-description="Figure 1.6.14"><a href="#fig-normal-pdf-cdf" title="Copy heading and permalink for Figure 1.6.14" aria-label="Copy heading and permalink for Figure 1.6.14">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py"># === Standard normal PDF and CDF ===
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

mu, sigma = 0.0, 1.0
dist = norm(loc=mu, scale=sigma)
x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)
pdf_values = dist.pdf(x)
cdf_values = dist.cdf(x)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
ax1.plot(x, pdf_values, label="PDF")
ax1.fill_between(x, pdf_values, alpha=0.2)
ax1.set_xlabel("x")
ax1.set_ylabel("Density")
ax1.set_title("Standard Normal PDF")
ax1.grid(True, alpha=0.3)
ax1.legend()
ax2.plot(x, cdf_values, label="CDF")
ax2.set_xlabel("x")
ax2.set_ylabel("Cumulative Probability")
ax2.set_title("Standard Normal CDF")
ax2.grid(True, alpha=0.3)
ax2.legend()
plt.tight_layout()
plt.savefig("normal_pdf_cdf.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsubsection 1.6.6.2: Cumulative Distribution Function"><a href="#subsubsec-Cumulative-Distribution-Function" title="Copy heading and permalink for Subsubsection 1.6.6.2: Cumulative Distribution Function" aria-label="Copy heading and permalink for Subsubsection 1.6.6.2: Cumulative Distribution Function">ðŸ”—</a></div></section><div class="autopermalink" data-description="Subsection 1.6.6: Continuous Random Variables"><a href="#subsec-Continuous-Random-Variables" title="Copy heading and permalink for Subsection 1.6.6: Continuous Random Variables" aria-label="Copy heading and permalink for Subsection 1.6.6: Continuous Random Variables">ðŸ”—</a></div></section><section class="subsection" id="subsec-Independent-Variables"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.7</span><span class="space"> </span><span class="title">Independent Random Variables</span>
</h3>
<div class="para logical" id="subsec-Independent-Variables-2">
<div class="para">Random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are <em class="alert">independent</em> if their joint distribution factorizes:</div>
<div class="displaymath process-math" id="eqn-independent-variables">
\begin{equation}
P(X=x_i, Y=y_j) = P(X=x_i) P(Y=y_j), \quad \text{for all } i, j.\tag{1.6.22}
\end{equation}
</div>
<div class="para">For continuous variables:</div>
<div class="displaymath process-math" id="eqn-independent-density">
\begin{equation}
f_{X,Y}(x, y) = f_X(x) f_Y(y).\tag{1.6.23}
\end{equation}
</div>
<div class="para">Equivalently, <span class="process-math">\(P(X=x_i \mid Y=y_j) = P(X=x_i)\)</span> or <span class="process-math">\(f_{X|Y}(x \mid y) = f_X(x)\text{.}\)</span>
</div>
<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Independent-Variables-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="para" id="subsec-Independent-Variables-3">Independence implies <span class="process-math">\(\mathrm{Cov}(X,Y) = 0\text{,}\)</span> but zero covariance does not imply independence, except for jointly normal variables.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Independent-Variables-3" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsec-Independent-Variables-4"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.15</span><span class="period">.</span><span class="space"> </span><span class="title">Independent vs. dependent variables.</span>
</h4>
<div class="para" id="subsec-Independent-Variables-4-2">Consider the patient dataset with <span class="process-math">\(X\)</span> (disease status) and <span class="process-math">\(Y\)</span> (test result), which are dependent (see <a href="sec-Two-or-More-Random-Variables.html#tab-patient-data-for-jt-and-conditional-probs" class="xref" data-knowl="./knowl/xref/tab-patient-data-for-jt-and-conditional-probs.html" data-reveal-label="Reveal" data-close-label="Close" title="Table 1.6.6: Patient counts (disease vs. test)">TableÂ 1.6.6</a>). Compare with <span class="process-math">\(Z\text{,}\)</span> a patientâ€™s age group (young/old), assumed independent of <span class="process-math">\(X\text{.}\)</span> The plot below shows joint probabilities for dependent and independent cases.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Independent-Variables-4-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Example 1.6.15: Independent vs. dependent variables"><a href="#subsec-Independent-Variables-4" title="Copy heading and permalink for Example 1.6.15: Independent vs. dependent variables" aria-label="Copy heading and permalink for Example 1.6.15: Independent vs. dependent variables">ðŸ”—</a></div></article><figure class="figure figure-like" id="fig-independence-heatmap"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/independence_heatmap.png" class="contained" alt="Heatmaps comparing dependent and independent joint probabilities."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.16<span class="period">.</span></span><span class="space"> </span>Heatmaps comparing joint probabilities for dependent (<span class="process-math">\(X\text{:}\)</span> disease, <span class="process-math">\(Y\text{:}\)</span> test) and independent (<span class="process-math">\(X\text{:}\)</span> disease, <span class="process-math">\(Z\text{:}\)</span> age) variables. The left heatmap shows non-factorized probabilities, indicating dependence; the right shows factorized probabilities, confirming independence.<div class="autopermalink" data-description="Figure 1.6.16"><a href="#fig-independence-heatmap" title="Copy heading and permalink for Figure 1.6.16" aria-label="Copy heading and permalink for Figure 1.6.16">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py"># === Heatmap for independent vs. dependent variables ===
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Dependent: X (disease), Y (test)
joint_xy = np.array([[0.15, 0.05], [0.30, 0.50]])
# Independent: X (disease), Z (age: young/old, P(young)=0.4, P(old)=0.6)
P_X = np.array([0.2, 0.8])  # P(D), P(N)
P_Z = np.array([0.4, 0.6])  # P(Young), P(Old)
joint_xz = np.outer(P_X, P_Z)

# Plot
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
sns.heatmap(joint_xy, annot=True, fmt=".3f", cmap="Blues", cbar=False,
            xticklabels=["Y=+", "Y=-"], yticklabels=["X=D", "X=N"], ax=ax1)
ax1.set_title("Dependent: P(X,Y)")
sns.heatmap(joint_xz, annot=True, fmt=".3f", cmap="Blues", cbar=False,
            xticklabels=["Z=Young", "Z=Old"], yticklabels=["X=D", "X=N"], ax=ax2)
ax2.set_title("Independent: P(X)P(Z)")
plt.tight_layout()
plt.savefig("independence_heatmap.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsection 1.6.7: Independent Random Variables"><a href="#subsec-Independent-Variables" title="Copy heading and permalink for Subsection 1.6.7: Independent Random Variables" aria-label="Copy heading and permalink for Subsection 1.6.7: Independent Random Variables">ðŸ”—</a></div></section><section class="subsection" id="subsec-Application-Medical-Diagnosis"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">1.6.8</span><span class="space"> </span><span class="title">Application: Medical Diagnosis</span>
</h3>
<div class="para" id="subsec-Application-Medical-Diagnosis-2">Joint and conditional probabilities are critical in medical diagnosis. Using the patient dataset, we estimate the probability of disease given symptoms and test results, combining multiple evidence sources.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Application-Medical-Diagnosis-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<article class="example example-like" id="subsec-Application-Medical-Diagnosis-3"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.6.17</span><span class="period">.</span><span class="space"> </span><span class="title">Diagnosing disease with test and severity.</span>
</h4>
<div class="para" id="subsec-Application-Medical-Diagnosis-3-2">Augment the patient dataset with symptom severity (<span class="process-math">\(S\text{,}\)</span> normal, mean 5 for D, 3 for N, std 1.5). For a patient with a positive test (<span class="process-math">\(Y=+\)</span>) and high severity (<span class="process-math">\(S \geq 4\)</span>), compute <span class="process-math">\(P(D \mid +, S \geq 4)\)</span> using conditional probabilities.<div class="autopermalink" data-description="Paragraph"><a href="#subsec-Application-Medical-Diagnosis-3-2" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div>
<div class="autopermalink" data-description="Example 1.6.17: Diagnosing disease with test and severity"><a href="#subsec-Application-Medical-Diagnosis-3" title="Copy heading and permalink for Example 1.6.17: Diagnosing disease with test and severity" aria-label="Copy heading and permalink for Example 1.6.17: Diagnosing disease with test and severity">ðŸ”—</a></div></article><figure class="figure figure-like" id="fig-diagnosis-conditional"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/./images/essential-probability-and-statistics/diagnosis_conditional.png" class="contained" alt="Bar chart of conditional probabilities for diagnosis."></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">1.6.18<span class="period">.</span></span><span class="space"> </span>Bar chart of conditional probabilities <span class="process-math">\(P(D \mid Y, S)\)</span> for combinations of test result (<span class="process-math">\(Y\)</span>) and symptom severity (<span class="process-math">\(S \geq 4\)</span> or <span class="process-math">\(S \lt 4\)</span>). This illustrates how multiple features refine disease probability estimates in medical diagnostics.<div class="autopermalink" data-description="Figure 1.6.18"><a href="#fig-diagnosis-conditional" title="Copy heading and permalink for Figure 1.6.18" aria-label="Copy heading and permalink for Figure 1.6.18">ðŸ”—</a></div></figcaption></figure><div class="code-box"><pre class="program clipboardable line-numbers"><code class="language-py">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

np.random.seed(42)

# Synthetic patient data
counts = {"D+": 150, "D-": 50, "N+": 300, "N-": 500}
data = []
for status, test, count in [("D", 1, 150), ("D", 0, 50), ("N", 1, 300), ("N", 0, 500)]:
    severity = np.random.normal(5 if status == "D" else 3, 1.5, count)
    data.extend([[1 if status == "D" else 0, test, s] for s in severity])
data = pd.DataFrame(data, columns=["Disease", "Test", "Severity"])
data["High_Severity"] = data["Severity"] &gt;= 4

# Compute conditional probabilities
probs = []
for test, hs in [(1, True), (1, False), (0, True), (0, False)]:
    subset = data[(data["Test"] == test) \amp; (data["High_Severity"] == hs)]
    if len(subset) &gt; 0:
        p_d = np.mean(subset["Disease"])
        probs.append(p_d)
    else:
        probs.append(0)

# Plot
labels = ["Y=+, Sâ‰¥4", "Y=+, S&lt;4", "Y=-, Sâ‰¥4", "Y=-, S&lt;4"]
plt.figure(figsize=(8, 6))
plt.bar(labels, probs, color="blue")
plt.ylabel("P(D | Y, S)")
plt.title("Conditional Probability of Disease")
plt.ylim(0, 1)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("diagnosis_conditional.png", dpi=300)
plt.show()
</code></pre></div>
<div class="autopermalink" data-description="Subsection 1.6.8: Application: Medical Diagnosis"><a href="#subsec-Application-Medical-Diagnosis" title="Copy heading and permalink for Subsection 1.6.8: Application: Medical Diagnosis" aria-label="Copy heading and permalink for Subsection 1.6.8: Application: Medical Diagnosis">ðŸ”—</a></div></section><section class="conclusion" id="sec-Two-or-More-Random-Variables-11"><div class="para" id="sec-Two-or-More-Random-Variables-11-1">Joint, marginal, and conditional probabilities form the foundation for modeling relationships between random variables. Joint probabilities capture co-occurrence, marginals summarize individual variables, and conditionals refine probabilities based on evidence. Bayesâ€™ rule updates beliefs, while independence simplifies joint distributions. Visualizations like heatmaps, scatter plots, and tree diagrams clarify these concepts. Apply these tools in fields like medical diagnostics, as shown, or explore further with resources like <a class="external" href="https://www.probabilitycourse.com/" target="_blank">Probability Course</a><details class="ptx-footnote" aria-live="polite" id="sec-Two-or-More-Random-Variables-11-1-2"><summary class="ptx-footnote__number" title="Footnote 1.6.1"><sup>â€‰1â€‰</sup></summary><div class="ptx-footnote__contents" id="sec-Two-or-More-Random-Variables-11-1-2"><code class="code-inline tex2jax_ignore">probabilitycourse.com</code></div></details>.<div class="autopermalink" data-description="Paragraph"><a href="#sec-Two-or-More-Random-Variables-11-1" title="Copy heading and permalink for Paragraph" aria-label="Copy heading and permalink for Paragraph">ðŸ”—</a></div>
</div></section><div class="autopermalink" data-description="Section 1.6: Two or More Random Variables"><a href="#sec-Two-or-More-Random-Variables" title="Copy heading and permalink for Section 1.6: Two or More Random Variables" aria-label="Copy heading and permalink for Section 1.6: Two or More Random Variables">ðŸ”—</a></div></section></div>
<div id="ptx-content-footer" class="ptx-content-footer">
<a class="previous-button button" href="sec-Random-Variables-and-Probabilities.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Top</span></a><a class="next-button button" href="sec-Example-Discrete-Probability-Distributions.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" height="100%" viewBox="338 3000 8772 6866" role="img"><title>PreTeXt logo</title><g style="stroke-width:.025in; stroke:currentColor; fill:none"><polyline points="472,3590 472,9732 " style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png" alt="Runstone Academy logo"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png" alt="MathJax logo"></a>
</div>
</body>
</html>
